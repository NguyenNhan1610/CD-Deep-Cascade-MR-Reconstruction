{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Unrolled Cascade with Data Consistency (DC) - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from scipy.io import loadmat\n",
    "# Importing our model\n",
    "MY_UTILS_PATH = \"../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "import cs_models as fsnet\n",
    "from  data_generator import DataGenerator\n",
    "# Importing callbacks and data augmentation utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import  Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/volume1/Raw_data/Kspace/Train/e14437s5_P49152.7.npy\n",
      "25\n",
      "/home/ubuntu/volume1/Raw_data/Kspace/Val/e14441s5_P76800.7.npy\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "## PARAMETERS\n",
    "H,W = 256,256 # Training image dimensions\n",
    "channels = 2 # complex data 0-> real; 1-> imaginary\n",
    "norm = np.sqrt(H*W)\n",
    "\n",
    "# Train Set \n",
    "train_path = \"/home/ubuntu/volume1/Raw_data/Kspace/Train/*.npy\"\n",
    "kspace_files_train = np.asarray(glob.glob(train_path))\n",
    "\n",
    "# Validation set\n",
    "val_path = \"/home/ubuntu/volume1/Raw_data/Kspace/Val/*.npy\"\n",
    "kspace_files_val = np.asarray(glob.glob(val_path))\n",
    "\n",
    "indexes = np.arange(kspace_files_train.size,dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "kspace_files_train = kspace_files_train[indexes]\n",
    "\n",
    "\n",
    "print(kspace_files_train[-1])\n",
    "print(len(kspace_files_train))\n",
    "\n",
    "print(kspace_files_val[-1])\n",
    "print(len(kspace_files_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 4004\n"
     ]
    }
   ],
   "source": [
    "offset = 5\n",
    "# Get number of samples\n",
    "ntrain = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "    ntrain += (np.load(kspace_files_train[ii]).shape[0] - 2*offset)\n",
    "\n",
    "# Load train data    \n",
    "rec_train = np.zeros((ntrain,H,W,2))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "     aux_kspace = np.load(kspace_files_train[ii])/norm\n",
    "     aux = int(aux_kspace.shape[0] - 2*offset)\n",
    "     aux2 = np.fft.ifft2(aux_kspace[offset:-offset,:,:,0]+\\\n",
    "                         1j*aux_kspace[offset:-offset,:,:,1])\n",
    "     rec_train[aux_counter:aux_counter+aux,:,:,0] = aux2.real\n",
    "     rec_train[aux_counter:aux_counter+aux,:,:,1] = aux2.imag\n",
    "     aux_counter+=aux\n",
    "\n",
    "# Shuffle training    \n",
    "indexes = np.arange(rec_train.shape[0],dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "rec_train = rec_train[indexes]\n",
    "print(\"Number of training samples\", rec_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 1600\n"
     ]
    }
   ],
   "source": [
    "# Get number of samples\n",
    "nval = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    nval += (np.load(kspace_files_val[ii]).shape[0] - 2*offset)\n",
    "\n",
    "kspace_val = np.zeros((nval,H,W,2))\n",
    "rec_val = np.zeros((nval,H,W,2))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    aux_kspace = np.load(kspace_files_val[ii])/norm\n",
    "    aux = int(aux_kspace.shape[0] - 2*offset)\n",
    "    kspace_val[aux_counter:aux_counter+aux] = aux_kspace[offset:-offset]\n",
    "    aux2 = np.fft.ifft2(aux_kspace[offset:-offset,:,:,0]+1j*aux_kspace[offset:-offset,:,:,1])\n",
    "    rec_val[aux_counter:aux_counter+aux,:,:,0] = aux2.real\n",
    "    rec_val[aux_counter:aux_counter+aux,:,:,1] = aux2.imag\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Undersampling kspace\n",
    "#rec_val = (rec_val-stats[0])/stats[1]\n",
    "rec_val_abs = np.abs(rec_val[:,:,:,0]+1j*rec_val[:,:,:,1])[:,:,:,np.newaxis]\n",
    "\n",
    "print(\"Number of samples\", kspace_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size= 6\n",
    "\n",
    "# Early stopping callback to shut down training after\n",
    "#10 epochs with no improvement\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                                       patience=20, \n",
    "                                       verbose=0, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(gen1,gen2,under_masks):\n",
    "    while True:\n",
    "        rec_real = gen1.next()\n",
    "        rec_imag = gen2.next()\n",
    "        kspace = np.fft.fft2(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])\n",
    "        kspace2 = np.zeros((kspace.shape[0],kspace.shape[1],kspace.shape[2],2))\n",
    "        kspace2[:,:,:,0] = kspace.real\n",
    "        kspace2[:,:,:,1] = kspace.imag\n",
    "        indexes = np.random.choice(np.arange(under_masks.shape[0], dtype=int), rec_real.shape[0], replace=False)\n",
    "        kspace2[under_masks[indexes]] = 0\n",
    "        \n",
    "        rec = np.abs(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])[:,:,:,np.newaxis]\n",
    "        rec_complex = np.zeros((rec.shape[0],rec.shape[1],rec.shape[2],2),dtype = np.float32)\n",
    "        rec_complex[:,:,:,0] = rec_real[:,:,:,0]\n",
    "        rec_complex[:,:,:,1] = rec_imag[:,:,:,0]\n",
    "        \n",
    "        yield([kspace2,under_masks[indexes].astype(np.float32)],[rec_complex,rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling: 0.8000030517578125\n",
      "Mask type: bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 256, 256, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 2)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 48) 912         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 2)  98          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 2)  0           conv2d_6[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 256, 256, 2)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 256, 256, 2)  0           lambda_6[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 2)  0           multiply_1[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 256, 256, 2)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 48) 912         lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 48) 20784       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 2)  98          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256, 256, 2)  0           conv2d_12[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 256, 256, 2)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 2)  0           lambda_16[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256, 256, 2)  0           multiply_2[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 256, 256, 2)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 48) 912         lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 2)  98          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 256, 2)  0           conv2d_18[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 256, 256, 2)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 256, 256, 2)  0           lambda_26[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 2)  0           multiply_3[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 256, 256, 2)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 48) 912         lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 2)  98          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 256, 2)  0           conv2d_24[0][0]                  \n",
      "                                                                 lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 256, 256, 2)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 256, 256, 2)  0           lambda_36[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 256, 2)  0           multiply_4[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 256, 256, 2)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 256, 256, 1)  0           lambda_41[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iiii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 112s 169ms/step - loss: 0.2056 - lambda_41_loss: 0.2289 - lambda_46_loss: 0.2056 - val_loss: 0.1446 - val_lambda_41_loss: 0.1609 - val_lambda_46_loss: 0.1446\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1402 - lambda_41_loss: 0.1642 - lambda_46_loss: 0.1402 - val_loss: 0.1124 - val_lambda_41_loss: 0.1404 - val_lambda_46_loss: 0.1124\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1125 - lambda_41_loss: 0.1296 - lambda_46_loss: 0.1125 - val_loss: 0.1044 - val_lambda_41_loss: 0.1250 - val_lambda_46_loss: 0.1044\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1018 - lambda_41_loss: 0.1169 - lambda_46_loss: 0.1018 - val_loss: 0.1032 - val_lambda_41_loss: 0.1155 - val_lambda_46_loss: 0.1032\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0972 - lambda_41_loss: 0.1100 - lambda_46_loss: 0.0972 - val_loss: 0.0955 - val_lambda_41_loss: 0.1077 - val_lambda_46_loss: 0.0955\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0971 - lambda_41_loss: 0.1124 - lambda_46_loss: 0.0971 - val_loss: 0.1080 - val_lambda_41_loss: 0.1226 - val_lambda_46_loss: 0.1080\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0937 - lambda_41_loss: 0.1072 - lambda_46_loss: 0.0937 - val_loss: 0.0951 - val_lambda_41_loss: 0.1066 - val_lambda_46_loss: 0.0951\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0910 - lambda_41_loss: 0.1045 - lambda_46_loss: 0.0910 - val_loss: 0.0911 - val_lambda_41_loss: 0.1022 - val_lambda_46_loss: 0.0911\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0874 - lambda_41_loss: 0.0996 - lambda_46_loss: 0.0874 - val_loss: 0.0950 - val_lambda_41_loss: 0.1076 - val_lambda_46_loss: 0.0950\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0843 - lambda_41_loss: 0.0951 - lambda_46_loss: 0.0843 - val_loss: 0.0897 - val_lambda_41_loss: 0.0979 - val_lambda_46_loss: 0.0897\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0842 - lambda_41_loss: 0.0955 - lambda_46_loss: 0.0842 - val_loss: 0.0914 - val_lambda_41_loss: 0.1014 - val_lambda_46_loss: 0.0914\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0836 - lambda_41_loss: 0.0949 - lambda_46_loss: 0.0836 - val_loss: 0.0878 - val_lambda_41_loss: 0.0968 - val_lambda_46_loss: 0.0878\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0834 - lambda_41_loss: 0.0944 - lambda_46_loss: 0.0834 - val_loss: 0.0821 - val_lambda_41_loss: 0.0909 - val_lambda_46_loss: 0.0821\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0795 - lambda_41_loss: 0.0901 - lambda_46_loss: 0.0795 - val_loss: 0.1011 - val_lambda_41_loss: 0.1135 - val_lambda_46_loss: 0.1011\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0894 - lambda_41_loss: 0.1029 - lambda_46_loss: 0.0894 - val_loss: 0.1096 - val_lambda_41_loss: 0.1278 - val_lambda_46_loss: 0.1096\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0837 - lambda_41_loss: 0.0954 - lambda_46_loss: 0.0837 - val_loss: 0.0862 - val_lambda_41_loss: 0.1004 - val_lambda_46_loss: 0.0862\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0781 - lambda_41_loss: 0.0874 - lambda_46_loss: 0.0781 - val_loss: 0.0873 - val_lambda_41_loss: 0.0968 - val_lambda_46_loss: 0.0873\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0767 - lambda_41_loss: 0.0859 - lambda_46_loss: 0.0767 - val_loss: 0.0860 - val_lambda_41_loss: 0.0976 - val_lambda_46_loss: 0.0860\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0776 - lambda_41_loss: 0.0875 - lambda_46_loss: 0.0776 - val_loss: 0.0825 - val_lambda_41_loss: 0.0976 - val_lambda_46_loss: 0.0825\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0755 - lambda_41_loss: 0.0844 - lambda_46_loss: 0.0755 - val_loss: 0.0816 - val_lambda_41_loss: 0.0900 - val_lambda_46_loss: 0.0816\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0748 - lambda_41_loss: 0.0839 - lambda_46_loss: 0.0748 - val_loss: 0.0824 - val_lambda_41_loss: 0.0938 - val_lambda_46_loss: 0.0824\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0738 - lambda_41_loss: 0.0822 - lambda_46_loss: 0.0738 - val_loss: 0.0812 - val_lambda_41_loss: 0.0881 - val_lambda_46_loss: 0.0812\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0743 - lambda_41_loss: 0.0834 - lambda_46_loss: 0.0743 - val_loss: 0.0817 - val_lambda_41_loss: 0.0896 - val_lambda_46_loss: 0.0817\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0744 - lambda_41_loss: 0.0831 - lambda_46_loss: 0.0744 - val_loss: 0.0855 - val_lambda_41_loss: 0.1010 - val_lambda_46_loss: 0.0855\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0738 - lambda_41_loss: 0.0826 - lambda_46_loss: 0.0738 - val_loss: 0.0935 - val_lambda_41_loss: 0.1075 - val_lambda_46_loss: 0.0935\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0727 - lambda_41_loss: 0.0812 - lambda_46_loss: 0.0727 - val_loss: 0.0863 - val_lambda_41_loss: 0.0953 - val_lambda_46_loss: 0.0863\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0727 - lambda_41_loss: 0.0810 - lambda_46_loss: 0.0727 - val_loss: 0.0843 - val_lambda_41_loss: 0.0927 - val_lambda_46_loss: 0.0843\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0733 - lambda_41_loss: 0.0820 - lambda_46_loss: 0.0733 - val_loss: 0.0840 - val_lambda_41_loss: 0.0940 - val_lambda_46_loss: 0.0840\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0714 - lambda_41_loss: 0.0797 - lambda_46_loss: 0.0714 - val_loss: 0.0814 - val_lambda_41_loss: 0.0897 - val_lambda_46_loss: 0.0814\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0718 - lambda_41_loss: 0.0799 - lambda_46_loss: 0.0718 - val_loss: 0.0804 - val_lambda_41_loss: 0.0881 - val_lambda_46_loss: 0.0804\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0713 - lambda_41_loss: 0.0795 - lambda_46_loss: 0.0713 - val_loss: 0.0804 - val_lambda_41_loss: 0.0879 - val_lambda_46_loss: 0.0804\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0713 - lambda_41_loss: 0.0792 - lambda_46_loss: 0.0713 - val_loss: 0.0806 - val_lambda_41_loss: 0.0915 - val_lambda_46_loss: 0.0806\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0704 - lambda_41_loss: 0.0786 - lambda_46_loss: 0.0704 - val_loss: 0.0822 - val_lambda_41_loss: 0.0907 - val_lambda_46_loss: 0.0822\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0704 - lambda_41_loss: 0.0782 - lambda_46_loss: 0.0704 - val_loss: 0.0796 - val_lambda_41_loss: 0.0873 - val_lambda_46_loss: 0.0796\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0713 - lambda_41_loss: 0.0798 - lambda_46_loss: 0.0713 - val_loss: 0.0779 - val_lambda_41_loss: 0.0877 - val_lambda_46_loss: 0.0779\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0703 - lambda_41_loss: 0.0782 - lambda_46_loss: 0.0703 - val_loss: 0.0781 - val_lambda_41_loss: 0.0866 - val_lambda_46_loss: 0.0781\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0697 - lambda_41_loss: 0.0776 - lambda_46_loss: 0.0697 - val_loss: 0.0789 - val_lambda_41_loss: 0.0874 - val_lambda_46_loss: 0.0789\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0697 - lambda_41_loss: 0.0774 - lambda_46_loss: 0.0697 - val_loss: 0.0792 - val_lambda_41_loss: 0.0874 - val_lambda_46_loss: 0.0792\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0691 - lambda_41_loss: 0.0768 - lambda_46_loss: 0.0691 - val_loss: 0.0773 - val_lambda_41_loss: 0.0847 - val_lambda_46_loss: 0.0773\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0700 - lambda_41_loss: 0.0777 - lambda_46_loss: 0.0700 - val_loss: 0.0791 - val_lambda_41_loss: 0.0881 - val_lambda_46_loss: 0.0791\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0691 - lambda_41_loss: 0.0769 - lambda_46_loss: 0.0691 - val_loss: 0.0831 - val_lambda_41_loss: 0.0928 - val_lambda_46_loss: 0.0831\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0694 - lambda_41_loss: 0.0772 - lambda_46_loss: 0.0694 - val_loss: 0.0794 - val_lambda_41_loss: 0.0883 - val_lambda_46_loss: 0.0794\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0678 - lambda_41_loss: 0.0750 - lambda_46_loss: 0.0678 - val_loss: 0.0893 - val_lambda_41_loss: 0.0964 - val_lambda_46_loss: 0.0893\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0690 - lambda_41_loss: 0.0769 - lambda_46_loss: 0.0690 - val_loss: 0.0794 - val_lambda_41_loss: 0.0874 - val_lambda_46_loss: 0.0794\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0679 - lambda_41_loss: 0.0752 - lambda_46_loss: 0.0679 - val_loss: 0.0757 - val_lambda_41_loss: 0.0832 - val_lambda_46_loss: 0.0757\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0669 - lambda_41_loss: 0.0743 - lambda_46_loss: 0.0669 - val_loss: 0.0803 - val_lambda_41_loss: 0.0883 - val_lambda_46_loss: 0.0803\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0683 - lambda_41_loss: 0.0758 - lambda_46_loss: 0.0683 - val_loss: 0.0805 - val_lambda_41_loss: 0.0887 - val_lambda_46_loss: 0.0805\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0676 - lambda_41_loss: 0.0747 - lambda_46_loss: 0.0676 - val_loss: 0.0760 - val_lambda_41_loss: 0.0840 - val_lambda_46_loss: 0.0760\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0675 - lambda_41_loss: 0.0748 - lambda_46_loss: 0.0675 - val_loss: 0.0779 - val_lambda_41_loss: 0.0854 - val_lambda_46_loss: 0.0779\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0676 - lambda_41_loss: 0.0747 - lambda_46_loss: 0.0676 - val_loss: 0.1015 - val_lambda_41_loss: 0.1082 - val_lambda_46_loss: 0.1015\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 256, 256, 2)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 48) 912         lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 2)  98          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 256, 256, 2)  0           conv2d_30[0][0]                  \n",
      "                                                                 lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 256, 256, 2)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 256, 256, 2)  0           lambda_56[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256, 256, 2)  0           multiply_5[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 256, 256, 2)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 48) 912         lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 2)  98          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 256, 256, 2)  0           conv2d_36[0][0]                  \n",
      "                                                                 lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 256, 256, 2)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 256, 256, 2)  0           lambda_66[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256, 256, 2)  0           multiply_6[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 256, 256, 2)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 48) 912         lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 256, 256, 2)  98          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 256, 256, 2)  0           conv2d_42[0][0]                  \n",
      "                                                                 lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 256, 256, 2)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 256, 256, 2)  0           lambda_76[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 256, 256, 2)  0           multiply_7[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 256, 256, 2)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 256, 256, 1)  0           lambda_81[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.2146 - lambda_81_loss: 0.2404 - lambda_86_loss: 0.2146 - val_loss: 0.1641 - val_lambda_81_loss: 0.1877 - val_lambda_86_loss: 0.1641\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1510 - lambda_81_loss: 0.1818 - lambda_86_loss: 0.1510 - val_loss: 0.1505 - val_lambda_81_loss: 0.1669 - val_lambda_86_loss: 0.1505\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1318 - lambda_81_loss: 0.1546 - lambda_86_loss: 0.1318 - val_loss: 0.1245 - val_lambda_81_loss: 0.1428 - val_lambda_86_loss: 0.1245\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1202 - lambda_81_loss: 0.1403 - lambda_86_loss: 0.1202 - val_loss: 0.1193 - val_lambda_81_loss: 0.1485 - val_lambda_86_loss: 0.1193\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1163 - lambda_81_loss: 0.1355 - lambda_86_loss: 0.1163 - val_loss: 0.1146 - val_lambda_81_loss: 0.1394 - val_lambda_86_loss: 0.1146\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1126 - lambda_81_loss: 0.1304 - lambda_86_loss: 0.1126 - val_loss: 0.1126 - val_lambda_81_loss: 0.1269 - val_lambda_86_loss: 0.1126\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1094 - lambda_81_loss: 0.1270 - lambda_86_loss: 0.1094 - val_loss: 0.1219 - val_lambda_81_loss: 0.1551 - val_lambda_86_loss: 0.1219\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1099 - lambda_81_loss: 0.1291 - lambda_86_loss: 0.1099 - val_loss: 0.1127 - val_lambda_81_loss: 0.1417 - val_lambda_86_loss: 0.1127\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1061 - lambda_81_loss: 0.1229 - lambda_86_loss: 0.1061 - val_loss: 0.1192 - val_lambda_81_loss: 0.1391 - val_lambda_86_loss: 0.1192\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1034 - lambda_81_loss: 0.1197 - lambda_86_loss: 0.1034 - val_loss: 0.1125 - val_lambda_81_loss: 0.1275 - val_lambda_86_loss: 0.1125\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1049 - lambda_81_loss: 0.1238 - lambda_86_loss: 0.1049 - val_loss: 0.1050 - val_lambda_81_loss: 0.1212 - val_lambda_86_loss: 0.1050\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1020 - lambda_81_loss: 0.1185 - lambda_86_loss: 0.1020 - val_loss: 0.1104 - val_lambda_81_loss: 0.1275 - val_lambda_86_loss: 0.1104\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0994 - lambda_81_loss: 0.1147 - lambda_86_loss: 0.0994 - val_loss: 0.1087 - val_lambda_81_loss: 0.1216 - val_lambda_86_loss: 0.1087\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0995 - lambda_81_loss: 0.1153 - lambda_86_loss: 0.0995 - val_loss: 0.1065 - val_lambda_81_loss: 0.1255 - val_lambda_86_loss: 0.1065\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0993 - lambda_81_loss: 0.1149 - lambda_86_loss: 0.0993 - val_loss: 0.1031 - val_lambda_81_loss: 0.1207 - val_lambda_86_loss: 0.1031\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0974 - lambda_81_loss: 0.1123 - lambda_86_loss: 0.0974 - val_loss: 0.1068 - val_lambda_81_loss: 0.1208 - val_lambda_86_loss: 0.1068\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0963 - lambda_81_loss: 0.1112 - lambda_86_loss: 0.0963 - val_loss: 0.1100 - val_lambda_81_loss: 0.1252 - val_lambda_86_loss: 0.1100\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0959 - lambda_81_loss: 0.1110 - lambda_86_loss: 0.0959 - val_loss: 0.1040 - val_lambda_81_loss: 0.1174 - val_lambda_86_loss: 0.1040\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0959 - lambda_81_loss: 0.1105 - lambda_86_loss: 0.0959 - val_loss: 0.1098 - val_lambda_81_loss: 0.1280 - val_lambda_86_loss: 0.1098\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0950 - lambda_81_loss: 0.1095 - lambda_86_loss: 0.0950 - val_loss: 0.1073 - val_lambda_81_loss: 0.1248 - val_lambda_86_loss: 0.1073\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0953 - lambda_81_loss: 0.1098 - lambda_86_loss: 0.0953 - val_loss: 0.1060 - val_lambda_81_loss: 0.1222 - val_lambda_86_loss: 0.1060\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0956 - lambda_81_loss: 0.1109 - lambda_86_loss: 0.0956 - val_loss: 0.1139 - val_lambda_81_loss: 0.1346 - val_lambda_86_loss: 0.1139\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0924 - lambda_81_loss: 0.1063 - lambda_86_loss: 0.0924 - val_loss: 0.0996 - val_lambda_81_loss: 0.1157 - val_lambda_86_loss: 0.0996\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0927 - lambda_81_loss: 0.1067 - lambda_86_loss: 0.0927 - val_loss: 0.1087 - val_lambda_81_loss: 0.1278 - val_lambda_86_loss: 0.1087\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0933 - lambda_81_loss: 0.1073 - lambda_86_loss: 0.0933 - val_loss: 0.1047 - val_lambda_81_loss: 0.1182 - val_lambda_86_loss: 0.1047\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0922 - lambda_81_loss: 0.1061 - lambda_86_loss: 0.0922 - val_loss: 0.0992 - val_lambda_81_loss: 0.1167 - val_lambda_86_loss: 0.0992\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0912 - lambda_81_loss: 0.1049 - lambda_86_loss: 0.0912 - val_loss: 0.0960 - val_lambda_81_loss: 0.1115 - val_lambda_86_loss: 0.0960\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0911 - lambda_81_loss: 0.1050 - lambda_86_loss: 0.0911 - val_loss: 0.0998 - val_lambda_81_loss: 0.1165 - val_lambda_86_loss: 0.0998\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0909 - lambda_81_loss: 0.1047 - lambda_86_loss: 0.0909 - val_loss: 0.0976 - val_lambda_81_loss: 0.1104 - val_lambda_86_loss: 0.0976\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0904 - lambda_81_loss: 0.1046 - lambda_86_loss: 0.0904 - val_loss: 0.0969 - val_lambda_81_loss: 0.1127 - val_lambda_86_loss: 0.0969\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0896 - lambda_81_loss: 0.1034 - lambda_86_loss: 0.0896 - val_loss: 0.1021 - val_lambda_81_loss: 0.1159 - val_lambda_86_loss: 0.1021\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0903 - lambda_81_loss: 0.1038 - lambda_86_loss: 0.0903 - val_loss: 0.1001 - val_lambda_81_loss: 0.1179 - val_lambda_86_loss: 0.1001\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0884 - lambda_81_loss: 0.1020 - lambda_86_loss: 0.0884 - val_loss: 0.0963 - val_lambda_81_loss: 0.1112 - val_lambda_86_loss: 0.0963\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0879 - lambda_81_loss: 0.1010 - lambda_86_loss: 0.0879 - val_loss: 0.0984 - val_lambda_81_loss: 0.1122 - val_lambda_86_loss: 0.0984\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0884 - lambda_81_loss: 0.1020 - lambda_86_loss: 0.0884 - val_loss: 0.1030 - val_lambda_81_loss: 0.1185 - val_lambda_86_loss: 0.1030\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.0881 - lambda_81_loss: 0.1014 - lambda_86_loss: 0.0881 - val_loss: 0.1017 - val_lambda_81_loss: 0.1218 - val_lambda_86_loss: 0.1017\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0886 - lambda_81_loss: 0.1021 - lambda_86_loss: 0.0886 - val_loss: 0.0981 - val_lambda_81_loss: 0.1107 - val_lambda_86_loss: 0.0981\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0879 - lambda_81_loss: 0.1012 - lambda_86_loss: 0.0879 - val_loss: 0.0942 - val_lambda_81_loss: 0.1081 - val_lambda_86_loss: 0.0942\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0880 - lambda_81_loss: 0.1018 - lambda_86_loss: 0.0880 - val_loss: 0.1043 - val_lambda_81_loss: 0.1229 - val_lambda_86_loss: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0871 - lambda_81_loss: 0.0999 - lambda_86_loss: 0.0871 - val_loss: 0.0937 - val_lambda_81_loss: 0.1092 - val_lambda_86_loss: 0.0937\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0859 - lambda_81_loss: 0.0991 - lambda_86_loss: 0.0859 - val_loss: 0.0997 - val_lambda_81_loss: 0.1190 - val_lambda_86_loss: 0.0997\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0870 - lambda_81_loss: 0.1002 - lambda_86_loss: 0.0870 - val_loss: 0.1048 - val_lambda_81_loss: 0.1220 - val_lambda_86_loss: 0.1048\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0868 - lambda_81_loss: 0.1000 - lambda_86_loss: 0.0868 - val_loss: 0.1075 - val_lambda_81_loss: 0.1222 - val_lambda_86_loss: 0.1075\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0866 - lambda_81_loss: 0.0997 - lambda_86_loss: 0.0866 - val_loss: 0.0986 - val_lambda_81_loss: 0.1154 - val_lambda_86_loss: 0.0986\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0855 - lambda_81_loss: 0.0986 - lambda_86_loss: 0.0855 - val_loss: 0.1015 - val_lambda_81_loss: 0.1161 - val_lambda_86_loss: 0.1015\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0861 - lambda_81_loss: 0.0992 - lambda_86_loss: 0.0861 - val_loss: 0.0980 - val_lambda_81_loss: 0.1127 - val_lambda_86_loss: 0.0980\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0860 - lambda_81_loss: 0.0990 - lambda_86_loss: 0.0860 - val_loss: 0.0971 - val_lambda_81_loss: 0.1127 - val_lambda_86_loss: 0.0971\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0855 - lambda_81_loss: 0.0983 - lambda_86_loss: 0.0855 - val_loss: 0.0991 - val_lambda_81_loss: 0.1161 - val_lambda_86_loss: 0.0991\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0859 - lambda_81_loss: 0.0990 - lambda_86_loss: 0.0859 - val_loss: 0.0984 - val_lambda_81_loss: 0.1161 - val_lambda_86_loss: 0.0984\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0846 - lambda_81_loss: 0.0977 - lambda_86_loss: 0.0846 - val_loss: 0.0959 - val_lambda_81_loss: 0.1113 - val_lambda_86_loss: 0.0959\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 256, 256, 48) 912         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 256, 256, 2)  98          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 256, 256, 2)  0           conv2d_48[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 256, 256, 2)  0           add_15[0][0]                     \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 256, 256, 2)  0           multiply_8[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 256, 256, 2)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 256, 256, 1)  0           lambda_91[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 84,146\n",
      "Trainable params: 84,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_k_gaussian_20.hdf5\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.4127 - lambda_91_loss: 0.4881 - lambda_96_loss: 0.4127 - val_loss: 0.3771 - val_lambda_91_loss: 0.4462 - val_lambda_96_loss: 0.3771\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.3650 - lambda_91_loss: 0.4342 - lambda_96_loss: 0.3650 - val_loss: 0.3564 - val_lambda_91_loss: 0.4309 - val_lambda_96_loss: 0.3564\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.3434 - lambda_91_loss: 0.4139 - lambda_96_loss: 0.3434 - val_loss: 0.3245 - val_lambda_91_loss: 0.3944 - val_lambda_96_loss: 0.3245\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.3298 - lambda_91_loss: 0.4002 - lambda_96_loss: 0.3298 - val_loss: 0.3174 - val_lambda_91_loss: 0.3846 - val_lambda_96_loss: 0.3174\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.3257 - lambda_91_loss: 0.3953 - lambda_96_loss: 0.3257 - val_loss: 0.3132 - val_lambda_91_loss: 0.3856 - val_lambda_96_loss: 0.3132\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.3193 - lambda_91_loss: 0.3884 - lambda_96_loss: 0.3193 - val_loss: 0.3059 - val_lambda_91_loss: 0.3718 - val_lambda_96_loss: 0.3059\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.3126 - lambda_91_loss: 0.3815 - lambda_96_loss: 0.3126 - val_loss: 0.2993 - val_lambda_91_loss: 0.3668 - val_lambda_96_loss: 0.2993\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.3096 - lambda_91_loss: 0.3782 - lambda_96_loss: 0.3096 - val_loss: 0.2973 - val_lambda_91_loss: 0.3671 - val_lambda_96_loss: 0.2973\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.3057 - lambda_91_loss: 0.3732 - lambda_96_loss: 0.3057 - val_loss: 0.2936 - val_lambda_91_loss: 0.3629 - val_lambda_96_loss: 0.2936\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.3026 - lambda_91_loss: 0.3704 - lambda_96_loss: 0.3026 - val_loss: 0.2933 - val_lambda_91_loss: 0.3564 - val_lambda_96_loss: 0.2933\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.3020 - lambda_91_loss: 0.3693 - lambda_96_loss: 0.3020 - val_loss: 0.2909 - val_lambda_91_loss: 0.3637 - val_lambda_96_loss: 0.2909\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2984 - lambda_91_loss: 0.3659 - lambda_96_loss: 0.2984 - val_loss: 0.2877 - val_lambda_91_loss: 0.3520 - val_lambda_96_loss: 0.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2955 - lambda_91_loss: 0.3621 - lambda_96_loss: 0.2955 - val_loss: 0.2882 - val_lambda_91_loss: 0.3561 - val_lambda_96_loss: 0.2882\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.2959 - lambda_91_loss: 0.3632 - lambda_96_loss: 0.2959 - val_loss: 0.2904 - val_lambda_91_loss: 0.3527 - val_lambda_96_loss: 0.2904\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2960 - lambda_91_loss: 0.3629 - lambda_96_loss: 0.2960 - val_loss: 0.2846 - val_lambda_91_loss: 0.3516 - val_lambda_96_loss: 0.2846\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2922 - lambda_91_loss: 0.3592 - lambda_96_loss: 0.2922 - val_loss: 0.2850 - val_lambda_91_loss: 0.3569 - val_lambda_96_loss: 0.2850\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2912 - lambda_91_loss: 0.3580 - lambda_96_loss: 0.2912 - val_loss: 0.2795 - val_lambda_91_loss: 0.3501 - val_lambda_96_loss: 0.2795\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2904 - lambda_91_loss: 0.3576 - lambda_96_loss: 0.2904 - val_loss: 0.2800 - val_lambda_91_loss: 0.3505 - val_lambda_96_loss: 0.2800\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2891 - lambda_91_loss: 0.3562 - lambda_96_loss: 0.2891 - val_loss: 0.2782 - val_lambda_91_loss: 0.3510 - val_lambda_96_loss: 0.2782\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2874 - lambda_91_loss: 0.3542 - lambda_96_loss: 0.2874 - val_loss: 0.2778 - val_lambda_91_loss: 0.3479 - val_lambda_96_loss: 0.2778\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2874 - lambda_91_loss: 0.3542 - lambda_96_loss: 0.2874 - val_loss: 0.2789 - val_lambda_91_loss: 0.3372 - val_lambda_96_loss: 0.2789\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2875 - lambda_91_loss: 0.3542 - lambda_96_loss: 0.2875 - val_loss: 0.2762 - val_lambda_91_loss: 0.3440 - val_lambda_96_loss: 0.2762\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2846 - lambda_91_loss: 0.3504 - lambda_96_loss: 0.2846 - val_loss: 0.2740 - val_lambda_91_loss: 0.3413 - val_lambda_96_loss: 0.2740\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2832 - lambda_91_loss: 0.3495 - lambda_96_loss: 0.2832 - val_loss: 0.2758 - val_lambda_91_loss: 0.3413 - val_lambda_96_loss: 0.2758\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2840 - lambda_91_loss: 0.3508 - lambda_96_loss: 0.2840 - val_loss: 0.2775 - val_lambda_91_loss: 0.3458 - val_lambda_96_loss: 0.2775\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2831 - lambda_91_loss: 0.3492 - lambda_96_loss: 0.2831 - val_loss: 0.2769 - val_lambda_91_loss: 0.3450 - val_lambda_96_loss: 0.2769\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2819 - lambda_91_loss: 0.3482 - lambda_96_loss: 0.2819 - val_loss: 0.2699 - val_lambda_91_loss: 0.3356 - val_lambda_96_loss: 0.2699\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2828 - lambda_91_loss: 0.3490 - lambda_96_loss: 0.2828 - val_loss: 0.2687 - val_lambda_91_loss: 0.3352 - val_lambda_96_loss: 0.2687\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2796 - lambda_91_loss: 0.3455 - lambda_96_loss: 0.2796 - val_loss: 0.2753 - val_lambda_91_loss: 0.3397 - val_lambda_96_loss: 0.2753\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2811 - lambda_91_loss: 0.3471 - lambda_96_loss: 0.2811 - val_loss: 0.2699 - val_lambda_91_loss: 0.3393 - val_lambda_96_loss: 0.2699\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2806 - lambda_91_loss: 0.3465 - lambda_96_loss: 0.2806 - val_loss: 0.2742 - val_lambda_91_loss: 0.3408 - val_lambda_96_loss: 0.2742\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2766 - lambda_91_loss: 0.3416 - lambda_96_loss: 0.2766 - val_loss: 0.2737 - val_lambda_91_loss: 0.3429 - val_lambda_96_loss: 0.2737\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2789 - lambda_91_loss: 0.3453 - lambda_96_loss: 0.2789 - val_loss: 0.2703 - val_lambda_91_loss: 0.3304 - val_lambda_96_loss: 0.2703\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2780 - lambda_91_loss: 0.3436 - lambda_96_loss: 0.2780 - val_loss: 0.2710 - val_lambda_91_loss: 0.3375 - val_lambda_96_loss: 0.2710\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2798 - lambda_91_loss: 0.3458 - lambda_96_loss: 0.2798 - val_loss: 0.2678 - val_lambda_91_loss: 0.3344 - val_lambda_96_loss: 0.2678\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2787 - lambda_91_loss: 0.3444 - lambda_96_loss: 0.2787 - val_loss: 0.2690 - val_lambda_91_loss: 0.3363 - val_lambda_96_loss: 0.2690\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2772 - lambda_91_loss: 0.3425 - lambda_96_loss: 0.2772 - val_loss: 0.2653 - val_lambda_91_loss: 0.3313 - val_lambda_96_loss: 0.2653\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2773 - lambda_91_loss: 0.3429 - lambda_96_loss: 0.2773 - val_loss: 0.2691 - val_lambda_91_loss: 0.3309 - val_lambda_96_loss: 0.2691\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2781 - lambda_91_loss: 0.3444 - lambda_96_loss: 0.2781 - val_loss: 0.2676 - val_lambda_91_loss: 0.3331 - val_lambda_96_loss: 0.2676\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2751 - lambda_91_loss: 0.3403 - lambda_96_loss: 0.2751 - val_loss: 0.2705 - val_lambda_91_loss: 0.3358 - val_lambda_96_loss: 0.2705\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2756 - lambda_91_loss: 0.3409 - lambda_96_loss: 0.2756 - val_loss: 0.2656 - val_lambda_91_loss: 0.3326 - val_lambda_96_loss: 0.2656\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2753 - lambda_91_loss: 0.3409 - lambda_96_loss: 0.2753 - val_loss: 0.2687 - val_lambda_91_loss: 0.3362 - val_lambda_96_loss: 0.2687\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2753 - lambda_91_loss: 0.3410 - lambda_96_loss: 0.2753 - val_loss: 0.2716 - val_lambda_91_loss: 0.3401 - val_lambda_96_loss: 0.2716\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2742 - lambda_91_loss: 0.3398 - lambda_96_loss: 0.2742 - val_loss: 0.2717 - val_lambda_91_loss: 0.3347 - val_lambda_96_loss: 0.2717\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2741 - lambda_91_loss: 0.3396 - lambda_96_loss: 0.2741 - val_loss: 0.2652 - val_lambda_91_loss: 0.3315 - val_lambda_96_loss: 0.2652\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2747 - lambda_91_loss: 0.3400 - lambda_96_loss: 0.2747 - val_loss: 0.2643 - val_lambda_91_loss: 0.3294 - val_lambda_96_loss: 0.2643\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2738 - lambda_91_loss: 0.3393 - lambda_96_loss: 0.2738 - val_loss: 0.2657 - val_lambda_91_loss: 0.3323 - val_lambda_96_loss: 0.2657\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2732 - lambda_91_loss: 0.3384 - lambda_96_loss: 0.2732 - val_loss: 0.2677 - val_lambda_91_loss: 0.3362 - val_lambda_96_loss: 0.2677\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2732 - lambda_91_loss: 0.3385 - lambda_96_loss: 0.2732 - val_loss: 0.2649 - val_lambda_91_loss: 0.3268 - val_lambda_96_loss: 0.2649\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2714 - lambda_91_loss: 0.3367 - lambda_96_loss: 0.2714 - val_loss: 0.2631 - val_lambda_91_loss: 0.3308 - val_lambda_96_loss: 0.2631\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 256, 256, 2)  0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 256, 256, 48) 912         lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 256, 256, 2)  98          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 256, 256, 2)  0           conv2d_54[0][0]                  \n",
      "                                                                 lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 256, 256, 2)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 256, 256, 2)  0           lambda_106[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 256, 256, 2)  0           multiply_9[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 256, 256, 2)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 256, 256, 1)  0           lambda_111[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 84,146\n",
      "Trainable params: 84,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_i_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.3131 - lambda_111_loss: 0.3399 - lambda_116_loss: 0.3131 - val_loss: 0.2833 - val_lambda_111_loss: 0.3176 - val_lambda_116_loss: 0.2833\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2743 - lambda_111_loss: 0.3015 - lambda_116_loss: 0.2743 - val_loss: 0.2647 - val_lambda_111_loss: 0.2904 - val_lambda_116_loss: 0.2647\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2628 - lambda_111_loss: 0.2894 - lambda_116_loss: 0.2628 - val_loss: 0.2667 - val_lambda_111_loss: 0.2967 - val_lambda_116_loss: 0.2667\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2580 - lambda_111_loss: 0.2847 - lambda_116_loss: 0.2580 - val_loss: 0.2487 - val_lambda_111_loss: 0.2768 - val_lambda_116_loss: 0.2487\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2544 - lambda_111_loss: 0.2812 - lambda_116_loss: 0.2544 - val_loss: 0.2553 - val_lambda_111_loss: 0.2818 - val_lambda_116_loss: 0.2553\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2511 - lambda_111_loss: 0.2780 - lambda_116_loss: 0.2511 - val_loss: 0.2644 - val_lambda_111_loss: 0.2830 - val_lambda_116_loss: 0.2644\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2476 - lambda_111_loss: 0.2749 - lambda_116_loss: 0.2476 - val_loss: 0.2508 - val_lambda_111_loss: 0.2740 - val_lambda_116_loss: 0.2508\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2460 - lambda_111_loss: 0.2729 - lambda_116_loss: 0.2460 - val_loss: 0.2463 - val_lambda_111_loss: 0.2802 - val_lambda_116_loss: 0.2463\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2470 - lambda_111_loss: 0.2739 - lambda_116_loss: 0.2470 - val_loss: 0.2614 - val_lambda_111_loss: 0.2971 - val_lambda_116_loss: 0.2614\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2409 - lambda_111_loss: 0.2683 - lambda_116_loss: 0.2409 - val_loss: 0.2508 - val_lambda_111_loss: 0.2725 - val_lambda_116_loss: 0.2508\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2417 - lambda_111_loss: 0.2692 - lambda_116_loss: 0.2417 - val_loss: 0.2418 - val_lambda_111_loss: 0.2711 - val_lambda_116_loss: 0.2418\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2383 - lambda_111_loss: 0.2654 - lambda_116_loss: 0.2383 - val_loss: 0.2503 - val_lambda_111_loss: 0.2747 - val_lambda_116_loss: 0.2503\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2386 - lambda_111_loss: 0.2661 - lambda_116_loss: 0.2386 - val_loss: 0.2534 - val_lambda_111_loss: 0.2788 - val_lambda_116_loss: 0.2534\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2382 - lambda_111_loss: 0.2655 - lambda_116_loss: 0.2382 - val_loss: 0.2411 - val_lambda_111_loss: 0.2656 - val_lambda_116_loss: 0.2411\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.2370 - lambda_111_loss: 0.2644 - lambda_116_loss: 0.2370 - val_loss: 0.2474 - val_lambda_111_loss: 0.2697 - val_lambda_116_loss: 0.2474\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2365 - lambda_111_loss: 0.2633 - lambda_116_loss: 0.2365 - val_loss: 0.2388 - val_lambda_111_loss: 0.2632 - val_lambda_116_loss: 0.2388\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2365 - lambda_111_loss: 0.2640 - lambda_116_loss: 0.2365 - val_loss: 0.2590 - val_lambda_111_loss: 0.2895 - val_lambda_116_loss: 0.2590\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2339 - lambda_111_loss: 0.2611 - lambda_116_loss: 0.2339 - val_loss: 0.2557 - val_lambda_111_loss: 0.2787 - val_lambda_116_loss: 0.2557\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2357 - lambda_111_loss: 0.2635 - lambda_116_loss: 0.2357 - val_loss: 0.2404 - val_lambda_111_loss: 0.2689 - val_lambda_116_loss: 0.2404\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2339 - lambda_111_loss: 0.2610 - lambda_116_loss: 0.2339 - val_loss: 0.2426 - val_lambda_111_loss: 0.2645 - val_lambda_116_loss: 0.2426\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2350 - lambda_111_loss: 0.2625 - lambda_116_loss: 0.2350 - val_loss: 0.2332 - val_lambda_111_loss: 0.2562 - val_lambda_116_loss: 0.2332\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2348 - lambda_111_loss: 0.2622 - lambda_116_loss: 0.2348 - val_loss: 0.2410 - val_lambda_111_loss: 0.2669 - val_lambda_116_loss: 0.2410\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2319 - lambda_111_loss: 0.2591 - lambda_116_loss: 0.2319 - val_loss: 0.2617 - val_lambda_111_loss: 0.2870 - val_lambda_116_loss: 0.2617\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2328 - lambda_111_loss: 0.2602 - lambda_116_loss: 0.2328 - val_loss: 0.2415 - val_lambda_111_loss: 0.2684 - val_lambda_116_loss: 0.2415\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2308 - lambda_111_loss: 0.2582 - lambda_116_loss: 0.2308 - val_loss: 0.2436 - val_lambda_111_loss: 0.2687 - val_lambda_116_loss: 0.2436\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2334 - lambda_111_loss: 0.2609 - lambda_116_loss: 0.2334 - val_loss: 0.2479 - val_lambda_111_loss: 0.2755 - val_lambda_116_loss: 0.2479\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2313 - lambda_111_loss: 0.2584 - lambda_116_loss: 0.2313 - val_loss: 0.2543 - val_lambda_111_loss: 0.2822 - val_lambda_116_loss: 0.2543\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2279 - lambda_111_loss: 0.2551 - lambda_116_loss: 0.2279 - val_loss: 0.2503 - val_lambda_111_loss: 0.2730 - val_lambda_116_loss: 0.2503\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2303 - lambda_111_loss: 0.2578 - lambda_116_loss: 0.2303 - val_loss: 0.2419 - val_lambda_111_loss: 0.2650 - val_lambda_116_loss: 0.2419\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2310 - lambda_111_loss: 0.2582 - lambda_116_loss: 0.2310 - val_loss: 0.2543 - val_lambda_111_loss: 0.2784 - val_lambda_116_loss: 0.2543\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2296 - lambda_111_loss: 0.2570 - lambda_116_loss: 0.2296 - val_loss: 0.2406 - val_lambda_111_loss: 0.2640 - val_lambda_116_loss: 0.2406\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2294 - lambda_111_loss: 0.2567 - lambda_116_loss: 0.2294 - val_loss: 0.2426 - val_lambda_111_loss: 0.2651 - val_lambda_116_loss: 0.2426\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2266 - lambda_111_loss: 0.2537 - lambda_116_loss: 0.2266 - val_loss: 0.2301 - val_lambda_111_loss: 0.2592 - val_lambda_116_loss: 0.2301\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2296 - lambda_111_loss: 0.2572 - lambda_116_loss: 0.2296 - val_loss: 0.2399 - val_lambda_111_loss: 0.2644 - val_lambda_116_loss: 0.2399\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2294 - lambda_111_loss: 0.2570 - lambda_116_loss: 0.2294 - val_loss: 0.2459 - val_lambda_111_loss: 0.2699 - val_lambda_116_loss: 0.2459\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 61s 91ms/step - loss: 0.2273 - lambda_111_loss: 0.2544 - lambda_116_loss: 0.2273 - val_loss: 0.2362 - val_lambda_111_loss: 0.2617 - val_lambda_116_loss: 0.2362\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 61s 91ms/step - loss: 0.2273 - lambda_111_loss: 0.2546 - lambda_116_loss: 0.2273 - val_loss: 0.2390 - val_lambda_111_loss: 0.2653 - val_lambda_116_loss: 0.2390\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2270 - lambda_111_loss: 0.2543 - lambda_116_loss: 0.2270 - val_loss: 0.2472 - val_lambda_111_loss: 0.2755 - val_lambda_116_loss: 0.2472\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2283 - lambda_111_loss: 0.2557 - lambda_116_loss: 0.2283 - val_loss: 0.2425 - val_lambda_111_loss: 0.2657 - val_lambda_116_loss: 0.2425\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2267 - lambda_111_loss: 0.2538 - lambda_116_loss: 0.2267 - val_loss: 0.2306 - val_lambda_111_loss: 0.2590 - val_lambda_116_loss: 0.2306\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 61s 91ms/step - loss: 0.2256 - lambda_111_loss: 0.2530 - lambda_116_loss: 0.2256 - val_loss: 0.2372 - val_lambda_111_loss: 0.2640 - val_lambda_116_loss: 0.2372\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2262 - lambda_111_loss: 0.2538 - lambda_116_loss: 0.2262 - val_loss: 0.2385 - val_lambda_111_loss: 0.2650 - val_lambda_116_loss: 0.2385\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2253 - lambda_111_loss: 0.2526 - lambda_116_loss: 0.2253 - val_loss: 0.2362 - val_lambda_111_loss: 0.2595 - val_lambda_116_loss: 0.2362\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2258 - lambda_111_loss: 0.2533 - lambda_116_loss: 0.2258 - val_loss: 0.2513 - val_lambda_111_loss: 0.2735 - val_lambda_116_loss: 0.2513\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2263 - lambda_111_loss: 0.2537 - lambda_116_loss: 0.2263 - val_loss: 0.2377 - val_lambda_111_loss: 0.2682 - val_lambda_116_loss: 0.2377\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2261 - lambda_111_loss: 0.2536 - lambda_116_loss: 0.2261 - val_loss: 0.2481 - val_lambda_111_loss: 0.2726 - val_lambda_116_loss: 0.2481\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2268 - lambda_111_loss: 0.2541 - lambda_116_loss: 0.2268 - val_loss: 0.2403 - val_lambda_111_loss: 0.2625 - val_lambda_116_loss: 0.2403\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2253 - lambda_111_loss: 0.2525 - lambda_116_loss: 0.2253 - val_loss: 0.2556 - val_lambda_111_loss: 0.2844 - val_lambda_116_loss: 0.2556\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 61s 91ms/step - loss: 0.2258 - lambda_111_loss: 0.2529 - lambda_116_loss: 0.2258 - val_loss: 0.2400 - val_lambda_111_loss: 0.2615 - val_lambda_116_loss: 0.2400\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 61s 91ms/step - loss: 0.2244 - lambda_111_loss: 0.2516 - lambda_116_loss: 0.2244 - val_loss: 0.2483 - val_lambda_111_loss: 0.2783 - val_lambda_116_loss: 0.2483\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 256, 256, 48) 912         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 256, 256, 2)  98          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 256, 256, 2)  0           conv2d_60[0][0]                  \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 256, 256, 2)  0           add_19[0][0]                     \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 256, 256, 2)  0           multiply_10[0][0]                \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 256, 256, 48) 912         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 256, 256, 2)  98          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 256, 256, 2)  0           conv2d_66[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 256, 256, 2)  0           add_21[0][0]                     \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 256, 256, 2)  0           multiply_11[0][0]                \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 256, 256, 2)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 256, 256, 1)  0           lambda_121[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kk_gaussian_20.hdf5\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.3914 - lambda_121_loss: 0.4638 - lambda_126_loss: 0.3914 - val_loss: 0.3366 - val_lambda_121_loss: 0.4116 - val_lambda_126_loss: 0.3366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.3287 - lambda_121_loss: 0.3999 - lambda_126_loss: 0.3287 - val_loss: 0.3080 - val_lambda_121_loss: 0.3795 - val_lambda_126_loss: 0.3080\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.3141 - lambda_121_loss: 0.3847 - lambda_126_loss: 0.3141 - val_loss: 0.3020 - val_lambda_121_loss: 0.3749 - val_lambda_126_loss: 0.3020\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.3038 - lambda_121_loss: 0.3726 - lambda_126_loss: 0.3038 - val_loss: 0.3015 - val_lambda_121_loss: 0.3743 - val_lambda_126_loss: 0.3015\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2991 - lambda_121_loss: 0.3677 - lambda_126_loss: 0.2991 - val_loss: 0.2882 - val_lambda_121_loss: 0.3559 - val_lambda_126_loss: 0.2882\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2917 - lambda_121_loss: 0.3591 - lambda_126_loss: 0.2917 - val_loss: 0.2786 - val_lambda_121_loss: 0.3444 - val_lambda_126_loss: 0.2786\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2869 - lambda_121_loss: 0.3534 - lambda_126_loss: 0.2869 - val_loss: 0.2677 - val_lambda_121_loss: 0.3388 - val_lambda_126_loss: 0.2677\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2839 - lambda_121_loss: 0.3502 - lambda_126_loss: 0.2839 - val_loss: 0.2770 - val_lambda_121_loss: 0.3390 - val_lambda_126_loss: 0.2770\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2798 - lambda_121_loss: 0.3457 - lambda_126_loss: 0.2798 - val_loss: 0.2698 - val_lambda_121_loss: 0.3351 - val_lambda_126_loss: 0.2698\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2782 - lambda_121_loss: 0.3441 - lambda_126_loss: 0.2782 - val_loss: 0.2801 - val_lambda_121_loss: 0.3487 - val_lambda_126_loss: 0.2801\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2790 - lambda_121_loss: 0.3446 - lambda_126_loss: 0.2790 - val_loss: 0.2711 - val_lambda_121_loss: 0.3335 - val_lambda_126_loss: 0.2711\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2743 - lambda_121_loss: 0.3391 - lambda_126_loss: 0.2743 - val_loss: 0.2620 - val_lambda_121_loss: 0.3276 - val_lambda_126_loss: 0.2620\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2748 - lambda_121_loss: 0.3400 - lambda_126_loss: 0.2748 - val_loss: 0.2632 - val_lambda_121_loss: 0.3290 - val_lambda_126_loss: 0.2632\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2698 - lambda_121_loss: 0.3343 - lambda_126_loss: 0.2698 - val_loss: 0.2562 - val_lambda_121_loss: 0.3219 - val_lambda_126_loss: 0.2562\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2684 - lambda_121_loss: 0.3332 - lambda_126_loss: 0.2684 - val_loss: 0.2604 - val_lambda_121_loss: 0.3245 - val_lambda_126_loss: 0.2604\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.2677 - lambda_121_loss: 0.3323 - lambda_126_loss: 0.2677 - val_loss: 0.2557 - val_lambda_121_loss: 0.3237 - val_lambda_126_loss: 0.2557\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2684 - lambda_121_loss: 0.3329 - lambda_126_loss: 0.2684 - val_loss: 0.2602 - val_lambda_121_loss: 0.3277 - val_lambda_126_loss: 0.2602\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2655 - lambda_121_loss: 0.3298 - lambda_126_loss: 0.2655 - val_loss: 0.2545 - val_lambda_121_loss: 0.3143 - val_lambda_126_loss: 0.2545\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2655 - lambda_121_loss: 0.3291 - lambda_126_loss: 0.2655 - val_loss: 0.2596 - val_lambda_121_loss: 0.3230 - val_lambda_126_loss: 0.2596\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2608 - lambda_121_loss: 0.3248 - lambda_126_loss: 0.2608 - val_loss: 0.2513 - val_lambda_121_loss: 0.3143 - val_lambda_126_loss: 0.2513\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2617 - lambda_121_loss: 0.3253 - lambda_126_loss: 0.2617 - val_loss: 0.2563 - val_lambda_121_loss: 0.3154 - val_lambda_126_loss: 0.2563\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2615 - lambda_121_loss: 0.3249 - lambda_126_loss: 0.2615 - val_loss: 0.2531 - val_lambda_121_loss: 0.3128 - val_lambda_126_loss: 0.2531\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2603 - lambda_121_loss: 0.3238 - lambda_126_loss: 0.2603 - val_loss: 0.2531 - val_lambda_121_loss: 0.3154 - val_lambda_126_loss: 0.2531\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2580 - lambda_121_loss: 0.3213 - lambda_126_loss: 0.2580 - val_loss: 0.2463 - val_lambda_121_loss: 0.3111 - val_lambda_126_loss: 0.2463\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.2586 - lambda_121_loss: 0.3222 - lambda_126_loss: 0.2586 - val_loss: 0.2495 - val_lambda_121_loss: 0.3145 - val_lambda_126_loss: 0.2495\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2603 - lambda_121_loss: 0.3241 - lambda_126_loss: 0.2603 - val_loss: 0.2467 - val_lambda_121_loss: 0.3117 - val_lambda_126_loss: 0.2467\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2569 - lambda_121_loss: 0.3202 - lambda_126_loss: 0.2569 - val_loss: 0.2491 - val_lambda_121_loss: 0.3115 - val_lambda_126_loss: 0.2491\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2570 - lambda_121_loss: 0.3200 - lambda_126_loss: 0.2570 - val_loss: 0.2522 - val_lambda_121_loss: 0.3185 - val_lambda_126_loss: 0.2522\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2549 - lambda_121_loss: 0.3179 - lambda_126_loss: 0.2549 - val_loss: 0.2478 - val_lambda_121_loss: 0.3117 - val_lambda_126_loss: 0.2478\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2554 - lambda_121_loss: 0.3183 - lambda_126_loss: 0.2554 - val_loss: 0.2439 - val_lambda_121_loss: 0.3070 - val_lambda_126_loss: 0.2439\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2520 - lambda_121_loss: 0.3152 - lambda_126_loss: 0.2520 - val_loss: 0.2452 - val_lambda_121_loss: 0.3076 - val_lambda_126_loss: 0.2452\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2535 - lambda_121_loss: 0.3162 - lambda_126_loss: 0.2535 - val_loss: 0.2462 - val_lambda_121_loss: 0.3113 - val_lambda_126_loss: 0.2462\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2510 - lambda_121_loss: 0.3142 - lambda_126_loss: 0.2510 - val_loss: 0.2404 - val_lambda_121_loss: 0.3016 - val_lambda_126_loss: 0.2404\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2534 - lambda_121_loss: 0.3158 - lambda_126_loss: 0.2534 - val_loss: 0.2402 - val_lambda_121_loss: 0.3003 - val_lambda_126_loss: 0.2402\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2523 - lambda_121_loss: 0.3154 - lambda_126_loss: 0.2523 - val_loss: 0.2385 - val_lambda_121_loss: 0.2974 - val_lambda_126_loss: 0.2385\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2502 - lambda_121_loss: 0.3127 - lambda_126_loss: 0.2502 - val_loss: 0.2429 - val_lambda_121_loss: 0.3060 - val_lambda_126_loss: 0.2429\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2498 - lambda_121_loss: 0.3121 - lambda_126_loss: 0.2498 - val_loss: 0.2417 - val_lambda_121_loss: 0.3032 - val_lambda_126_loss: 0.2417\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2506 - lambda_121_loss: 0.3133 - lambda_126_loss: 0.2506 - val_loss: 0.2451 - val_lambda_121_loss: 0.3059 - val_lambda_126_loss: 0.2451\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2487 - lambda_121_loss: 0.3117 - lambda_126_loss: 0.2487 - val_loss: 0.2386 - val_lambda_121_loss: 0.3051 - val_lambda_126_loss: 0.2386\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2488 - lambda_121_loss: 0.3108 - lambda_126_loss: 0.2488 - val_loss: 0.2383 - val_lambda_121_loss: 0.3039 - val_lambda_126_loss: 0.2383\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.2483 - lambda_121_loss: 0.3108 - lambda_126_loss: 0.2483 - val_loss: 0.2377 - val_lambda_121_loss: 0.3010 - val_lambda_126_loss: 0.2377\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2459 - lambda_121_loss: 0.3088 - lambda_126_loss: 0.2459 - val_loss: 0.2367 - val_lambda_121_loss: 0.2964 - val_lambda_126_loss: 0.2367\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2484 - lambda_121_loss: 0.3115 - lambda_126_loss: 0.2484 - val_loss: 0.2411 - val_lambda_121_loss: 0.3045 - val_lambda_126_loss: 0.2411\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2494 - lambda_121_loss: 0.3114 - lambda_126_loss: 0.2494 - val_loss: 0.2375 - val_lambda_121_loss: 0.2977 - val_lambda_126_loss: 0.2375\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2471 - lambda_121_loss: 0.3095 - lambda_126_loss: 0.2471 - val_loss: 0.2402 - val_lambda_121_loss: 0.3082 - val_lambda_126_loss: 0.2402\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2448 - lambda_121_loss: 0.3072 - lambda_126_loss: 0.2448 - val_loss: 0.2386 - val_lambda_121_loss: 0.3026 - val_lambda_126_loss: 0.2386\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.2447 - lambda_121_loss: 0.3067 - lambda_126_loss: 0.2447 - val_loss: 0.2387 - val_lambda_121_loss: 0.3050 - val_lambda_126_loss: 0.2387\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2451 - lambda_121_loss: 0.3073 - lambda_126_loss: 0.2451 - val_loss: 0.2380 - val_lambda_121_loss: 0.3013 - val_lambda_126_loss: 0.2380\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2451 - lambda_121_loss: 0.3074 - lambda_126_loss: 0.2451 - val_loss: 0.2358 - val_lambda_121_loss: 0.3006 - val_lambda_126_loss: 0.2358\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.2434 - lambda_121_loss: 0.3052 - lambda_126_loss: 0.2434 - val_loss: 0.2418 - val_lambda_121_loss: 0.3086 - val_lambda_126_loss: 0.2418\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 256, 256, 2)  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 256, 256, 48) 912         lambda_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 256, 256, 2)  98          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 256, 256, 2)  0           conv2d_72[0][0]                  \n",
      "                                                                 lambda_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 256, 256, 2)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 256, 256, 2)  0           lambda_136[0][0]                 \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 256, 256, 2)  0           multiply_12[0][0]                \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 256, 256, 2)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 256, 256, 48) 912         lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 256, 256, 2)  98          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 256, 256, 2)  0           conv2d_78[0][0]                  \n",
      "                                                                 lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 256, 256, 2)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 256, 256, 2)  0           lambda_146[0][0]                 \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 256, 256, 2)  0           multiply_13[0][0]                \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 256, 256, 2)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 256, 256, 1)  0           lambda_151[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 68s 102ms/step - loss: 0.2436 - lambda_151_loss: 0.2761 - lambda_156_loss: 0.2436 - val_loss: 0.1940 - val_lambda_151_loss: 0.2135 - val_lambda_156_loss: 0.1940\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1841 - lambda_151_loss: 0.2143 - lambda_156_loss: 0.1841 - val_loss: 0.1930 - val_lambda_151_loss: 0.2371 - val_lambda_156_loss: 0.1930\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1715 - lambda_151_loss: 0.2015 - lambda_156_loss: 0.1715 - val_loss: 0.1639 - val_lambda_151_loss: 0.1927 - val_lambda_156_loss: 0.1639\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1609 - lambda_151_loss: 0.1909 - lambda_156_loss: 0.1609 - val_loss: 0.1515 - val_lambda_151_loss: 0.1794 - val_lambda_156_loss: 0.1515\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1559 - lambda_151_loss: 0.1850 - lambda_156_loss: 0.1559 - val_loss: 0.1573 - val_lambda_151_loss: 0.1875 - val_lambda_156_loss: 0.1573\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1526 - lambda_151_loss: 0.1819 - lambda_156_loss: 0.1526 - val_loss: 0.1550 - val_lambda_151_loss: 0.1807 - val_lambda_156_loss: 0.1550\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1501 - lambda_151_loss: 0.1794 - lambda_156_loss: 0.1501 - val_loss: 0.1773 - val_lambda_151_loss: 0.2077 - val_lambda_156_loss: 0.1773\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1487 - lambda_151_loss: 0.1775 - lambda_156_loss: 0.1487 - val_loss: 0.1528 - val_lambda_151_loss: 0.1815 - val_lambda_156_loss: 0.1528\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1479 - lambda_151_loss: 0.1776 - lambda_156_loss: 0.1479 - val_loss: 0.1468 - val_lambda_151_loss: 0.1873 - val_lambda_156_loss: 0.1468\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1450 - lambda_151_loss: 0.1738 - lambda_156_loss: 0.1450 - val_loss: 0.1530 - val_lambda_151_loss: 0.1960 - val_lambda_156_loss: 0.1530\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1411 - lambda_151_loss: 0.1705 - lambda_156_loss: 0.1411 - val_loss: 0.1471 - val_lambda_151_loss: 0.1790 - val_lambda_156_loss: 0.1471\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1433 - lambda_151_loss: 0.1721 - lambda_156_loss: 0.1433 - val_loss: 0.1467 - val_lambda_151_loss: 0.1731 - val_lambda_156_loss: 0.1467\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1391 - lambda_151_loss: 0.1675 - lambda_156_loss: 0.1391 - val_loss: 0.1507 - val_lambda_151_loss: 0.1803 - val_lambda_156_loss: 0.1507\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1400 - lambda_151_loss: 0.1683 - lambda_156_loss: 0.1400 - val_loss: 0.1502 - val_lambda_151_loss: 0.1830 - val_lambda_156_loss: 0.1502\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1384 - lambda_151_loss: 0.1669 - lambda_156_loss: 0.1384 - val_loss: 0.1577 - val_lambda_151_loss: 0.1968 - val_lambda_156_loss: 0.1577\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1380 - lambda_151_loss: 0.1667 - lambda_156_loss: 0.1380 - val_loss: 0.1474 - val_lambda_151_loss: 0.1829 - val_lambda_156_loss: 0.1474\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1377 - lambda_151_loss: 0.1655 - lambda_156_loss: 0.1377 - val_loss: 0.1383 - val_lambda_151_loss: 0.1719 - val_lambda_156_loss: 0.1383\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1359 - lambda_151_loss: 0.1637 - lambda_156_loss: 0.1359 - val_loss: 0.1460 - val_lambda_151_loss: 0.1797 - val_lambda_156_loss: 0.1460\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1359 - lambda_151_loss: 0.1633 - lambda_156_loss: 0.1359 - val_loss: 0.1448 - val_lambda_151_loss: 0.1831 - val_lambda_156_loss: 0.1448\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1357 - lambda_151_loss: 0.1633 - lambda_156_loss: 0.1357 - val_loss: 0.1384 - val_lambda_151_loss: 0.1642 - val_lambda_156_loss: 0.1384\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.1352 - lambda_151_loss: 0.1626 - lambda_156_loss: 0.1352 - val_loss: 0.1403 - val_lambda_151_loss: 0.1745 - val_lambda_156_loss: 0.1403\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1336 - lambda_151_loss: 0.1605 - lambda_156_loss: 0.1336 - val_loss: 0.1391 - val_lambda_151_loss: 0.1654 - val_lambda_156_loss: 0.1391\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.1333 - lambda_151_loss: 0.1602 - lambda_156_loss: 0.1333 - val_loss: 0.1451 - val_lambda_151_loss: 0.1781 - val_lambda_156_loss: 0.1451\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1344 - lambda_151_loss: 0.1615 - lambda_156_loss: 0.1344 - val_loss: 0.1385 - val_lambda_151_loss: 0.1700 - val_lambda_156_loss: 0.1385\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1330 - lambda_151_loss: 0.1599 - lambda_156_loss: 0.1330 - val_loss: 0.1518 - val_lambda_151_loss: 0.1842 - val_lambda_156_loss: 0.1518\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1319 - lambda_151_loss: 0.1582 - lambda_156_loss: 0.1319 - val_loss: 0.1387 - val_lambda_151_loss: 0.1677 - val_lambda_156_loss: 0.1387\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1320 - lambda_151_loss: 0.1584 - lambda_156_loss: 0.1320 - val_loss: 0.1355 - val_lambda_151_loss: 0.1668 - val_lambda_156_loss: 0.1355\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1301 - lambda_151_loss: 0.1562 - lambda_156_loss: 0.1301 - val_loss: 0.1452 - val_lambda_151_loss: 0.1738 - val_lambda_156_loss: 0.1452\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1309 - lambda_151_loss: 0.1569 - lambda_156_loss: 0.1309 - val_loss: 0.1522 - val_lambda_151_loss: 0.1839 - val_lambda_156_loss: 0.1522\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1306 - lambda_151_loss: 0.1564 - lambda_156_loss: 0.1306 - val_loss: 0.1383 - val_lambda_151_loss: 0.1738 - val_lambda_156_loss: 0.1383\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1292 - lambda_151_loss: 0.1552 - lambda_156_loss: 0.1292 - val_loss: 0.1418 - val_lambda_151_loss: 0.1793 - val_lambda_156_loss: 0.1418\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1294 - lambda_151_loss: 0.1551 - lambda_156_loss: 0.1294 - val_loss: 0.1324 - val_lambda_151_loss: 0.1547 - val_lambda_156_loss: 0.1324\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1282 - lambda_151_loss: 0.1537 - lambda_156_loss: 0.1282 - val_loss: 0.1365 - val_lambda_151_loss: 0.1677 - val_lambda_156_loss: 0.1365\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1297 - lambda_151_loss: 0.1555 - lambda_156_loss: 0.1297 - val_loss: 0.1445 - val_lambda_151_loss: 0.1711 - val_lambda_156_loss: 0.1445\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1290 - lambda_151_loss: 0.1543 - lambda_156_loss: 0.1290 - val_loss: 0.1404 - val_lambda_151_loss: 0.1723 - val_lambda_156_loss: 0.1404\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1283 - lambda_151_loss: 0.1538 - lambda_156_loss: 0.1283 - val_loss: 0.1491 - val_lambda_151_loss: 0.1793 - val_lambda_156_loss: 0.1491\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1296 - lambda_151_loss: 0.1548 - lambda_156_loss: 0.1296 - val_loss: 0.1430 - val_lambda_151_loss: 0.1732 - val_lambda_156_loss: 0.1430\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1284 - lambda_151_loss: 0.1535 - lambda_156_loss: 0.1284 - val_loss: 0.1465 - val_lambda_151_loss: 0.1797 - val_lambda_156_loss: 0.1465\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1274 - lambda_151_loss: 0.1522 - lambda_156_loss: 0.1274 - val_loss: 0.1377 - val_lambda_151_loss: 0.1673 - val_lambda_156_loss: 0.1377\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1252 - lambda_151_loss: 0.1497 - lambda_156_loss: 0.1252 - val_loss: 0.1451 - val_lambda_151_loss: 0.1764 - val_lambda_156_loss: 0.1451\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1269 - lambda_151_loss: 0.1516 - lambda_156_loss: 0.1269 - val_loss: 0.1342 - val_lambda_151_loss: 0.1684 - val_lambda_156_loss: 0.1342\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1267 - lambda_151_loss: 0.1514 - lambda_156_loss: 0.1267 - val_loss: 0.1497 - val_lambda_151_loss: 0.1803 - val_lambda_156_loss: 0.1497\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1274 - lambda_151_loss: 0.1523 - lambda_156_loss: 0.1274 - val_loss: 0.1661 - val_lambda_151_loss: 0.2014 - val_lambda_156_loss: 0.1661\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1268 - lambda_151_loss: 0.1509 - lambda_156_loss: 0.1268 - val_loss: 0.1307 - val_lambda_151_loss: 0.1628 - val_lambda_156_loss: 0.1307\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1251 - lambda_151_loss: 0.1491 - lambda_156_loss: 0.1251 - val_loss: 0.1304 - val_lambda_151_loss: 0.1566 - val_lambda_156_loss: 0.1304\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1248 - lambda_151_loss: 0.1488 - lambda_156_loss: 0.1248 - val_loss: 0.1347 - val_lambda_151_loss: 0.1620 - val_lambda_156_loss: 0.1347\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1259 - lambda_151_loss: 0.1501 - lambda_156_loss: 0.1259 - val_loss: 0.1319 - val_lambda_151_loss: 0.1575 - val_lambda_156_loss: 0.1319\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1280 - lambda_151_loss: 0.1531 - lambda_156_loss: 0.1280 - val_loss: 0.1349 - val_lambda_151_loss: 0.1633 - val_lambda_156_loss: 0.1349\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1258 - lambda_151_loss: 0.1500 - lambda_156_loss: 0.1258 - val_loss: 0.1371 - val_lambda_151_loss: 0.1609 - val_lambda_156_loss: 0.1371\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1254 - lambda_151_loss: 0.1494 - lambda_156_loss: 0.1254 - val_loss: 0.1354 - val_lambda_151_loss: 0.1673 - val_lambda_156_loss: 0.1354\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)             (None, 256, 256, 2)  0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 256, 256, 48) 912         lambda_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 256, 256, 2)  98          conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 256, 256, 2)  0           conv2d_84[0][0]                  \n",
      "                                                                 lambda_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)             (None, 256, 256, 2)  0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 256, 256, 2)  0           lambda_166[0][0]                 \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 256, 256, 2)  0           multiply_14[0][0]                \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 256, 256, 48) 912         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 256, 256, 2)  98          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 256, 256, 2)  0           conv2d_90[0][0]                  \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 256, 256, 2)  0           add_29[0][0]                     \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 256, 256, 2)  0           multiply_15[0][0]                \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)             (None, 256, 256, 2)  0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)             (None, 256, 256, 1)  0           lambda_171[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 67s 100ms/step - loss: 0.2626 - lambda_171_loss: 0.3063 - lambda_176_loss: 0.2626 - val_loss: 0.2192 - val_lambda_171_loss: 0.2621 - val_lambda_176_loss: 0.2192\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.2105 - lambda_171_loss: 0.2532 - lambda_176_loss: 0.2105 - val_loss: 0.2018 - val_lambda_171_loss: 0.2388 - val_lambda_176_loss: 0.2018\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1971 - lambda_171_loss: 0.2387 - lambda_176_loss: 0.1971 - val_loss: 0.1926 - val_lambda_171_loss: 0.2341 - val_lambda_176_loss: 0.1926\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1905 - lambda_171_loss: 0.2319 - lambda_176_loss: 0.1905 - val_loss: 0.1886 - val_lambda_171_loss: 0.2285 - val_lambda_176_loss: 0.1886\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1854 - lambda_171_loss: 0.2264 - lambda_176_loss: 0.1854 - val_loss: 0.1781 - val_lambda_171_loss: 0.2271 - val_lambda_176_loss: 0.1781\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1827 - lambda_171_loss: 0.2234 - lambda_176_loss: 0.1827 - val_loss: 0.1791 - val_lambda_171_loss: 0.2164 - val_lambda_176_loss: 0.1791\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1779 - lambda_171_loss: 0.2182 - lambda_176_loss: 0.1779 - val_loss: 0.1733 - val_lambda_171_loss: 0.2104 - val_lambda_176_loss: 0.1733\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1751 - lambda_171_loss: 0.2156 - lambda_176_loss: 0.1751 - val_loss: 0.1931 - val_lambda_171_loss: 0.2328 - val_lambda_176_loss: 0.1931\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1721 - lambda_171_loss: 0.2117 - lambda_176_loss: 0.1721 - val_loss: 0.1768 - val_lambda_171_loss: 0.2192 - val_lambda_176_loss: 0.1768\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1708 - lambda_171_loss: 0.2103 - lambda_176_loss: 0.1708 - val_loss: 0.1680 - val_lambda_171_loss: 0.2041 - val_lambda_176_loss: 0.1680\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1699 - lambda_171_loss: 0.2096 - lambda_176_loss: 0.1699 - val_loss: 0.1739 - val_lambda_171_loss: 0.2073 - val_lambda_176_loss: 0.1739\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1667 - lambda_171_loss: 0.2054 - lambda_176_loss: 0.1667 - val_loss: 0.1678 - val_lambda_171_loss: 0.2060 - val_lambda_176_loss: 0.1678\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1667 - lambda_171_loss: 0.2056 - lambda_176_loss: 0.1667 - val_loss: 0.1664 - val_lambda_171_loss: 0.2024 - val_lambda_176_loss: 0.1664\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1637 - lambda_171_loss: 0.2026 - lambda_176_loss: 0.1637 - val_loss: 0.1730 - val_lambda_171_loss: 0.2158 - val_lambda_176_loss: 0.1730\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1637 - lambda_171_loss: 0.2026 - lambda_176_loss: 0.1637 - val_loss: 0.1664 - val_lambda_171_loss: 0.2146 - val_lambda_176_loss: 0.1664\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1625 - lambda_171_loss: 0.2014 - lambda_176_loss: 0.1625 - val_loss: 0.1679 - val_lambda_171_loss: 0.1977 - val_lambda_176_loss: 0.1679\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1605 - lambda_171_loss: 0.1989 - lambda_176_loss: 0.1605 - val_loss: 0.1710 - val_lambda_171_loss: 0.2010 - val_lambda_176_loss: 0.1710\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1607 - lambda_171_loss: 0.1994 - lambda_176_loss: 0.1607 - val_loss: 0.1637 - val_lambda_171_loss: 0.1901 - val_lambda_176_loss: 0.1637\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1584 - lambda_171_loss: 0.1969 - lambda_176_loss: 0.1584 - val_loss: 0.1633 - val_lambda_171_loss: 0.1974 - val_lambda_176_loss: 0.1633\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1573 - lambda_171_loss: 0.1955 - lambda_176_loss: 0.1573 - val_loss: 0.1627 - val_lambda_171_loss: 0.1977 - val_lambda_176_loss: 0.1627\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1562 - lambda_171_loss: 0.1943 - lambda_176_loss: 0.1562 - val_loss: 0.1673 - val_lambda_171_loss: 0.1980 - val_lambda_176_loss: 0.1673\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1570 - lambda_171_loss: 0.1950 - lambda_176_loss: 0.1570 - val_loss: 0.1586 - val_lambda_171_loss: 0.1912 - val_lambda_176_loss: 0.1586\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1561 - lambda_171_loss: 0.1944 - lambda_176_loss: 0.1561 - val_loss: 0.1527 - val_lambda_171_loss: 0.1857 - val_lambda_176_loss: 0.1527\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1558 - lambda_171_loss: 0.1937 - lambda_176_loss: 0.1558 - val_loss: 0.1600 - val_lambda_171_loss: 0.1938 - val_lambda_176_loss: 0.1600\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1543 - lambda_171_loss: 0.1923 - lambda_176_loss: 0.1543 - val_loss: 0.1586 - val_lambda_171_loss: 0.1927 - val_lambda_176_loss: 0.1586\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1542 - lambda_171_loss: 0.1919 - lambda_176_loss: 0.1542 - val_loss: 0.1569 - val_lambda_171_loss: 0.1892 - val_lambda_176_loss: 0.1569\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1523 - lambda_171_loss: 0.1896 - lambda_176_loss: 0.1523 - val_loss: 0.1647 - val_lambda_171_loss: 0.2004 - val_lambda_176_loss: 0.1647\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1521 - lambda_171_loss: 0.1897 - lambda_176_loss: 0.1521 - val_loss: 0.1520 - val_lambda_171_loss: 0.1861 - val_lambda_176_loss: 0.1520\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1517 - lambda_171_loss: 0.1889 - lambda_176_loss: 0.1517 - val_loss: 0.1587 - val_lambda_171_loss: 0.1917 - val_lambda_176_loss: 0.1587\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1525 - lambda_171_loss: 0.1901 - lambda_176_loss: 0.1525 - val_loss: 0.1610 - val_lambda_171_loss: 0.1899 - val_lambda_176_loss: 0.1610\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1508 - lambda_171_loss: 0.1882 - lambda_176_loss: 0.1508 - val_loss: 0.1534 - val_lambda_171_loss: 0.1824 - val_lambda_176_loss: 0.1534\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1502 - lambda_171_loss: 0.1875 - lambda_176_loss: 0.1502 - val_loss: 0.1641 - val_lambda_171_loss: 0.1975 - val_lambda_176_loss: 0.1641\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1497 - lambda_171_loss: 0.1872 - lambda_176_loss: 0.1497 - val_loss: 0.1581 - val_lambda_171_loss: 0.1915 - val_lambda_176_loss: 0.1581\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1496 - lambda_171_loss: 0.1869 - lambda_176_loss: 0.1496 - val_loss: 0.1516 - val_lambda_171_loss: 0.1856 - val_lambda_176_loss: 0.1516\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1488 - lambda_171_loss: 0.1857 - lambda_176_loss: 0.1488 - val_loss: 0.1512 - val_lambda_171_loss: 0.1890 - val_lambda_176_loss: 0.1512\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1484 - lambda_171_loss: 0.1858 - lambda_176_loss: 0.1484 - val_loss: 0.1602 - val_lambda_171_loss: 0.1940 - val_lambda_176_loss: 0.1602\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1483 - lambda_171_loss: 0.1851 - lambda_176_loss: 0.1483 - val_loss: 0.1542 - val_lambda_171_loss: 0.1848 - val_lambda_176_loss: 0.1542\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1476 - lambda_171_loss: 0.1851 - lambda_176_loss: 0.1476 - val_loss: 0.1549 - val_lambda_171_loss: 0.1858 - val_lambda_176_loss: 0.1549\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1480 - lambda_171_loss: 0.1849 - lambda_176_loss: 0.1480 - val_loss: 0.1549 - val_lambda_171_loss: 0.1825 - val_lambda_176_loss: 0.1549\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1471 - lambda_171_loss: 0.1839 - lambda_176_loss: 0.1471 - val_loss: 0.1616 - val_lambda_171_loss: 0.1957 - val_lambda_176_loss: 0.1616\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1467 - lambda_171_loss: 0.1830 - lambda_176_loss: 0.1467 - val_loss: 0.1543 - val_lambda_171_loss: 0.1886 - val_lambda_176_loss: 0.1543\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1456 - lambda_171_loss: 0.1825 - lambda_176_loss: 0.1456 - val_loss: 0.1498 - val_lambda_171_loss: 0.1803 - val_lambda_176_loss: 0.1498\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1457 - lambda_171_loss: 0.1820 - lambda_176_loss: 0.1457 - val_loss: 0.1504 - val_lambda_171_loss: 0.1834 - val_lambda_176_loss: 0.1504\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1455 - lambda_171_loss: 0.1818 - lambda_176_loss: 0.1455 - val_loss: 0.1545 - val_lambda_171_loss: 0.1897 - val_lambda_176_loss: 0.1545\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1451 - lambda_171_loss: 0.1814 - lambda_176_loss: 0.1451 - val_loss: 0.1481 - val_lambda_171_loss: 0.1850 - val_lambda_176_loss: 0.1481\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1455 - lambda_171_loss: 0.1827 - lambda_176_loss: 0.1455 - val_loss: 0.1523 - val_lambda_171_loss: 0.1868 - val_lambda_176_loss: 0.1523\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1446 - lambda_171_loss: 0.1810 - lambda_176_loss: 0.1446 - val_loss: 0.1435 - val_lambda_171_loss: 0.1803 - val_lambda_176_loss: 0.1435\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1445 - lambda_171_loss: 0.1806 - lambda_176_loss: 0.1445 - val_loss: 0.1507 - val_lambda_171_loss: 0.1812 - val_lambda_176_loss: 0.1507\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1446 - lambda_171_loss: 0.1813 - lambda_176_loss: 0.1446 - val_loss: 0.1496 - val_lambda_171_loss: 0.1803 - val_lambda_176_loss: 0.1496\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1432 - lambda_171_loss: 0.1793 - lambda_176_loss: 0.1432 - val_loss: 0.1574 - val_lambda_171_loss: 0.1895 - val_lambda_176_loss: 0.1574\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 256, 256, 48) 912         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 256, 256, 2)  98          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 256, 256, 2)  0           conv2d_96[0][0]                  \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 256, 256, 2)  0           add_31[0][0]                     \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 256, 256, 2)  0           multiply_16[0][0]                \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)             (None, 256, 256, 2)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 256, 256, 48) 912         lambda_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 256, 256, 2)  98          conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 256, 256, 2)  0           conv2d_102[0][0]                 \n",
      "                                                                 lambda_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)             (None, 256, 256, 2)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 256, 256, 2)  0           lambda_186[0][0]                 \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 256, 256, 2)  0           multiply_17[0][0]                \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)             (None, 256, 256, 2)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)             (None, 256, 256, 1)  0           lambda_191[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 67s 100ms/step - loss: 0.2691 - lambda_191_loss: 0.3010 - lambda_196_loss: 0.2691 - val_loss: 0.2452 - val_lambda_191_loss: 0.2862 - val_lambda_196_loss: 0.2452\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2151 - lambda_191_loss: 0.2486 - lambda_196_loss: 0.2151 - val_loss: 0.2024 - val_lambda_191_loss: 0.2337 - val_lambda_196_loss: 0.2024\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1951 - lambda_191_loss: 0.2290 - lambda_196_loss: 0.1951 - val_loss: 0.1904 - val_lambda_191_loss: 0.2201 - val_lambda_196_loss: 0.1904\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1841 - lambda_191_loss: 0.2180 - lambda_196_loss: 0.1841 - val_loss: 0.1726 - val_lambda_191_loss: 0.2063 - val_lambda_196_loss: 0.1726\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1794 - lambda_191_loss: 0.2134 - lambda_196_loss: 0.1794 - val_loss: 0.1695 - val_lambda_191_loss: 0.2013 - val_lambda_196_loss: 0.1695\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1748 - lambda_191_loss: 0.2091 - lambda_196_loss: 0.1748 - val_loss: 0.1658 - val_lambda_191_loss: 0.2015 - val_lambda_196_loss: 0.1658\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1728 - lambda_191_loss: 0.2060 - lambda_196_loss: 0.1728 - val_loss: 0.1687 - val_lambda_191_loss: 0.2077 - val_lambda_196_loss: 0.1687\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1684 - lambda_191_loss: 0.2014 - lambda_196_loss: 0.1684 - val_loss: 0.1615 - val_lambda_191_loss: 0.1892 - val_lambda_196_loss: 0.1615\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1668 - lambda_191_loss: 0.1987 - lambda_196_loss: 0.1668 - val_loss: 0.1641 - val_lambda_191_loss: 0.1968 - val_lambda_196_loss: 0.1641\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1633 - lambda_191_loss: 0.1952 - lambda_196_loss: 0.1633 - val_loss: 0.1655 - val_lambda_191_loss: 0.2035 - val_lambda_196_loss: 0.1655\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1621 - lambda_191_loss: 0.1941 - lambda_196_loss: 0.1621 - val_loss: 0.1691 - val_lambda_191_loss: 0.1998 - val_lambda_196_loss: 0.1691\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1615 - lambda_191_loss: 0.1932 - lambda_196_loss: 0.1615 - val_loss: 0.1631 - val_lambda_191_loss: 0.1939 - val_lambda_196_loss: 0.1631\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1607 - lambda_191_loss: 0.1943 - lambda_196_loss: 0.1607 - val_loss: 0.1580 - val_lambda_191_loss: 0.2006 - val_lambda_196_loss: 0.1580\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1595 - lambda_191_loss: 0.1903 - lambda_196_loss: 0.1595 - val_loss: 0.1536 - val_lambda_191_loss: 0.1830 - val_lambda_196_loss: 0.1536\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1579 - lambda_191_loss: 0.1883 - lambda_196_loss: 0.1579 - val_loss: 0.1576 - val_lambda_191_loss: 0.1938 - val_lambda_196_loss: 0.1576\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1552 - lambda_191_loss: 0.1850 - lambda_196_loss: 0.1552 - val_loss: 0.1538 - val_lambda_191_loss: 0.1897 - val_lambda_196_loss: 0.1538\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1545 - lambda_191_loss: 0.1840 - lambda_196_loss: 0.1545 - val_loss: 0.1497 - val_lambda_191_loss: 0.1840 - val_lambda_196_loss: 0.1497\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1535 - lambda_191_loss: 0.1828 - lambda_196_loss: 0.1535 - val_loss: 0.1550 - val_lambda_191_loss: 0.1937 - val_lambda_196_loss: 0.1550\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1536 - lambda_191_loss: 0.1827 - lambda_196_loss: 0.1536 - val_loss: 0.1514 - val_lambda_191_loss: 0.1873 - val_lambda_196_loss: 0.1514\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1521 - lambda_191_loss: 0.1811 - lambda_196_loss: 0.1521 - val_loss: 0.1540 - val_lambda_191_loss: 0.1892 - val_lambda_196_loss: 0.1540\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1519 - lambda_191_loss: 0.1808 - lambda_196_loss: 0.1519 - val_loss: 0.1505 - val_lambda_191_loss: 0.1791 - val_lambda_196_loss: 0.1505\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1507 - lambda_191_loss: 0.1797 - lambda_196_loss: 0.1507 - val_loss: 0.1460 - val_lambda_191_loss: 0.1873 - val_lambda_196_loss: 0.1460\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1505 - lambda_191_loss: 0.1800 - lambda_196_loss: 0.1505 - val_loss: 0.1471 - val_lambda_191_loss: 0.1769 - val_lambda_196_loss: 0.1471\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1508 - lambda_191_loss: 0.1799 - lambda_196_loss: 0.1508 - val_loss: 0.1499 - val_lambda_191_loss: 0.1753 - val_lambda_196_loss: 0.1499\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1485 - lambda_191_loss: 0.1763 - lambda_196_loss: 0.1485 - val_loss: 0.1508 - val_lambda_191_loss: 0.1847 - val_lambda_196_loss: 0.1508\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1482 - lambda_191_loss: 0.1761 - lambda_196_loss: 0.1482 - val_loss: 0.1467 - val_lambda_191_loss: 0.1685 - val_lambda_196_loss: 0.1467\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1479 - lambda_191_loss: 0.1754 - lambda_196_loss: 0.1479 - val_loss: 0.1440 - val_lambda_191_loss: 0.1697 - val_lambda_196_loss: 0.1440\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1477 - lambda_191_loss: 0.1759 - lambda_196_loss: 0.1477 - val_loss: 0.1528 - val_lambda_191_loss: 0.1811 - val_lambda_196_loss: 0.1528\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1479 - lambda_191_loss: 0.1762 - lambda_196_loss: 0.1479 - val_loss: 0.1460 - val_lambda_191_loss: 0.1718 - val_lambda_196_loss: 0.1460\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1463 - lambda_191_loss: 0.1738 - lambda_196_loss: 0.1463 - val_loss: 0.1491 - val_lambda_191_loss: 0.1707 - val_lambda_196_loss: 0.1491\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1459 - lambda_191_loss: 0.1735 - lambda_196_loss: 0.1459 - val_loss: 0.1450 - val_lambda_191_loss: 0.1756 - val_lambda_196_loss: 0.1450\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1462 - lambda_191_loss: 0.1740 - lambda_196_loss: 0.1462 - val_loss: 0.1495 - val_lambda_191_loss: 0.1753 - val_lambda_196_loss: 0.1495\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1456 - lambda_191_loss: 0.1740 - lambda_196_loss: 0.1456 - val_loss: 0.1468 - val_lambda_191_loss: 0.1732 - val_lambda_196_loss: 0.1468\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1451 - lambda_191_loss: 0.1722 - lambda_196_loss: 0.1451 - val_loss: 0.1430 - val_lambda_191_loss: 0.1688 - val_lambda_196_loss: 0.1430\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1455 - lambda_191_loss: 0.1729 - lambda_196_loss: 0.1455 - val_loss: 0.1423 - val_lambda_191_loss: 0.1675 - val_lambda_196_loss: 0.1423\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1442 - lambda_191_loss: 0.1709 - lambda_196_loss: 0.1442 - val_loss: 0.1469 - val_lambda_191_loss: 0.1742 - val_lambda_196_loss: 0.1469\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1430 - lambda_191_loss: 0.1698 - lambda_196_loss: 0.1430 - val_loss: 0.1448 - val_lambda_191_loss: 0.1703 - val_lambda_196_loss: 0.1448\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1444 - lambda_191_loss: 0.1718 - lambda_196_loss: 0.1444 - val_loss: 0.1430 - val_lambda_191_loss: 0.1722 - val_lambda_196_loss: 0.1430\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1428 - lambda_191_loss: 0.1699 - lambda_196_loss: 0.1428 - val_loss: 0.1392 - val_lambda_191_loss: 0.1690 - val_lambda_196_loss: 0.1392\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1427 - lambda_191_loss: 0.1691 - lambda_196_loss: 0.1427 - val_loss: 0.1433 - val_lambda_191_loss: 0.1682 - val_lambda_196_loss: 0.1433\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1435 - lambda_191_loss: 0.1706 - lambda_196_loss: 0.1435 - val_loss: 0.1407 - val_lambda_191_loss: 0.1714 - val_lambda_196_loss: 0.1407\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1429 - lambda_191_loss: 0.1697 - lambda_196_loss: 0.1429 - val_loss: 0.1392 - val_lambda_191_loss: 0.1705 - val_lambda_196_loss: 0.1392\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1421 - lambda_191_loss: 0.1692 - lambda_196_loss: 0.1421 - val_loss: 0.1452 - val_lambda_191_loss: 0.1680 - val_lambda_196_loss: 0.1452\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1407 - lambda_191_loss: 0.1667 - lambda_196_loss: 0.1407 - val_loss: 0.1441 - val_lambda_191_loss: 0.1705 - val_lambda_196_loss: 0.1441\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1405 - lambda_191_loss: 0.1670 - lambda_196_loss: 0.1405 - val_loss: 0.1467 - val_lambda_191_loss: 0.1742 - val_lambda_196_loss: 0.1467\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1419 - lambda_191_loss: 0.1684 - lambda_196_loss: 0.1419 - val_loss: 0.1405 - val_lambda_191_loss: 0.1687 - val_lambda_196_loss: 0.1405\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1411 - lambda_191_loss: 0.1674 - lambda_196_loss: 0.1411 - val_loss: 0.1407 - val_lambda_191_loss: 0.1687 - val_lambda_196_loss: 0.1407\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1412 - lambda_191_loss: 0.1672 - lambda_196_loss: 0.1412 - val_loss: 0.1403 - val_lambda_191_loss: 0.1687 - val_lambda_196_loss: 0.1403\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1405 - lambda_191_loss: 0.1665 - lambda_196_loss: 0.1405 - val_loss: 0.1440 - val_lambda_191_loss: 0.1830 - val_lambda_196_loss: 0.1440\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1397 - lambda_191_loss: 0.1658 - lambda_196_loss: 0.1397 - val_loss: 0.1408 - val_lambda_191_loss: 0.1702 - val_lambda_196_loss: 0.1408\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 256, 256, 48) 912         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 256, 256, 2)  98          conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 256, 256, 2)  0           conv2d_108[0][0]                 \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 256, 256, 2)  0           add_35[0][0]                     \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 256, 256, 2)  0           multiply_18[0][0]                \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 256, 256, 48) 912         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 256, 256, 2)  98          conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 256, 256, 2)  0           conv2d_114[0][0]                 \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 256, 256, 2)  0           add_37[0][0]                     \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 256, 256, 2)  0           multiply_19[0][0]                \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 256, 256, 48) 912         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 256, 256, 2)  98          conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 256, 256, 2)  0           conv2d_120[0][0]                 \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 256, 256, 2)  0           add_39[0][0]                     \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 256, 256, 2)  0           multiply_20[0][0]                \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)             (None, 256, 256, 2)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)             (None, 256, 256, 1)  0           lambda_201[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkk_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.3793 - lambda_201_loss: 0.4510 - lambda_206_loss: 0.3793 - val_loss: 0.3317 - val_lambda_201_loss: 0.4046 - val_lambda_206_loss: 0.3317\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.3242 - lambda_201_loss: 0.3946 - lambda_206_loss: 0.3242 - val_loss: 0.3027 - val_lambda_201_loss: 0.3677 - val_lambda_206_loss: 0.3027\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.3077 - lambda_201_loss: 0.3762 - lambda_206_loss: 0.3077 - val_loss: 0.2994 - val_lambda_201_loss: 0.3712 - val_lambda_206_loss: 0.2994\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2943 - lambda_201_loss: 0.3615 - lambda_206_loss: 0.2943 - val_loss: 0.2816 - val_lambda_201_loss: 0.3537 - val_lambda_206_loss: 0.2816\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2882 - lambda_201_loss: 0.3544 - lambda_206_loss: 0.2882 - val_loss: 0.2749 - val_lambda_201_loss: 0.3363 - val_lambda_206_loss: 0.2749\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2831 - lambda_201_loss: 0.3487 - lambda_206_loss: 0.2831 - val_loss: 0.2647 - val_lambda_201_loss: 0.3334 - val_lambda_206_loss: 0.2647\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2808 - lambda_201_loss: 0.3459 - lambda_206_loss: 0.2808 - val_loss: 0.2640 - val_lambda_201_loss: 0.3314 - val_lambda_206_loss: 0.2640\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2745 - lambda_201_loss: 0.3397 - lambda_206_loss: 0.2745 - val_loss: 0.2598 - val_lambda_201_loss: 0.3279 - val_lambda_206_loss: 0.2598\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2724 - lambda_201_loss: 0.3374 - lambda_206_loss: 0.2724 - val_loss: 0.2619 - val_lambda_201_loss: 0.3290 - val_lambda_206_loss: 0.2619\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2717 - lambda_201_loss: 0.3363 - lambda_206_loss: 0.2717 - val_loss: 0.2583 - val_lambda_201_loss: 0.3230 - val_lambda_206_loss: 0.2583\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2680 - lambda_201_loss: 0.3320 - lambda_206_loss: 0.2680 - val_loss: 0.2557 - val_lambda_201_loss: 0.3217 - val_lambda_206_loss: 0.2557\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2645 - lambda_201_loss: 0.3281 - lambda_206_loss: 0.2645 - val_loss: 0.2569 - val_lambda_201_loss: 0.3204 - val_lambda_206_loss: 0.2569\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2641 - lambda_201_loss: 0.3275 - lambda_206_loss: 0.2641 - val_loss: 0.2514 - val_lambda_201_loss: 0.3211 - val_lambda_206_loss: 0.2514\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2612 - lambda_201_loss: 0.3241 - lambda_206_loss: 0.2612 - val_loss: 0.2549 - val_lambda_201_loss: 0.3168 - val_lambda_206_loss: 0.2549\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2616 - lambda_201_loss: 0.3244 - lambda_206_loss: 0.2616 - val_loss: 0.2485 - val_lambda_201_loss: 0.3123 - val_lambda_206_loss: 0.2485\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2601 - lambda_201_loss: 0.3235 - lambda_206_loss: 0.2601 - val_loss: 0.2474 - val_lambda_201_loss: 0.3157 - val_lambda_206_loss: 0.2474\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2573 - lambda_201_loss: 0.3197 - lambda_206_loss: 0.2573 - val_loss: 0.2446 - val_lambda_201_loss: 0.3086 - val_lambda_206_loss: 0.2446\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2554 - lambda_201_loss: 0.3183 - lambda_206_loss: 0.2554 - val_loss: 0.2416 - val_lambda_201_loss: 0.3038 - val_lambda_206_loss: 0.2416\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2551 - lambda_201_loss: 0.3181 - lambda_206_loss: 0.2551 - val_loss: 0.2432 - val_lambda_201_loss: 0.3072 - val_lambda_206_loss: 0.2432\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2554 - lambda_201_loss: 0.3174 - lambda_206_loss: 0.2554 - val_loss: 0.2440 - val_lambda_201_loss: 0.3086 - val_lambda_206_loss: 0.2440\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2529 - lambda_201_loss: 0.3154 - lambda_206_loss: 0.2529 - val_loss: 0.2421 - val_lambda_201_loss: 0.3030 - val_lambda_206_loss: 0.2421\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2526 - lambda_201_loss: 0.3148 - lambda_206_loss: 0.2526 - val_loss: 0.2474 - val_lambda_201_loss: 0.3088 - val_lambda_206_loss: 0.2474\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2524 - lambda_201_loss: 0.3141 - lambda_206_loss: 0.2524 - val_loss: 0.2403 - val_lambda_201_loss: 0.2993 - val_lambda_206_loss: 0.2403\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2501 - lambda_201_loss: 0.3122 - lambda_206_loss: 0.2501 - val_loss: 0.2396 - val_lambda_201_loss: 0.3031 - val_lambda_206_loss: 0.2396\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2499 - lambda_201_loss: 0.3113 - lambda_206_loss: 0.2499 - val_loss: 0.2404 - val_lambda_201_loss: 0.3008 - val_lambda_206_loss: 0.2404\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2491 - lambda_201_loss: 0.3112 - lambda_206_loss: 0.2491 - val_loss: 0.2385 - val_lambda_201_loss: 0.3015 - val_lambda_206_loss: 0.2385\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2482 - lambda_201_loss: 0.3100 - lambda_206_loss: 0.2482 - val_loss: 0.2389 - val_lambda_201_loss: 0.2998 - val_lambda_206_loss: 0.2389\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2461 - lambda_201_loss: 0.3078 - lambda_206_loss: 0.2461 - val_loss: 0.2335 - val_lambda_201_loss: 0.2929 - val_lambda_206_loss: 0.2335\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2455 - lambda_201_loss: 0.3068 - lambda_206_loss: 0.2455 - val_loss: 0.2335 - val_lambda_201_loss: 0.2947 - val_lambda_206_loss: 0.2335\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2468 - lambda_201_loss: 0.3084 - lambda_206_loss: 0.2468 - val_loss: 0.2402 - val_lambda_201_loss: 0.3041 - val_lambda_206_loss: 0.2402\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2446 - lambda_201_loss: 0.3061 - lambda_206_loss: 0.2446 - val_loss: 0.2332 - val_lambda_201_loss: 0.2888 - val_lambda_206_loss: 0.2332\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2442 - lambda_201_loss: 0.3055 - lambda_206_loss: 0.2442 - val_loss: 0.2336 - val_lambda_201_loss: 0.2907 - val_lambda_206_loss: 0.2336\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2429 - lambda_201_loss: 0.3036 - lambda_206_loss: 0.2429 - val_loss: 0.2363 - val_lambda_201_loss: 0.2946 - val_lambda_206_loss: 0.2363\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2430 - lambda_201_loss: 0.3046 - lambda_206_loss: 0.2430 - val_loss: 0.2320 - val_lambda_201_loss: 0.2932 - val_lambda_206_loss: 0.2320\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2412 - lambda_201_loss: 0.3023 - lambda_206_loss: 0.2412 - val_loss: 0.2343 - val_lambda_201_loss: 0.2959 - val_lambda_206_loss: 0.2343\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2415 - lambda_201_loss: 0.3023 - lambda_206_loss: 0.2415 - val_loss: 0.2342 - val_lambda_201_loss: 0.2955 - val_lambda_206_loss: 0.2342\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2416 - lambda_201_loss: 0.3027 - lambda_206_loss: 0.2416 - val_loss: 0.2310 - val_lambda_201_loss: 0.2894 - val_lambda_206_loss: 0.2310\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2393 - lambda_201_loss: 0.2998 - lambda_206_loss: 0.2393 - val_loss: 0.2281 - val_lambda_201_loss: 0.2878 - val_lambda_206_loss: 0.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2389 - lambda_201_loss: 0.2997 - lambda_206_loss: 0.2389 - val_loss: 0.2290 - val_lambda_201_loss: 0.2889 - val_lambda_206_loss: 0.2290\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2407 - lambda_201_loss: 0.3015 - lambda_206_loss: 0.2407 - val_loss: 0.2294 - val_lambda_201_loss: 0.2868 - val_lambda_206_loss: 0.2294\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2389 - lambda_201_loss: 0.3005 - lambda_206_loss: 0.2389 - val_loss: 0.2325 - val_lambda_201_loss: 0.2964 - val_lambda_206_loss: 0.2325\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2402 - lambda_201_loss: 0.3009 - lambda_206_loss: 0.2402 - val_loss: 0.2295 - val_lambda_201_loss: 0.2931 - val_lambda_206_loss: 0.2295\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2392 - lambda_201_loss: 0.2996 - lambda_206_loss: 0.2392 - val_loss: 0.2320 - val_lambda_201_loss: 0.2934 - val_lambda_206_loss: 0.2320\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2360 - lambda_201_loss: 0.2963 - lambda_206_loss: 0.2360 - val_loss: 0.2258 - val_lambda_201_loss: 0.2827 - val_lambda_206_loss: 0.2258\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2372 - lambda_201_loss: 0.2974 - lambda_206_loss: 0.2372 - val_loss: 0.2243 - val_lambda_201_loss: 0.2871 - val_lambda_206_loss: 0.2243\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2376 - lambda_201_loss: 0.2978 - lambda_206_loss: 0.2376 - val_loss: 0.2330 - val_lambda_201_loss: 0.2991 - val_lambda_206_loss: 0.2330\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2376 - lambda_201_loss: 0.2982 - lambda_206_loss: 0.2376 - val_loss: 0.2299 - val_lambda_201_loss: 0.2944 - val_lambda_206_loss: 0.2299\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2350 - lambda_201_loss: 0.2957 - lambda_206_loss: 0.2350 - val_loss: 0.2252 - val_lambda_201_loss: 0.2864 - val_lambda_206_loss: 0.2252\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2360 - lambda_201_loss: 0.2970 - lambda_206_loss: 0.2360 - val_loss: 0.2264 - val_lambda_201_loss: 0.2886 - val_lambda_206_loss: 0.2264\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 80s 120ms/step - loss: 0.2353 - lambda_201_loss: 0.2955 - lambda_206_loss: 0.2353 - val_loss: 0.2253 - val_lambda_201_loss: 0.2854 - val_lambda_206_loss: 0.2253\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 256, 256, 48) 912         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 256, 256, 2)  98          conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 256, 256, 2)  0           conv2d_126[0][0]                 \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 256, 256, 2)  0           add_41[0][0]                     \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 256, 256, 2)  0           multiply_21[0][0]                \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_211 (Lambda)             (None, 256, 256, 2)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 256, 256, 48) 912         lambda_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 256, 256, 2)  98          conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 256, 256, 2)  0           conv2d_132[0][0]                 \n",
      "                                                                 lambda_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_216 (Lambda)             (None, 256, 256, 2)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 256, 256, 2)  0           lambda_216[0][0]                 \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 256, 256, 2)  0           multiply_22[0][0]                \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)             (None, 256, 256, 2)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 256, 256, 48) 912         lambda_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 256, 256, 2)  98          conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 256, 256, 2)  0           conv2d_138[0][0]                 \n",
      "                                                                 lambda_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_226 (Lambda)             (None, 256, 256, 2)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 256, 256, 2)  0           lambda_226[0][0]                 \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 256, 256, 2)  0           multiply_23[0][0]                \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_231 (Lambda)             (None, 256, 256, 2)  0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_236 (Lambda)             (None, 256, 256, 1)  0           lambda_231[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.2157 - lambda_231_loss: 0.2454 - lambda_236_loss: 0.2157 - val_loss: 0.1597 - val_lambda_231_loss: 0.1934 - val_lambda_236_loss: 0.1597\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1543 - lambda_231_loss: 0.1822 - lambda_236_loss: 0.1543 - val_loss: 0.1425 - val_lambda_231_loss: 0.1719 - val_lambda_236_loss: 0.1425\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1403 - lambda_231_loss: 0.1651 - lambda_236_loss: 0.1403 - val_loss: 0.1296 - val_lambda_231_loss: 0.1624 - val_lambda_236_loss: 0.1296\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1311 - lambda_231_loss: 0.1559 - lambda_236_loss: 0.1311 - val_loss: 0.1293 - val_lambda_231_loss: 0.1572 - val_lambda_236_loss: 0.1293\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1283 - lambda_231_loss: 0.1529 - lambda_236_loss: 0.1283 - val_loss: 0.1279 - val_lambda_231_loss: 0.1588 - val_lambda_236_loss: 0.1279\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1244 - lambda_231_loss: 0.1486 - lambda_236_loss: 0.1244 - val_loss: 0.1225 - val_lambda_231_loss: 0.1505 - val_lambda_236_loss: 0.1225\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1219 - lambda_231_loss: 0.1459 - lambda_236_loss: 0.1219 - val_loss: 0.1232 - val_lambda_231_loss: 0.1453 - val_lambda_236_loss: 0.1232\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1186 - lambda_231_loss: 0.1420 - lambda_236_loss: 0.1186 - val_loss: 0.1170 - val_lambda_231_loss: 0.1435 - val_lambda_236_loss: 0.1170\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1178 - lambda_231_loss: 0.1413 - lambda_236_loss: 0.1178 - val_loss: 0.1222 - val_lambda_231_loss: 0.1533 - val_lambda_236_loss: 0.1222\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1162 - lambda_231_loss: 0.1389 - lambda_236_loss: 0.1162 - val_loss: 0.1229 - val_lambda_231_loss: 0.1499 - val_lambda_236_loss: 0.1229\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1146 - lambda_231_loss: 0.1373 - lambda_236_loss: 0.1146 - val_loss: 0.1183 - val_lambda_231_loss: 0.1483 - val_lambda_236_loss: 0.1183\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1130 - lambda_231_loss: 0.1350 - lambda_236_loss: 0.1130 - val_loss: 0.1181 - val_lambda_231_loss: 0.1427 - val_lambda_236_loss: 0.1181\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1123 - lambda_231_loss: 0.1346 - lambda_236_loss: 0.1123 - val_loss: 0.1216 - val_lambda_231_loss: 0.1630 - val_lambda_236_loss: 0.1216\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1112 - lambda_231_loss: 0.1328 - lambda_236_loss: 0.1112 - val_loss: 0.1288 - val_lambda_231_loss: 0.1590 - val_lambda_236_loss: 0.1288\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1107 - lambda_231_loss: 0.1324 - lambda_236_loss: 0.1107 - val_loss: 0.1174 - val_lambda_231_loss: 0.1399 - val_lambda_236_loss: 0.1174\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1095 - lambda_231_loss: 0.1311 - lambda_236_loss: 0.1095 - val_loss: 0.1135 - val_lambda_231_loss: 0.1399 - val_lambda_236_loss: 0.1135\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1087 - lambda_231_loss: 0.1298 - lambda_236_loss: 0.1087 - val_loss: 0.1193 - val_lambda_231_loss: 0.1453 - val_lambda_236_loss: 0.1193\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1081 - lambda_231_loss: 0.1291 - lambda_236_loss: 0.1081 - val_loss: 0.1146 - val_lambda_231_loss: 0.1403 - val_lambda_236_loss: 0.1146\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1068 - lambda_231_loss: 0.1272 - lambda_236_loss: 0.1068 - val_loss: 0.1113 - val_lambda_231_loss: 0.1291 - val_lambda_236_loss: 0.1113\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1067 - lambda_231_loss: 0.1273 - lambda_236_loss: 0.1067 - val_loss: 0.1088 - val_lambda_231_loss: 0.1274 - val_lambda_236_loss: 0.1088\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1051 - lambda_231_loss: 0.1253 - lambda_236_loss: 0.1051 - val_loss: 0.1202 - val_lambda_231_loss: 0.1481 - val_lambda_236_loss: 0.1202\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1055 - lambda_231_loss: 0.1264 - lambda_236_loss: 0.1055 - val_loss: 0.1107 - val_lambda_231_loss: 0.1301 - val_lambda_236_loss: 0.1107\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1046 - lambda_231_loss: 0.1245 - lambda_236_loss: 0.1046 - val_loss: 0.1081 - val_lambda_231_loss: 0.1273 - val_lambda_236_loss: 0.1081\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1032 - lambda_231_loss: 0.1229 - lambda_236_loss: 0.1032 - val_loss: 0.1056 - val_lambda_231_loss: 0.1256 - val_lambda_236_loss: 0.1056\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1036 - lambda_231_loss: 0.1230 - lambda_236_loss: 0.1036 - val_loss: 0.1079 - val_lambda_231_loss: 0.1292 - val_lambda_236_loss: 0.1079\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1019 - lambda_231_loss: 0.1208 - lambda_236_loss: 0.1019 - val_loss: 0.1051 - val_lambda_231_loss: 0.1313 - val_lambda_236_loss: 0.1051\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1022 - lambda_231_loss: 0.1209 - lambda_236_loss: 0.1022 - val_loss: 0.1079 - val_lambda_231_loss: 0.1252 - val_lambda_236_loss: 0.1079\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1017 - lambda_231_loss: 0.1201 - lambda_236_loss: 0.1017 - val_loss: 0.1064 - val_lambda_231_loss: 0.1258 - val_lambda_236_loss: 0.1064\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0998 - lambda_231_loss: 0.1171 - lambda_236_loss: 0.0998 - val_loss: 0.1036 - val_lambda_231_loss: 0.1273 - val_lambda_236_loss: 0.1036\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0987 - lambda_231_loss: 0.1162 - lambda_236_loss: 0.0987 - val_loss: 0.1037 - val_lambda_231_loss: 0.1241 - val_lambda_236_loss: 0.1037\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1000 - lambda_231_loss: 0.1173 - lambda_236_loss: 0.1000 - val_loss: 0.1037 - val_lambda_231_loss: 0.1185 - val_lambda_236_loss: 0.1037\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0977 - lambda_231_loss: 0.1143 - lambda_236_loss: 0.0977 - val_loss: 0.1051 - val_lambda_231_loss: 0.1234 - val_lambda_236_loss: 0.1051\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0990 - lambda_231_loss: 0.1157 - lambda_236_loss: 0.0990 - val_loss: 0.1048 - val_lambda_231_loss: 0.1228 - val_lambda_236_loss: 0.1048\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0971 - lambda_231_loss: 0.1127 - lambda_236_loss: 0.0971 - val_loss: 0.1019 - val_lambda_231_loss: 0.1205 - val_lambda_236_loss: 0.1019\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0975 - lambda_231_loss: 0.1131 - lambda_236_loss: 0.0975 - val_loss: 0.1021 - val_lambda_231_loss: 0.1183 - val_lambda_236_loss: 0.1021\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0968 - lambda_231_loss: 0.1125 - lambda_236_loss: 0.0968 - val_loss: 0.0988 - val_lambda_231_loss: 0.1141 - val_lambda_236_loss: 0.0988\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0964 - lambda_231_loss: 0.1115 - lambda_236_loss: 0.0964 - val_loss: 0.1055 - val_lambda_231_loss: 0.1202 - val_lambda_236_loss: 0.1055\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0946 - lambda_231_loss: 0.1095 - lambda_236_loss: 0.0946 - val_loss: 0.0991 - val_lambda_231_loss: 0.1129 - val_lambda_236_loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0942 - lambda_231_loss: 0.1084 - lambda_236_loss: 0.0942 - val_loss: 0.1074 - val_lambda_231_loss: 0.1277 - val_lambda_236_loss: 0.1074\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0948 - lambda_231_loss: 0.1095 - lambda_236_loss: 0.0948 - val_loss: 0.0969 - val_lambda_231_loss: 0.1095 - val_lambda_236_loss: 0.0969\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0949 - lambda_231_loss: 0.1091 - lambda_236_loss: 0.0949 - val_loss: 0.0977 - val_lambda_231_loss: 0.1110 - val_lambda_236_loss: 0.0977\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0944 - lambda_231_loss: 0.1088 - lambda_236_loss: 0.0944 - val_loss: 0.1014 - val_lambda_231_loss: 0.1202 - val_lambda_236_loss: 0.1014\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0933 - lambda_231_loss: 0.1073 - lambda_236_loss: 0.0933 - val_loss: 0.0975 - val_lambda_231_loss: 0.1161 - val_lambda_236_loss: 0.0975\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0934 - lambda_231_loss: 0.1075 - lambda_236_loss: 0.0934 - val_loss: 0.1003 - val_lambda_231_loss: 0.1218 - val_lambda_236_loss: 0.1003\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0940 - lambda_231_loss: 0.1076 - lambda_236_loss: 0.0940 - val_loss: 0.0984 - val_lambda_231_loss: 0.1121 - val_lambda_236_loss: 0.0984\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0926 - lambda_231_loss: 0.1062 - lambda_236_loss: 0.0926 - val_loss: 0.1016 - val_lambda_231_loss: 0.1157 - val_lambda_236_loss: 0.1016\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0934 - lambda_231_loss: 0.1078 - lambda_236_loss: 0.0934 - val_loss: 0.0971 - val_lambda_231_loss: 0.1104 - val_lambda_236_loss: 0.0971\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0922 - lambda_231_loss: 0.1052 - lambda_236_loss: 0.0922 - val_loss: 0.1003 - val_lambda_231_loss: 0.1153 - val_lambda_236_loss: 0.1003\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0915 - lambda_231_loss: 0.1042 - lambda_236_loss: 0.0915 - val_loss: 0.0990 - val_lambda_231_loss: 0.1121 - val_lambda_236_loss: 0.0990\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.0924 - lambda_231_loss: 0.1059 - lambda_236_loss: 0.0924 - val_loss: 0.0958 - val_lambda_231_loss: 0.1099 - val_lambda_236_loss: 0.0958\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 256, 256, 48) 912         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 256, 256, 2)  98          conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 256, 256, 2)  0           conv2d_144[0][0]                 \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 256, 256, 2)  0           add_47[0][0]                     \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 256, 256, 2)  0           multiply_24[0][0]                \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_241 (Lambda)             (None, 256, 256, 2)  0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 256, 256, 48) 912         lambda_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 256, 256, 2)  98          conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 256, 256, 2)  0           conv2d_150[0][0]                 \n",
      "                                                                 lambda_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_246 (Lambda)             (None, 256, 256, 2)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 256, 256, 2)  0           lambda_246[0][0]                 \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 256, 256, 2)  0           multiply_25[0][0]                \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 256, 256, 48) 912         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 256, 256, 2)  98          conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 256, 256, 2)  0           conv2d_156[0][0]                 \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 256, 256, 2)  0           add_51[0][0]                     \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 256, 256, 2)  0           multiply_26[0][0]                \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_251 (Lambda)             (None, 256, 256, 2)  0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_256 (Lambda)             (None, 256, 256, 1)  0           lambda_251[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.2567 - lambda_251_loss: 0.2948 - lambda_256_loss: 0.2567 - val_loss: 0.2260 - val_lambda_251_loss: 0.2553 - val_lambda_256_loss: 0.2260\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1992 - lambda_251_loss: 0.2374 - lambda_256_loss: 0.1992 - val_loss: 0.1812 - val_lambda_251_loss: 0.2214 - val_lambda_256_loss: 0.1812\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1817 - lambda_251_loss: 0.2186 - lambda_256_loss: 0.1817 - val_loss: 0.1684 - val_lambda_251_loss: 0.2110 - val_lambda_256_loss: 0.1684\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1716 - lambda_251_loss: 0.2074 - lambda_256_loss: 0.1716 - val_loss: 0.1681 - val_lambda_251_loss: 0.1972 - val_lambda_256_loss: 0.1681\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1644 - lambda_251_loss: 0.1994 - lambda_256_loss: 0.1644 - val_loss: 0.1612 - val_lambda_251_loss: 0.1907 - val_lambda_256_loss: 0.1612\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1600 - lambda_251_loss: 0.1945 - lambda_256_loss: 0.1600 - val_loss: 0.1601 - val_lambda_251_loss: 0.1939 - val_lambda_256_loss: 0.1601\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1567 - lambda_251_loss: 0.1907 - lambda_256_loss: 0.1567 - val_loss: 0.1477 - val_lambda_251_loss: 0.1817 - val_lambda_256_loss: 0.1477\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1548 - lambda_251_loss: 0.1886 - lambda_256_loss: 0.1548 - val_loss: 0.1496 - val_lambda_251_loss: 0.1790 - val_lambda_256_loss: 0.1496\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1519 - lambda_251_loss: 0.1851 - lambda_256_loss: 0.1519 - val_loss: 0.1487 - val_lambda_251_loss: 0.1786 - val_lambda_256_loss: 0.1487\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1490 - lambda_251_loss: 0.1816 - lambda_256_loss: 0.1490 - val_loss: 0.1472 - val_lambda_251_loss: 0.1892 - val_lambda_256_loss: 0.1472\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1476 - lambda_251_loss: 0.1802 - lambda_256_loss: 0.1476 - val_loss: 0.1559 - val_lambda_251_loss: 0.1901 - val_lambda_256_loss: 0.1559\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1448 - lambda_251_loss: 0.1770 - lambda_256_loss: 0.1448 - val_loss: 0.1473 - val_lambda_251_loss: 0.1759 - val_lambda_256_loss: 0.1473\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1435 - lambda_251_loss: 0.1752 - lambda_256_loss: 0.1435 - val_loss: 0.1437 - val_lambda_251_loss: 0.1701 - val_lambda_256_loss: 0.1437\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1430 - lambda_251_loss: 0.1746 - lambda_256_loss: 0.1430 - val_loss: 0.1435 - val_lambda_251_loss: 0.1676 - val_lambda_256_loss: 0.1435\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1413 - lambda_251_loss: 0.1727 - lambda_256_loss: 0.1413 - val_loss: 0.1376 - val_lambda_251_loss: 0.1699 - val_lambda_256_loss: 0.1376\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1402 - lambda_251_loss: 0.1712 - lambda_256_loss: 0.1402 - val_loss: 0.1375 - val_lambda_251_loss: 0.1679 - val_lambda_256_loss: 0.1375\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1392 - lambda_251_loss: 0.1698 - lambda_256_loss: 0.1392 - val_loss: 0.1413 - val_lambda_251_loss: 0.1702 - val_lambda_256_loss: 0.1413\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1390 - lambda_251_loss: 0.1701 - lambda_256_loss: 0.1390 - val_loss: 0.1380 - val_lambda_251_loss: 0.1695 - val_lambda_256_loss: 0.1380\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1375 - lambda_251_loss: 0.1678 - lambda_256_loss: 0.1375 - val_loss: 0.1357 - val_lambda_251_loss: 0.1594 - val_lambda_256_loss: 0.1357\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1367 - lambda_251_loss: 0.1669 - lambda_256_loss: 0.1367 - val_loss: 0.1385 - val_lambda_251_loss: 0.1632 - val_lambda_256_loss: 0.1385\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1356 - lambda_251_loss: 0.1656 - lambda_256_loss: 0.1356 - val_loss: 0.1468 - val_lambda_251_loss: 0.1742 - val_lambda_256_loss: 0.1468\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1355 - lambda_251_loss: 0.1650 - lambda_256_loss: 0.1355 - val_loss: 0.1394 - val_lambda_251_loss: 0.1651 - val_lambda_256_loss: 0.1394\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1353 - lambda_251_loss: 0.1651 - lambda_256_loss: 0.1353 - val_loss: 0.1381 - val_lambda_251_loss: 0.1648 - val_lambda_256_loss: 0.1381\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1334 - lambda_251_loss: 0.1624 - lambda_256_loss: 0.1334 - val_loss: 0.1341 - val_lambda_251_loss: 0.1572 - val_lambda_256_loss: 0.1341\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1332 - lambda_251_loss: 0.1624 - lambda_256_loss: 0.1332 - val_loss: 0.1429 - val_lambda_251_loss: 0.1707 - val_lambda_256_loss: 0.1429\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1323 - lambda_251_loss: 0.1613 - lambda_256_loss: 0.1323 - val_loss: 0.1377 - val_lambda_251_loss: 0.1644 - val_lambda_256_loss: 0.1377\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1309 - lambda_251_loss: 0.1598 - lambda_256_loss: 0.1309 - val_loss: 0.1348 - val_lambda_251_loss: 0.1632 - val_lambda_256_loss: 0.1348\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1312 - lambda_251_loss: 0.1602 - lambda_256_loss: 0.1312 - val_loss: 0.1332 - val_lambda_251_loss: 0.1589 - val_lambda_256_loss: 0.1332\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1325 - lambda_251_loss: 0.1617 - lambda_256_loss: 0.1325 - val_loss: 0.1314 - val_lambda_251_loss: 0.1614 - val_lambda_256_loss: 0.1314\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1307 - lambda_251_loss: 0.1595 - lambda_256_loss: 0.1307 - val_loss: 0.1384 - val_lambda_251_loss: 0.1632 - val_lambda_256_loss: 0.1384\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1296 - lambda_251_loss: 0.1576 - lambda_256_loss: 0.1296 - val_loss: 0.1317 - val_lambda_251_loss: 0.1561 - val_lambda_256_loss: 0.1317\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1292 - lambda_251_loss: 0.1574 - lambda_256_loss: 0.1292 - val_loss: 0.1323 - val_lambda_251_loss: 0.1586 - val_lambda_256_loss: 0.1323\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1296 - lambda_251_loss: 0.1581 - lambda_256_loss: 0.1296 - val_loss: 0.1298 - val_lambda_251_loss: 0.1561 - val_lambda_256_loss: 0.1298\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1285 - lambda_251_loss: 0.1568 - lambda_256_loss: 0.1285 - val_loss: 0.1369 - val_lambda_251_loss: 0.1687 - val_lambda_256_loss: 0.1369\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1285 - lambda_251_loss: 0.1563 - lambda_256_loss: 0.1285 - val_loss: 0.1327 - val_lambda_251_loss: 0.1593 - val_lambda_256_loss: 0.1327\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1284 - lambda_251_loss: 0.1568 - lambda_256_loss: 0.1284 - val_loss: 0.1338 - val_lambda_251_loss: 0.1603 - val_lambda_256_loss: 0.1338\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1281 - lambda_251_loss: 0.1561 - lambda_256_loss: 0.1281 - val_loss: 0.1290 - val_lambda_251_loss: 0.1554 - val_lambda_256_loss: 0.1290\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1279 - lambda_251_loss: 0.1560 - lambda_256_loss: 0.1279 - val_loss: 0.1345 - val_lambda_251_loss: 0.1590 - val_lambda_256_loss: 0.1345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1262 - lambda_251_loss: 0.1537 - lambda_256_loss: 0.1262 - val_loss: 0.1273 - val_lambda_251_loss: 0.1548 - val_lambda_256_loss: 0.1273\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1281 - lambda_251_loss: 0.1562 - lambda_256_loss: 0.1281 - val_loss: 0.1285 - val_lambda_251_loss: 0.1532 - val_lambda_256_loss: 0.1285\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1254 - lambda_251_loss: 0.1524 - lambda_256_loss: 0.1254 - val_loss: 0.1350 - val_lambda_251_loss: 0.1580 - val_lambda_256_loss: 0.1350\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1260 - lambda_251_loss: 0.1537 - lambda_256_loss: 0.1260 - val_loss: 0.1359 - val_lambda_251_loss: 0.1598 - val_lambda_256_loss: 0.1359\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1264 - lambda_251_loss: 0.1539 - lambda_256_loss: 0.1264 - val_loss: 0.1272 - val_lambda_251_loss: 0.1554 - val_lambda_256_loss: 0.1272\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1261 - lambda_251_loss: 0.1536 - lambda_256_loss: 0.1261 - val_loss: 0.1308 - val_lambda_251_loss: 0.1555 - val_lambda_256_loss: 0.1308\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1251 - lambda_251_loss: 0.1524 - lambda_256_loss: 0.1251 - val_loss: 0.1281 - val_lambda_251_loss: 0.1507 - val_lambda_256_loss: 0.1281\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1253 - lambda_251_loss: 0.1528 - lambda_256_loss: 0.1253 - val_loss: 0.1315 - val_lambda_251_loss: 0.1543 - val_lambda_256_loss: 0.1315\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1244 - lambda_251_loss: 0.1514 - lambda_256_loss: 0.1244 - val_loss: 0.1324 - val_lambda_251_loss: 0.1542 - val_lambda_256_loss: 0.1324\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1249 - lambda_251_loss: 0.1521 - lambda_256_loss: 0.1249 - val_loss: 0.1320 - val_lambda_251_loss: 0.1545 - val_lambda_256_loss: 0.1320\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1254 - lambda_251_loss: 0.1525 - lambda_256_loss: 0.1254 - val_loss: 0.1280 - val_lambda_251_loss: 0.1569 - val_lambda_256_loss: 0.1280\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1244 - lambda_251_loss: 0.1517 - lambda_256_loss: 0.1244 - val_loss: 0.1343 - val_lambda_251_loss: 0.1640 - val_lambda_256_loss: 0.1343\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 256, 256, 48) 912         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 256, 256, 2)  98          conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 256, 256, 2)  0           conv2d_162[0][0]                 \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 256, 256, 2)  0           add_53[0][0]                     \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 256, 256, 2)  0           multiply_27[0][0]                \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 256, 256, 48) 912         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 256, 256, 2)  98          conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 256, 256, 2)  0           conv2d_168[0][0]                 \n",
      "                                                                 add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 256, 256, 2)  0           add_55[0][0]                     \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 256, 256, 2)  0           multiply_28[0][0]                \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_261 (Lambda)             (None, 256, 256, 2)  0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 256, 256, 48) 912         lambda_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 256, 256, 2)  98          conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 256, 256, 2)  0           conv2d_174[0][0]                 \n",
      "                                                                 lambda_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_266 (Lambda)             (None, 256, 256, 2)  0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 256, 256, 2)  0           lambda_266[0][0]                 \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 256, 256, 2)  0           multiply_29[0][0]                \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_271 (Lambda)             (None, 256, 256, 2)  0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_276 (Lambda)             (None, 256, 256, 1)  0           lambda_271[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.2605 - lambda_271_loss: 0.2942 - lambda_276_loss: 0.2605 - val_loss: 0.1991 - val_lambda_271_loss: 0.2305 - val_lambda_276_loss: 0.1991\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.2010 - lambda_271_loss: 0.2324 - lambda_276_loss: 0.2010 - val_loss: 0.1856 - val_lambda_271_loss: 0.2248 - val_lambda_276_loss: 0.1856\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1857 - lambda_271_loss: 0.2167 - lambda_276_loss: 0.1857 - val_loss: 0.1820 - val_lambda_271_loss: 0.2100 - val_lambda_276_loss: 0.1820\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1768 - lambda_271_loss: 0.2071 - lambda_276_loss: 0.1768 - val_loss: 0.1701 - val_lambda_271_loss: 0.2065 - val_lambda_276_loss: 0.1701\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 81s 121ms/step - loss: 0.1717 - lambda_271_loss: 0.2016 - lambda_276_loss: 0.1717 - val_loss: 0.1758 - val_lambda_271_loss: 0.2140 - val_lambda_276_loss: 0.1758\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1685 - lambda_271_loss: 0.1989 - lambda_276_loss: 0.1685 - val_loss: 0.1677 - val_lambda_271_loss: 0.2187 - val_lambda_276_loss: 0.1677\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1659 - lambda_271_loss: 0.1957 - lambda_276_loss: 0.1659 - val_loss: 0.1586 - val_lambda_271_loss: 0.1823 - val_lambda_276_loss: 0.1586\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1610 - lambda_271_loss: 0.1896 - lambda_276_loss: 0.1610 - val_loss: 0.1533 - val_lambda_271_loss: 0.1797 - val_lambda_276_loss: 0.1533\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1601 - lambda_271_loss: 0.1891 - lambda_276_loss: 0.1601 - val_loss: 0.1539 - val_lambda_271_loss: 0.1832 - val_lambda_276_loss: 0.1539\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1560 - lambda_271_loss: 0.1838 - lambda_276_loss: 0.1560 - val_loss: 0.1583 - val_lambda_271_loss: 0.2006 - val_lambda_276_loss: 0.1583\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1543 - lambda_271_loss: 0.1824 - lambda_276_loss: 0.1543 - val_loss: 0.1456 - val_lambda_271_loss: 0.1727 - val_lambda_276_loss: 0.1456\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1536 - lambda_271_loss: 0.1818 - lambda_276_loss: 0.1536 - val_loss: 0.1454 - val_lambda_271_loss: 0.1781 - val_lambda_276_loss: 0.1454\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1521 - lambda_271_loss: 0.1797 - lambda_276_loss: 0.1521 - val_loss: 0.1492 - val_lambda_271_loss: 0.1732 - val_lambda_276_loss: 0.1492\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1490 - lambda_271_loss: 0.1757 - lambda_276_loss: 0.1490 - val_loss: 0.1443 - val_lambda_271_loss: 0.1803 - val_lambda_276_loss: 0.1443\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1489 - lambda_271_loss: 0.1759 - lambda_276_loss: 0.1489 - val_loss: 0.1460 - val_lambda_271_loss: 0.1777 - val_lambda_276_loss: 0.1460\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1477 - lambda_271_loss: 0.1741 - lambda_276_loss: 0.1477 - val_loss: 0.1394 - val_lambda_271_loss: 0.1716 - val_lambda_276_loss: 0.1394\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1464 - lambda_271_loss: 0.1727 - lambda_276_loss: 0.1464 - val_loss: 0.1434 - val_lambda_271_loss: 0.1768 - val_lambda_276_loss: 0.1434\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1454 - lambda_271_loss: 0.1717 - lambda_276_loss: 0.1454 - val_loss: 0.1432 - val_lambda_271_loss: 0.1652 - val_lambda_276_loss: 0.1432\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1458 - lambda_271_loss: 0.1718 - lambda_276_loss: 0.1458 - val_loss: 0.1538 - val_lambda_271_loss: 0.1788 - val_lambda_276_loss: 0.1538\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1429 - lambda_271_loss: 0.1680 - lambda_276_loss: 0.1429 - val_loss: 0.1401 - val_lambda_271_loss: 0.1705 - val_lambda_276_loss: 0.1401\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1432 - lambda_271_loss: 0.1688 - lambda_276_loss: 0.1432 - val_loss: 0.1386 - val_lambda_271_loss: 0.1650 - val_lambda_276_loss: 0.1386\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1411 - lambda_271_loss: 0.1663 - lambda_276_loss: 0.1411 - val_loss: 0.1376 - val_lambda_271_loss: 0.1645 - val_lambda_276_loss: 0.1376\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1415 - lambda_271_loss: 0.1672 - lambda_276_loss: 0.1415 - val_loss: 0.1389 - val_lambda_271_loss: 0.1639 - val_lambda_276_loss: 0.1389\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1415 - lambda_271_loss: 0.1668 - lambda_276_loss: 0.1415 - val_loss: 0.1368 - val_lambda_271_loss: 0.1642 - val_lambda_276_loss: 0.1368\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1401 - lambda_271_loss: 0.1645 - lambda_276_loss: 0.1401 - val_loss: 0.1418 - val_lambda_271_loss: 0.1669 - val_lambda_276_loss: 0.1418\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1400 - lambda_271_loss: 0.1648 - lambda_276_loss: 0.1400 - val_loss: 0.1347 - val_lambda_271_loss: 0.1588 - val_lambda_276_loss: 0.1347\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1398 - lambda_271_loss: 0.1645 - lambda_276_loss: 0.1398 - val_loss: 0.1360 - val_lambda_271_loss: 0.1573 - val_lambda_276_loss: 0.1360\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1386 - lambda_271_loss: 0.1636 - lambda_276_loss: 0.1386 - val_loss: 0.1374 - val_lambda_271_loss: 0.1675 - val_lambda_276_loss: 0.1374\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1378 - lambda_271_loss: 0.1631 - lambda_276_loss: 0.1378 - val_loss: 0.1344 - val_lambda_271_loss: 0.1556 - val_lambda_276_loss: 0.1344\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1374 - lambda_271_loss: 0.1614 - lambda_276_loss: 0.1374 - val_loss: 0.1358 - val_lambda_271_loss: 0.1666 - val_lambda_276_loss: 0.1358\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1373 - lambda_271_loss: 0.1614 - lambda_276_loss: 0.1373 - val_loss: 0.1379 - val_lambda_271_loss: 0.1653 - val_lambda_276_loss: 0.1379\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1358 - lambda_271_loss: 0.1597 - lambda_276_loss: 0.1358 - val_loss: 0.1325 - val_lambda_271_loss: 0.1572 - val_lambda_276_loss: 0.1325\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1360 - lambda_271_loss: 0.1600 - lambda_276_loss: 0.1360 - val_loss: 0.1340 - val_lambda_271_loss: 0.1562 - val_lambda_276_loss: 0.1340\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1362 - lambda_271_loss: 0.1602 - lambda_276_loss: 0.1362 - val_loss: 0.1334 - val_lambda_271_loss: 0.1608 - val_lambda_276_loss: 0.1334\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1349 - lambda_271_loss: 0.1588 - lambda_276_loss: 0.1349 - val_loss: 0.1312 - val_lambda_271_loss: 0.1618 - val_lambda_276_loss: 0.1312\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1360 - lambda_271_loss: 0.1597 - lambda_276_loss: 0.1360 - val_loss: 0.1352 - val_lambda_271_loss: 0.1581 - val_lambda_276_loss: 0.1352\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1348 - lambda_271_loss: 0.1584 - lambda_276_loss: 0.1348 - val_loss: 0.1311 - val_lambda_271_loss: 0.1509 - val_lambda_276_loss: 0.1311\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1347 - lambda_271_loss: 0.1581 - lambda_276_loss: 0.1347 - val_loss: 0.1304 - val_lambda_271_loss: 0.1586 - val_lambda_276_loss: 0.1304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1330 - lambda_271_loss: 0.1564 - lambda_276_loss: 0.1330 - val_loss: 0.1324 - val_lambda_271_loss: 0.1584 - val_lambda_276_loss: 0.1324\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1345 - lambda_271_loss: 0.1578 - lambda_276_loss: 0.1345 - val_loss: 0.1320 - val_lambda_271_loss: 0.1563 - val_lambda_276_loss: 0.1320\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1336 - lambda_271_loss: 0.1566 - lambda_276_loss: 0.1336 - val_loss: 0.1314 - val_lambda_271_loss: 0.1615 - val_lambda_276_loss: 0.1314\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1336 - lambda_271_loss: 0.1575 - lambda_276_loss: 0.1336 - val_loss: 0.1521 - val_lambda_271_loss: 0.1845 - val_lambda_276_loss: 0.1521\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1333 - lambda_271_loss: 0.1569 - lambda_276_loss: 0.1333 - val_loss: 0.1356 - val_lambda_271_loss: 0.1611 - val_lambda_276_loss: 0.1356\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1318 - lambda_271_loss: 0.1546 - lambda_276_loss: 0.1318 - val_loss: 0.1288 - val_lambda_271_loss: 0.1562 - val_lambda_276_loss: 0.1288\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1329 - lambda_271_loss: 0.1561 - lambda_276_loss: 0.1329 - val_loss: 0.1326 - val_lambda_271_loss: 0.1598 - val_lambda_276_loss: 0.1326\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1307 - lambda_271_loss: 0.1536 - lambda_276_loss: 0.1307 - val_loss: 0.1293 - val_lambda_271_loss: 0.1525 - val_lambda_276_loss: 0.1293\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1318 - lambda_271_loss: 0.1551 - lambda_276_loss: 0.1318 - val_loss: 0.1289 - val_lambda_271_loss: 0.1599 - val_lambda_276_loss: 0.1289\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1315 - lambda_271_loss: 0.1542 - lambda_276_loss: 0.1315 - val_loss: 0.1282 - val_lambda_271_loss: 0.1537 - val_lambda_276_loss: 0.1282\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1300 - lambda_271_loss: 0.1525 - lambda_276_loss: 0.1300 - val_loss: 0.1297 - val_lambda_271_loss: 0.1515 - val_lambda_276_loss: 0.1297\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1303 - lambda_271_loss: 0.1527 - lambda_276_loss: 0.1303 - val_loss: 0.1281 - val_lambda_271_loss: 0.1545 - val_lambda_276_loss: 0.1281\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_281 (Lambda)             (None, 256, 256, 2)  0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 256, 256, 48) 912         lambda_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 256, 256, 2)  98          conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 256, 256, 2)  0           conv2d_180[0][0]                 \n",
      "                                                                 lambda_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_286 (Lambda)             (None, 256, 256, 2)  0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 256, 256, 2)  0           lambda_286[0][0]                 \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 256, 256, 2)  0           multiply_30[0][0]                \n",
      "                                                                 input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_291 (Lambda)             (None, 256, 256, 2)  0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 256, 256, 48) 912         lambda_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 256, 256, 2)  98          conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 256, 256, 2)  0           conv2d_186[0][0]                 \n",
      "                                                                 lambda_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_296 (Lambda)             (None, 256, 256, 2)  0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 256, 256, 2)  0           lambda_296[0][0]                 \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 256, 256, 2)  0           multiply_31[0][0]                \n",
      "                                                                 input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 256, 256, 48) 912         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 256, 256, 2)  98          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 256, 256, 2)  0           conv2d_192[0][0]                 \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 256, 256, 2)  0           add_63[0][0]                     \n",
      "                                                                 input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 256, 256, 2)  0           multiply_32[0][0]                \n",
      "                                                                 input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_301 (Lambda)             (None, 256, 256, 2)  0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_306 (Lambda)             (None, 256, 256, 1)  0           lambda_301[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 86s 129ms/step - loss: 0.2210 - lambda_301_loss: 0.2616 - lambda_306_loss: 0.2210 - val_loss: 0.1806 - val_lambda_301_loss: 0.2126 - val_lambda_306_loss: 0.1806\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 81s 122ms/step - loss: 0.1689 - lambda_301_loss: 0.2028 - lambda_306_loss: 0.1689 - val_loss: 0.1639 - val_lambda_301_loss: 0.2029 - val_lambda_306_loss: 0.1639\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1548 - lambda_301_loss: 0.1861 - lambda_306_loss: 0.1548 - val_loss: 0.1518 - val_lambda_301_loss: 0.1789 - val_lambda_306_loss: 0.1518\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1455 - lambda_301_loss: 0.1735 - lambda_306_loss: 0.1455 - val_loss: 0.1476 - val_lambda_301_loss: 0.1725 - val_lambda_306_loss: 0.1476\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1429 - lambda_301_loss: 0.1722 - lambda_306_loss: 0.1429 - val_loss: 0.1353 - val_lambda_301_loss: 0.1645 - val_lambda_306_loss: 0.1353\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1388 - lambda_301_loss: 0.1664 - lambda_306_loss: 0.1388 - val_loss: 0.1492 - val_lambda_301_loss: 0.1904 - val_lambda_306_loss: 0.1492\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1357 - lambda_301_loss: 0.1634 - lambda_306_loss: 0.1357 - val_loss: 0.1403 - val_lambda_301_loss: 0.1700 - val_lambda_306_loss: 0.1403\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1325 - lambda_301_loss: 0.1606 - lambda_306_loss: 0.1325 - val_loss: 0.1447 - val_lambda_301_loss: 0.1704 - val_lambda_306_loss: 0.1447\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1319 - lambda_301_loss: 0.1592 - lambda_306_loss: 0.1319 - val_loss: 0.1331 - val_lambda_301_loss: 0.1597 - val_lambda_306_loss: 0.1331\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1293 - lambda_301_loss: 0.1574 - lambda_306_loss: 0.1293 - val_loss: 0.1320 - val_lambda_301_loss: 0.1545 - val_lambda_306_loss: 0.1320\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1279 - lambda_301_loss: 0.1557 - lambda_306_loss: 0.1279 - val_loss: 0.1275 - val_lambda_301_loss: 0.1545 - val_lambda_306_loss: 0.1275\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1277 - lambda_301_loss: 0.1554 - lambda_306_loss: 0.1277 - val_loss: 0.1282 - val_lambda_301_loss: 0.1580 - val_lambda_306_loss: 0.1282\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1237 - lambda_301_loss: 0.1504 - lambda_306_loss: 0.1237 - val_loss: 0.1379 - val_lambda_301_loss: 0.1634 - val_lambda_306_loss: 0.1379\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1231 - lambda_301_loss: 0.1503 - lambda_306_loss: 0.1231 - val_loss: 0.1423 - val_lambda_301_loss: 0.1717 - val_lambda_306_loss: 0.1423\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1228 - lambda_301_loss: 0.1504 - lambda_306_loss: 0.1228 - val_loss: 0.1284 - val_lambda_301_loss: 0.1595 - val_lambda_306_loss: 0.1284\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1233 - lambda_301_loss: 0.1509 - lambda_306_loss: 0.1233 - val_loss: 0.1370 - val_lambda_301_loss: 0.1621 - val_lambda_306_loss: 0.1370\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1210 - lambda_301_loss: 0.1485 - lambda_306_loss: 0.1210 - val_loss: 0.1447 - val_lambda_301_loss: 0.1731 - val_lambda_306_loss: 0.1447\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1208 - lambda_301_loss: 0.1477 - lambda_306_loss: 0.1208 - val_loss: 0.1224 - val_lambda_301_loss: 0.1534 - val_lambda_306_loss: 0.1224\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1192 - lambda_301_loss: 0.1459 - lambda_306_loss: 0.1192 - val_loss: 0.1268 - val_lambda_301_loss: 0.1558 - val_lambda_306_loss: 0.1268\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1192 - lambda_301_loss: 0.1457 - lambda_306_loss: 0.1192 - val_loss: 0.1320 - val_lambda_301_loss: 0.1592 - val_lambda_306_loss: 0.1320\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1187 - lambda_301_loss: 0.1458 - lambda_306_loss: 0.1187 - val_loss: 0.1282 - val_lambda_301_loss: 0.1564 - val_lambda_306_loss: 0.1282\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1183 - lambda_301_loss: 0.1458 - lambda_306_loss: 0.1183 - val_loss: 0.1341 - val_lambda_301_loss: 0.1721 - val_lambda_306_loss: 0.1341\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1170 - lambda_301_loss: 0.1443 - lambda_306_loss: 0.1170 - val_loss: 0.1358 - val_lambda_301_loss: 0.1572 - val_lambda_306_loss: 0.1358\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1158 - lambda_301_loss: 0.1425 - lambda_306_loss: 0.1158 - val_loss: 0.1230 - val_lambda_301_loss: 0.1470 - val_lambda_306_loss: 0.1230\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1158 - lambda_301_loss: 0.1424 - lambda_306_loss: 0.1158 - val_loss: 0.1264 - val_lambda_301_loss: 0.1633 - val_lambda_306_loss: 0.1264\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1159 - lambda_301_loss: 0.1428 - lambda_306_loss: 0.1159 - val_loss: 0.1210 - val_lambda_301_loss: 0.1446 - val_lambda_306_loss: 0.1210\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1163 - lambda_301_loss: 0.1428 - lambda_306_loss: 0.1163 - val_loss: 0.1228 - val_lambda_301_loss: 0.1471 - val_lambda_306_loss: 0.1228\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1145 - lambda_301_loss: 0.1406 - lambda_306_loss: 0.1145 - val_loss: 0.1284 - val_lambda_301_loss: 0.1550 - val_lambda_306_loss: 0.1284\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1143 - lambda_301_loss: 0.1409 - lambda_306_loss: 0.1143 - val_loss: 0.1262 - val_lambda_301_loss: 0.1543 - val_lambda_306_loss: 0.1262\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1139 - lambda_301_loss: 0.1402 - lambda_306_loss: 0.1139 - val_loss: 0.1256 - val_lambda_301_loss: 0.1482 - val_lambda_306_loss: 0.1256\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1138 - lambda_301_loss: 0.1402 - lambda_306_loss: 0.1138 - val_loss: 0.1224 - val_lambda_301_loss: 0.1513 - val_lambda_306_loss: 0.1224\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1135 - lambda_301_loss: 0.1398 - lambda_306_loss: 0.1135 - val_loss: 0.1205 - val_lambda_301_loss: 0.1498 - val_lambda_306_loss: 0.1205\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1123 - lambda_301_loss: 0.1385 - lambda_306_loss: 0.1123 - val_loss: 0.1172 - val_lambda_301_loss: 0.1395 - val_lambda_306_loss: 0.1172\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1132 - lambda_301_loss: 0.1393 - lambda_306_loss: 0.1132 - val_loss: 0.1324 - val_lambda_301_loss: 0.1595 - val_lambda_306_loss: 0.1324\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1121 - lambda_301_loss: 0.1385 - lambda_306_loss: 0.1121 - val_loss: 0.1300 - val_lambda_301_loss: 0.1566 - val_lambda_306_loss: 0.1300\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1133 - lambda_301_loss: 0.1397 - lambda_306_loss: 0.1133 - val_loss: 0.1205 - val_lambda_301_loss: 0.1452 - val_lambda_306_loss: 0.1205\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1115 - lambda_301_loss: 0.1379 - lambda_306_loss: 0.1115 - val_loss: 0.1174 - val_lambda_301_loss: 0.1497 - val_lambda_306_loss: 0.1174\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1110 - lambda_301_loss: 0.1365 - lambda_306_loss: 0.1110 - val_loss: 0.1181 - val_lambda_301_loss: 0.1450 - val_lambda_306_loss: 0.1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1110 - lambda_301_loss: 0.1368 - lambda_306_loss: 0.1110 - val_loss: 0.1182 - val_lambda_301_loss: 0.1454 - val_lambda_306_loss: 0.1182\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1102 - lambda_301_loss: 0.1362 - lambda_306_loss: 0.1102 - val_loss: 0.1271 - val_lambda_301_loss: 0.1533 - val_lambda_306_loss: 0.1271\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1180 - lambda_301_loss: 0.1462 - lambda_306_loss: 0.1180 - val_loss: 0.1238 - val_lambda_301_loss: 0.1542 - val_lambda_306_loss: 0.1238\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1104 - lambda_301_loss: 0.1363 - lambda_306_loss: 0.1104 - val_loss: 0.1223 - val_lambda_301_loss: 0.1481 - val_lambda_306_loss: 0.1223\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1099 - lambda_301_loss: 0.1357 - lambda_306_loss: 0.1099 - val_loss: 0.1168 - val_lambda_301_loss: 0.1419 - val_lambda_306_loss: 0.1168\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1104 - lambda_301_loss: 0.1365 - lambda_306_loss: 0.1104 - val_loss: 0.1202 - val_lambda_301_loss: 0.1522 - val_lambda_306_loss: 0.1202\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1098 - lambda_301_loss: 0.1360 - lambda_306_loss: 0.1098 - val_loss: 0.1197 - val_lambda_301_loss: 0.1567 - val_lambda_306_loss: 0.1197\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1095 - lambda_301_loss: 0.1354 - lambda_306_loss: 0.1095 - val_loss: 0.1216 - val_lambda_301_loss: 0.1474 - val_lambda_306_loss: 0.1216\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1094 - lambda_301_loss: 0.1350 - lambda_306_loss: 0.1094 - val_loss: 0.1217 - val_lambda_301_loss: 0.1488 - val_lambda_306_loss: 0.1217\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1085 - lambda_301_loss: 0.1345 - lambda_306_loss: 0.1085 - val_loss: 0.1159 - val_lambda_301_loss: 0.1440 - val_lambda_306_loss: 0.1159\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1105 - lambda_301_loss: 0.1365 - lambda_306_loss: 0.1105 - val_loss: 0.1314 - val_lambda_301_loss: 0.1603 - val_lambda_306_loss: 0.1314\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1097 - lambda_301_loss: 0.1355 - lambda_306_loss: 0.1097 - val_loss: 0.1150 - val_lambda_301_loss: 0.1412 - val_lambda_306_loss: 0.1150\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_311 (Lambda)             (None, 256, 256, 2)  0           input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 256, 256, 48) 912         lambda_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 256, 256, 2)  98          conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 256, 256, 2)  0           conv2d_198[0][0]                 \n",
      "                                                                 lambda_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_316 (Lambda)             (None, 256, 256, 2)  0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 256, 256, 2)  0           lambda_316[0][0]                 \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 256, 256, 2)  0           multiply_33[0][0]                \n",
      "                                                                 input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 256, 256, 48) 912         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 256, 256, 2)  98          conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 256, 256, 2)  0           conv2d_204[0][0]                 \n",
      "                                                                 add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 256, 256, 2)  0           add_67[0][0]                     \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 256, 256, 2)  0           multiply_34[0][0]                \n",
      "                                                                 input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_321 (Lambda)             (None, 256, 256, 2)  0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 256, 256, 48) 912         lambda_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 256, 256, 2)  98          conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 256, 256, 2)  0           conv2d_210[0][0]                 \n",
      "                                                                 lambda_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_326 (Lambda)             (None, 256, 256, 2)  0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 256, 256, 2)  0           lambda_326[0][0]                 \n",
      "                                                                 input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 256, 256, 2)  0           multiply_35[0][0]                \n",
      "                                                                 input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_331 (Lambda)             (None, 256, 256, 2)  0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_336 (Lambda)             (None, 256, 256, 1)  0           lambda_331[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 86s 130ms/step - loss: 0.2057 - lambda_331_loss: 0.2333 - lambda_336_loss: 0.2057 - val_loss: 0.1475 - val_lambda_331_loss: 0.1721 - val_lambda_336_loss: 0.1475\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1442 - lambda_331_loss: 0.1667 - lambda_336_loss: 0.1442 - val_loss: 0.1440 - val_lambda_331_loss: 0.1718 - val_lambda_336_loss: 0.1440\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1330 - lambda_331_loss: 0.1542 - lambda_336_loss: 0.1330 - val_loss: 0.1279 - val_lambda_331_loss: 0.1533 - val_lambda_336_loss: 0.1279\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1274 - lambda_331_loss: 0.1479 - lambda_336_loss: 0.1274 - val_loss: 0.1247 - val_lambda_331_loss: 0.1477 - val_lambda_336_loss: 0.1247\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1228 - lambda_331_loss: 0.1424 - lambda_336_loss: 0.1228 - val_loss: 0.1306 - val_lambda_331_loss: 0.1551 - val_lambda_336_loss: 0.1306\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1204 - lambda_331_loss: 0.1400 - lambda_336_loss: 0.1204 - val_loss: 0.1162 - val_lambda_331_loss: 0.1371 - val_lambda_336_loss: 0.1162\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1175 - lambda_331_loss: 0.1362 - lambda_336_loss: 0.1175 - val_loss: 0.1217 - val_lambda_331_loss: 0.1450 - val_lambda_336_loss: 0.1217\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1149 - lambda_331_loss: 0.1335 - lambda_336_loss: 0.1149 - val_loss: 0.1224 - val_lambda_331_loss: 0.1442 - val_lambda_336_loss: 0.1224\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1137 - lambda_331_loss: 0.1319 - lambda_336_loss: 0.1137 - val_loss: 0.1160 - val_lambda_331_loss: 0.1353 - val_lambda_336_loss: 0.1160\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1127 - lambda_331_loss: 0.1308 - lambda_336_loss: 0.1127 - val_loss: 0.1173 - val_lambda_331_loss: 0.1305 - val_lambda_336_loss: 0.1173\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1114 - lambda_331_loss: 0.1293 - lambda_336_loss: 0.1114 - val_loss: 0.1189 - val_lambda_331_loss: 0.1383 - val_lambda_336_loss: 0.1189\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1088 - lambda_331_loss: 0.1261 - lambda_336_loss: 0.1088 - val_loss: 0.1105 - val_lambda_331_loss: 0.1295 - val_lambda_336_loss: 0.1105\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1081 - lambda_331_loss: 0.1257 - lambda_336_loss: 0.1081 - val_loss: 0.1171 - val_lambda_331_loss: 0.1357 - val_lambda_336_loss: 0.1171\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1072 - lambda_331_loss: 0.1241 - lambda_336_loss: 0.1072 - val_loss: 0.1160 - val_lambda_331_loss: 0.1426 - val_lambda_336_loss: 0.1160\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 82s 122ms/step - loss: 0.1058 - lambda_331_loss: 0.1222 - lambda_336_loss: 0.1058 - val_loss: 0.1097 - val_lambda_331_loss: 0.1296 - val_lambda_336_loss: 0.1097\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1053 - lambda_331_loss: 0.1218 - lambda_336_loss: 0.1053 - val_loss: 0.1244 - val_lambda_331_loss: 0.1421 - val_lambda_336_loss: 0.1244\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1046 - lambda_331_loss: 0.1206 - lambda_336_loss: 0.1046 - val_loss: 0.1076 - val_lambda_331_loss: 0.1244 - val_lambda_336_loss: 0.1076\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1042 - lambda_331_loss: 0.1204 - lambda_336_loss: 0.1042 - val_loss: 0.1268 - val_lambda_331_loss: 0.1551 - val_lambda_336_loss: 0.1268\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1030 - lambda_331_loss: 0.1193 - lambda_336_loss: 0.1030 - val_loss: 0.1094 - val_lambda_331_loss: 0.1242 - val_lambda_336_loss: 0.1094\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1019 - lambda_331_loss: 0.1176 - lambda_336_loss: 0.1019 - val_loss: 0.1259 - val_lambda_331_loss: 0.1509 - val_lambda_336_loss: 0.1259\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1023 - lambda_331_loss: 0.1181 - lambda_336_loss: 0.1023 - val_loss: 0.1132 - val_lambda_331_loss: 0.1327 - val_lambda_336_loss: 0.1132\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1013 - lambda_331_loss: 0.1168 - lambda_336_loss: 0.1013 - val_loss: 0.1061 - val_lambda_331_loss: 0.1290 - val_lambda_336_loss: 0.1061\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1009 - lambda_331_loss: 0.1164 - lambda_336_loss: 0.1009 - val_loss: 0.1088 - val_lambda_331_loss: 0.1320 - val_lambda_336_loss: 0.1088\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1002 - lambda_331_loss: 0.1154 - lambda_336_loss: 0.1002 - val_loss: 0.1221 - val_lambda_331_loss: 0.1417 - val_lambda_336_loss: 0.1221\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0999 - lambda_331_loss: 0.1153 - lambda_336_loss: 0.0999 - val_loss: 0.1088 - val_lambda_331_loss: 0.1222 - val_lambda_336_loss: 0.1088\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1002 - lambda_331_loss: 0.1157 - lambda_336_loss: 0.1002 - val_loss: 0.1033 - val_lambda_331_loss: 0.1193 - val_lambda_336_loss: 0.1033\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0992 - lambda_331_loss: 0.1144 - lambda_336_loss: 0.0992 - val_loss: 0.1047 - val_lambda_331_loss: 0.1219 - val_lambda_336_loss: 0.1047\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0983 - lambda_331_loss: 0.1134 - lambda_336_loss: 0.0983 - val_loss: 0.1062 - val_lambda_331_loss: 0.1250 - val_lambda_336_loss: 0.1062\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0985 - lambda_331_loss: 0.1134 - lambda_336_loss: 0.0985 - val_loss: 0.1058 - val_lambda_331_loss: 0.1265 - val_lambda_336_loss: 0.1058\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.0982 - lambda_331_loss: 0.1134 - lambda_336_loss: 0.0982 - val_loss: 0.0996 - val_lambda_331_loss: 0.1161 - val_lambda_336_loss: 0.0996\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0973 - lambda_331_loss: 0.1122 - lambda_336_loss: 0.0973 - val_loss: 0.1026 - val_lambda_331_loss: 0.1212 - val_lambda_336_loss: 0.1026\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0972 - lambda_331_loss: 0.1121 - lambda_336_loss: 0.0972 - val_loss: 0.1088 - val_lambda_331_loss: 0.1273 - val_lambda_336_loss: 0.1088\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0964 - lambda_331_loss: 0.1110 - lambda_336_loss: 0.0964 - val_loss: 0.1046 - val_lambda_331_loss: 0.1224 - val_lambda_336_loss: 0.1046\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0963 - lambda_331_loss: 0.1109 - lambda_336_loss: 0.0963 - val_loss: 0.1045 - val_lambda_331_loss: 0.1233 - val_lambda_336_loss: 0.1045\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0959 - lambda_331_loss: 0.1104 - lambda_336_loss: 0.0959 - val_loss: 0.1061 - val_lambda_331_loss: 0.1288 - val_lambda_336_loss: 0.1061\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0955 - lambda_331_loss: 0.1099 - lambda_336_loss: 0.0955 - val_loss: 0.1063 - val_lambda_331_loss: 0.1280 - val_lambda_336_loss: 0.1063\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0956 - lambda_331_loss: 0.1102 - lambda_336_loss: 0.0956 - val_loss: 0.1014 - val_lambda_331_loss: 0.1187 - val_lambda_336_loss: 0.1014\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0952 - lambda_331_loss: 0.1093 - lambda_336_loss: 0.0952 - val_loss: 0.1021 - val_lambda_331_loss: 0.1191 - val_lambda_336_loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0945 - lambda_331_loss: 0.1087 - lambda_336_loss: 0.0945 - val_loss: 0.1060 - val_lambda_331_loss: 0.1269 - val_lambda_336_loss: 0.1060\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0947 - lambda_331_loss: 0.1089 - lambda_336_loss: 0.0947 - val_loss: 0.1044 - val_lambda_331_loss: 0.1223 - val_lambda_336_loss: 0.1044\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0940 - lambda_331_loss: 0.1080 - lambda_336_loss: 0.0940 - val_loss: 0.1053 - val_lambda_331_loss: 0.1246 - val_lambda_336_loss: 0.1053\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0943 - lambda_331_loss: 0.1083 - lambda_336_loss: 0.0943 - val_loss: 0.1079 - val_lambda_331_loss: 0.1268 - val_lambda_336_loss: 0.1079\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0938 - lambda_331_loss: 0.1078 - lambda_336_loss: 0.0938 - val_loss: 0.1036 - val_lambda_331_loss: 0.1249 - val_lambda_336_loss: 0.1036\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0938 - lambda_331_loss: 0.1079 - lambda_336_loss: 0.0938 - val_loss: 0.1075 - val_lambda_331_loss: 0.1253 - val_lambda_336_loss: 0.1075\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0936 - lambda_331_loss: 0.1074 - lambda_336_loss: 0.0936 - val_loss: 0.1066 - val_lambda_331_loss: 0.1223 - val_lambda_336_loss: 0.1066\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0922 - lambda_331_loss: 0.1059 - lambda_336_loss: 0.0922 - val_loss: 0.1059 - val_lambda_331_loss: 0.1223 - val_lambda_336_loss: 0.1059\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0939 - lambda_331_loss: 0.1078 - lambda_336_loss: 0.0939 - val_loss: 0.1044 - val_lambda_331_loss: 0.1236 - val_lambda_336_loss: 0.1044\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0928 - lambda_331_loss: 0.1068 - lambda_336_loss: 0.0928 - val_loss: 0.0976 - val_lambda_331_loss: 0.1116 - val_lambda_336_loss: 0.0976\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0928 - lambda_331_loss: 0.1065 - lambda_336_loss: 0.0928 - val_loss: 0.1043 - val_lambda_331_loss: 0.1224 - val_lambda_336_loss: 0.1043\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.0924 - lambda_331_loss: 0.1064 - lambda_336_loss: 0.0924 - val_loss: 0.1024 - val_lambda_331_loss: 0.1206 - val_lambda_336_loss: 0.1024\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_341 (Lambda)             (None, 256, 256, 2)  0           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 256, 256, 48) 912         lambda_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 256, 256, 2)  98          conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 256, 256, 2)  0           conv2d_216[0][0]                 \n",
      "                                                                 lambda_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_346 (Lambda)             (None, 256, 256, 2)  0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 256, 256, 2)  0           lambda_346[0][0]                 \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 256, 256, 2)  0           multiply_36[0][0]                \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_351 (Lambda)             (None, 256, 256, 2)  0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 256, 256, 48) 912         lambda_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 256, 256, 2)  98          conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 256, 256, 2)  0           conv2d_222[0][0]                 \n",
      "                                                                 lambda_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_356 (Lambda)             (None, 256, 256, 2)  0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 256, 256, 2)  0           lambda_356[0][0]                 \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 256, 256, 2)  0           multiply_37[0][0]                \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 256, 256, 48) 912         add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 256, 256, 2)  98          conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 256, 256, 2)  0           conv2d_228[0][0]                 \n",
      "                                                                 add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 256, 256, 2)  0           add_75[0][0]                     \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 256, 256, 2)  0           multiply_38[0][0]                \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_361 (Lambda)             (None, 256, 256, 2)  0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_366 (Lambda)             (None, 256, 256, 1)  0           lambda_361[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 87s 131ms/step - loss: 0.2200 - lambda_361_loss: 0.2600 - lambda_366_loss: 0.2200 - val_loss: 0.1688 - val_lambda_361_loss: 0.2042 - val_lambda_366_loss: 0.1688\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1664 - lambda_361_loss: 0.1994 - lambda_366_loss: 0.1664 - val_loss: 0.1566 - val_lambda_361_loss: 0.2019 - val_lambda_366_loss: 0.1566\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1535 - lambda_361_loss: 0.1845 - lambda_366_loss: 0.1535 - val_loss: 0.1461 - val_lambda_361_loss: 0.1796 - val_lambda_366_loss: 0.1461\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1452 - lambda_361_loss: 0.1736 - lambda_366_loss: 0.1452 - val_loss: 0.1412 - val_lambda_361_loss: 0.1793 - val_lambda_366_loss: 0.1412\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1405 - lambda_361_loss: 0.1692 - lambda_366_loss: 0.1405 - val_loss: 0.1530 - val_lambda_361_loss: 0.1825 - val_lambda_366_loss: 0.1530\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1358 - lambda_361_loss: 0.1638 - lambda_366_loss: 0.1358 - val_loss: 0.1429 - val_lambda_361_loss: 0.1734 - val_lambda_366_loss: 0.1429\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1357 - lambda_361_loss: 0.1641 - lambda_366_loss: 0.1357 - val_loss: 0.1453 - val_lambda_361_loss: 0.1740 - val_lambda_366_loss: 0.1453\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1316 - lambda_361_loss: 0.1590 - lambda_366_loss: 0.1316 - val_loss: 0.1360 - val_lambda_361_loss: 0.1630 - val_lambda_366_loss: 0.1360\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1307 - lambda_361_loss: 0.1583 - lambda_366_loss: 0.1307 - val_loss: 0.1413 - val_lambda_361_loss: 0.1672 - val_lambda_366_loss: 0.1413\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1275 - lambda_361_loss: 0.1547 - lambda_366_loss: 0.1275 - val_loss: 0.1345 - val_lambda_361_loss: 0.1603 - val_lambda_366_loss: 0.1345\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1262 - lambda_361_loss: 0.1525 - lambda_366_loss: 0.1262 - val_loss: 0.1315 - val_lambda_361_loss: 0.1628 - val_lambda_366_loss: 0.1315\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1250 - lambda_361_loss: 0.1512 - lambda_366_loss: 0.1250 - val_loss: 0.1252 - val_lambda_361_loss: 0.1532 - val_lambda_366_loss: 0.1252\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1244 - lambda_361_loss: 0.1506 - lambda_366_loss: 0.1244 - val_loss: 0.1294 - val_lambda_361_loss: 0.1540 - val_lambda_366_loss: 0.1294\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1231 - lambda_361_loss: 0.1495 - lambda_366_loss: 0.1231 - val_loss: 0.1355 - val_lambda_361_loss: 0.1660 - val_lambda_366_loss: 0.1355\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1227 - lambda_361_loss: 0.1486 - lambda_366_loss: 0.1227 - val_loss: 0.1209 - val_lambda_361_loss: 0.1505 - val_lambda_366_loss: 0.1209\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1216 - lambda_361_loss: 0.1471 - lambda_366_loss: 0.1216 - val_loss: 0.1353 - val_lambda_361_loss: 0.1584 - val_lambda_366_loss: 0.1353\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1207 - lambda_361_loss: 0.1461 - lambda_366_loss: 0.1207 - val_loss: 0.1251 - val_lambda_361_loss: 0.1539 - val_lambda_366_loss: 0.1251\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1194 - lambda_361_loss: 0.1452 - lambda_366_loss: 0.1194 - val_loss: 0.1322 - val_lambda_361_loss: 0.1561 - val_lambda_366_loss: 0.1322\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1196 - lambda_361_loss: 0.1450 - lambda_366_loss: 0.1196 - val_loss: 0.1304 - val_lambda_361_loss: 0.1555 - val_lambda_366_loss: 0.1304\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1188 - lambda_361_loss: 0.1444 - lambda_366_loss: 0.1188 - val_loss: 0.1295 - val_lambda_361_loss: 0.1519 - val_lambda_366_loss: 0.1295\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1181 - lambda_361_loss: 0.1431 - lambda_366_loss: 0.1181 - val_loss: 0.1271 - val_lambda_361_loss: 0.1547 - val_lambda_366_loss: 0.1271\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1178 - lambda_361_loss: 0.1425 - lambda_366_loss: 0.1178 - val_loss: 0.1258 - val_lambda_361_loss: 0.1509 - val_lambda_366_loss: 0.1258\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1170 - lambda_361_loss: 0.1419 - lambda_366_loss: 0.1170 - val_loss: 0.1214 - val_lambda_361_loss: 0.1450 - val_lambda_366_loss: 0.1214\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1157 - lambda_361_loss: 0.1397 - lambda_366_loss: 0.1157 - val_loss: 0.1341 - val_lambda_361_loss: 0.1548 - val_lambda_366_loss: 0.1341\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1163 - lambda_361_loss: 0.1412 - lambda_366_loss: 0.1163 - val_loss: 0.1292 - val_lambda_361_loss: 0.1535 - val_lambda_366_loss: 0.1292\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1161 - lambda_361_loss: 0.1405 - lambda_366_loss: 0.1161 - val_loss: 0.1280 - val_lambda_361_loss: 0.1504 - val_lambda_366_loss: 0.1280\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1146 - lambda_361_loss: 0.1385 - lambda_366_loss: 0.1146 - val_loss: 0.1248 - val_lambda_361_loss: 0.1563 - val_lambda_366_loss: 0.1248\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1151 - lambda_361_loss: 0.1394 - lambda_366_loss: 0.1151 - val_loss: 0.1208 - val_lambda_361_loss: 0.1480 - val_lambda_366_loss: 0.1208\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1139 - lambda_361_loss: 0.1375 - lambda_366_loss: 0.1139 - val_loss: 0.1303 - val_lambda_361_loss: 0.1530 - val_lambda_366_loss: 0.1303\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1137 - lambda_361_loss: 0.1376 - lambda_366_loss: 0.1137 - val_loss: 0.1283 - val_lambda_361_loss: 0.1493 - val_lambda_366_loss: 0.1283\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1145 - lambda_361_loss: 0.1385 - lambda_366_loss: 0.1145 - val_loss: 0.1264 - val_lambda_361_loss: 0.1499 - val_lambda_366_loss: 0.1264\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1142 - lambda_361_loss: 0.1382 - lambda_366_loss: 0.1142 - val_loss: 0.1288 - val_lambda_361_loss: 0.1532 - val_lambda_366_loss: 0.1288\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1135 - lambda_361_loss: 0.1373 - lambda_366_loss: 0.1135 - val_loss: 0.1308 - val_lambda_361_loss: 0.1579 - val_lambda_366_loss: 0.1308\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1124 - lambda_361_loss: 0.1361 - lambda_366_loss: 0.1124 - val_loss: 0.1248 - val_lambda_361_loss: 0.1496 - val_lambda_366_loss: 0.1248\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1126 - lambda_361_loss: 0.1362 - lambda_366_loss: 0.1126 - val_loss: 0.1267 - val_lambda_361_loss: 0.1531 - val_lambda_366_loss: 0.1267\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1126 - lambda_361_loss: 0.1364 - lambda_366_loss: 0.1126 - val_loss: 0.1205 - val_lambda_361_loss: 0.1437 - val_lambda_366_loss: 0.1205\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1131 - lambda_361_loss: 0.1370 - lambda_366_loss: 0.1131 - val_loss: 0.1186 - val_lambda_361_loss: 0.1485 - val_lambda_366_loss: 0.1186\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1104 - lambda_361_loss: 0.1336 - lambda_366_loss: 0.1104 - val_loss: 0.1246 - val_lambda_361_loss: 0.1477 - val_lambda_366_loss: 0.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1120 - lambda_361_loss: 0.1355 - lambda_366_loss: 0.1120 - val_loss: 0.1216 - val_lambda_361_loss: 0.1458 - val_lambda_366_loss: 0.1216\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1113 - lambda_361_loss: 0.1346 - lambda_366_loss: 0.1113 - val_loss: 0.1173 - val_lambda_361_loss: 0.1380 - val_lambda_366_loss: 0.1173\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1106 - lambda_361_loss: 0.1337 - lambda_366_loss: 0.1106 - val_loss: 0.1193 - val_lambda_361_loss: 0.1416 - val_lambda_366_loss: 0.1193\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1228 - lambda_361_loss: 0.1499 - lambda_366_loss: 0.1228 - val_loss: 0.1318 - val_lambda_361_loss: 0.1579 - val_lambda_366_loss: 0.1318\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1161 - lambda_361_loss: 0.1413 - lambda_366_loss: 0.1161 - val_loss: 0.1228 - val_lambda_361_loss: 0.1509 - val_lambda_366_loss: 0.1228\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1101 - lambda_361_loss: 0.1332 - lambda_366_loss: 0.1101 - val_loss: 0.1215 - val_lambda_361_loss: 0.1430 - val_lambda_366_loss: 0.1215\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1100 - lambda_361_loss: 0.1329 - lambda_366_loss: 0.1100 - val_loss: 0.1322 - val_lambda_361_loss: 0.1556 - val_lambda_366_loss: 0.1322\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1101 - lambda_361_loss: 0.1332 - lambda_366_loss: 0.1101 - val_loss: 0.1231 - val_lambda_361_loss: 0.1428 - val_lambda_366_loss: 0.1231\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1093 - lambda_361_loss: 0.1322 - lambda_366_loss: 0.1093 - val_loss: 0.1245 - val_lambda_361_loss: 0.1482 - val_lambda_366_loss: 0.1245\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1089 - lambda_361_loss: 0.1314 - lambda_366_loss: 0.1089 - val_loss: 0.1244 - val_lambda_361_loss: 0.1480 - val_lambda_366_loss: 0.1244\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1089 - lambda_361_loss: 0.1316 - lambda_366_loss: 0.1089 - val_loss: 0.1242 - val_lambda_361_loss: 0.1483 - val_lambda_366_loss: 0.1242\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1089 - lambda_361_loss: 0.1317 - lambda_366_loss: 0.1089 - val_loss: 0.1258 - val_lambda_361_loss: 0.1502 - val_lambda_366_loss: 0.1258\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_371 (Lambda)             (None, 256, 256, 2)  0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 256, 256, 48) 912         lambda_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 256, 256, 2)  98          conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 256, 256, 2)  0           conv2d_234[0][0]                 \n",
      "                                                                 lambda_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_376 (Lambda)             (None, 256, 256, 2)  0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 256, 256, 2)  0           lambda_376[0][0]                 \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 256, 256, 2)  0           multiply_39[0][0]                \n",
      "                                                                 input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 256, 256, 48) 912         add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 256, 256, 2)  98          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 256, 256, 2)  0           conv2d_240[0][0]                 \n",
      "                                                                 add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 256, 256, 2)  0           add_79[0][0]                     \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 256, 256, 2)  0           multiply_40[0][0]                \n",
      "                                                                 input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_381 (Lambda)             (None, 256, 256, 2)  0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 256, 256, 48) 912         lambda_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 256, 256, 2)  98          conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 256, 256, 2)  0           conv2d_246[0][0]                 \n",
      "                                                                 lambda_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_386 (Lambda)             (None, 256, 256, 2)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 256, 256, 2)  0           lambda_386[0][0]                 \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 256, 256, 2)  0           multiply_41[0][0]                \n",
      "                                                                 input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_391 (Lambda)             (None, 256, 256, 2)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 256, 256, 48) 912         lambda_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 256, 256, 2)  98          conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 256, 256, 2)  0           conv2d_252[0][0]                 \n",
      "                                                                 lambda_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_396 (Lambda)             (None, 256, 256, 2)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 256, 256, 2)  0           lambda_396[0][0]                 \n",
      "                                                                 input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 256, 256, 2)  0           multiply_42[0][0]                \n",
      "                                                                 input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_401 (Lambda)             (None, 256, 256, 2)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_406 (Lambda)             (None, 256, 256, 1)  0           lambda_401[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ikii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.1890 - lambda_401_loss: 0.2173 - lambda_406_loss: 0.1890 - val_loss: 0.1255 - val_lambda_401_loss: 0.1396 - val_lambda_406_loss: 0.1255\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1251 - lambda_401_loss: 0.1484 - lambda_406_loss: 0.1251 - val_loss: 0.1109 - val_lambda_401_loss: 0.1343 - val_lambda_406_loss: 0.1109\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1077 - lambda_401_loss: 0.1240 - lambda_406_loss: 0.1077 - val_loss: 0.1073 - val_lambda_401_loss: 0.1204 - val_lambda_406_loss: 0.1073\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1012 - lambda_401_loss: 0.1170 - lambda_406_loss: 0.1012 - val_loss: 0.1129 - val_lambda_401_loss: 0.1445 - val_lambda_406_loss: 0.1129\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0971 - lambda_401_loss: 0.1122 - lambda_406_loss: 0.0971 - val_loss: 0.0962 - val_lambda_401_loss: 0.1096 - val_lambda_406_loss: 0.0962\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0937 - lambda_401_loss: 0.1070 - lambda_406_loss: 0.0937 - val_loss: 0.1019 - val_lambda_401_loss: 0.1133 - val_lambda_406_loss: 0.1019\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0923 - lambda_401_loss: 0.1067 - lambda_406_loss: 0.0923 - val_loss: 0.1089 - val_lambda_401_loss: 0.1244 - val_lambda_406_loss: 0.1089\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0892 - lambda_401_loss: 0.1022 - lambda_406_loss: 0.0892 - val_loss: 0.0920 - val_lambda_401_loss: 0.1000 - val_lambda_406_loss: 0.0920\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0872 - lambda_401_loss: 0.0986 - lambda_406_loss: 0.0872 - val_loss: 0.0899 - val_lambda_401_loss: 0.1054 - val_lambda_406_loss: 0.0899\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0848 - lambda_401_loss: 0.0960 - lambda_406_loss: 0.0848 - val_loss: 0.0937 - val_lambda_401_loss: 0.1210 - val_lambda_406_loss: 0.0937\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0855 - lambda_401_loss: 0.0981 - lambda_406_loss: 0.0855 - val_loss: 0.0964 - val_lambda_401_loss: 0.1097 - val_lambda_406_loss: 0.0964\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0825 - lambda_401_loss: 0.0927 - lambda_406_loss: 0.0825 - val_loss: 0.0914 - val_lambda_401_loss: 0.1072 - val_lambda_406_loss: 0.0914\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0822 - lambda_401_loss: 0.0926 - lambda_406_loss: 0.0822 - val_loss: 0.0961 - val_lambda_401_loss: 0.1090 - val_lambda_406_loss: 0.0961\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0805 - lambda_401_loss: 0.0908 - lambda_406_loss: 0.0805 - val_loss: 0.0893 - val_lambda_401_loss: 0.1006 - val_lambda_406_loss: 0.0893\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0805 - lambda_401_loss: 0.0909 - lambda_406_loss: 0.0805 - val_loss: 0.0893 - val_lambda_401_loss: 0.1043 - val_lambda_406_loss: 0.0893\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0797 - lambda_401_loss: 0.0901 - lambda_406_loss: 0.0797 - val_loss: 0.0893 - val_lambda_401_loss: 0.1011 - val_lambda_406_loss: 0.0893\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0785 - lambda_401_loss: 0.0884 - lambda_406_loss: 0.0785 - val_loss: 0.0856 - val_lambda_401_loss: 0.0958 - val_lambda_406_loss: 0.0856\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0784 - lambda_401_loss: 0.0881 - lambda_406_loss: 0.0784 - val_loss: 0.0881 - val_lambda_401_loss: 0.0989 - val_lambda_406_loss: 0.0881\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0764 - lambda_401_loss: 0.0854 - lambda_406_loss: 0.0764 - val_loss: 0.0911 - val_lambda_401_loss: 0.1009 - val_lambda_406_loss: 0.0911\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0771 - lambda_401_loss: 0.0868 - lambda_406_loss: 0.0771 - val_loss: 0.0895 - val_lambda_401_loss: 0.1038 - val_lambda_406_loss: 0.0895\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0752 - lambda_401_loss: 0.0846 - lambda_406_loss: 0.0752 - val_loss: 0.0887 - val_lambda_401_loss: 0.1000 - val_lambda_406_loss: 0.0887\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0758 - lambda_401_loss: 0.0849 - lambda_406_loss: 0.0758 - val_loss: 0.0876 - val_lambda_401_loss: 0.0992 - val_lambda_406_loss: 0.0876\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0749 - lambda_401_loss: 0.0838 - lambda_406_loss: 0.0749 - val_loss: 0.0842 - val_lambda_401_loss: 0.0956 - val_lambda_406_loss: 0.0842\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0748 - lambda_401_loss: 0.0836 - lambda_406_loss: 0.0748 - val_loss: 0.0807 - val_lambda_401_loss: 0.0914 - val_lambda_406_loss: 0.0807\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0742 - lambda_401_loss: 0.0831 - lambda_406_loss: 0.0742 - val_loss: 0.0829 - val_lambda_401_loss: 0.0908 - val_lambda_406_loss: 0.0829\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0743 - lambda_401_loss: 0.0835 - lambda_406_loss: 0.0743 - val_loss: 0.0912 - val_lambda_401_loss: 0.1018 - val_lambda_406_loss: 0.0912\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0734 - lambda_401_loss: 0.0820 - lambda_406_loss: 0.0734 - val_loss: 0.0811 - val_lambda_401_loss: 0.0898 - val_lambda_406_loss: 0.0811\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0727 - lambda_401_loss: 0.0810 - lambda_406_loss: 0.0727 - val_loss: 0.0869 - val_lambda_401_loss: 0.1027 - val_lambda_406_loss: 0.0869\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0736 - lambda_401_loss: 0.0822 - lambda_406_loss: 0.0736 - val_loss: 0.0821 - val_lambda_401_loss: 0.0919 - val_lambda_406_loss: 0.0821\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0729 - lambda_401_loss: 0.0816 - lambda_406_loss: 0.0729 - val_loss: 0.0886 - val_lambda_401_loss: 0.0960 - val_lambda_406_loss: 0.0886\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0728 - lambda_401_loss: 0.0816 - lambda_406_loss: 0.0728 - val_loss: 0.0815 - val_lambda_401_loss: 0.0901 - val_lambda_406_loss: 0.0815\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0720 - lambda_401_loss: 0.0801 - lambda_406_loss: 0.0720 - val_loss: 0.0860 - val_lambda_401_loss: 0.1008 - val_lambda_406_loss: 0.0860\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0716 - lambda_401_loss: 0.0799 - lambda_406_loss: 0.0716 - val_loss: 0.0836 - val_lambda_401_loss: 0.0912 - val_lambda_406_loss: 0.0836\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0722 - lambda_401_loss: 0.0810 - lambda_406_loss: 0.0722 - val_loss: 0.0791 - val_lambda_401_loss: 0.0923 - val_lambda_406_loss: 0.0791\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0706 - lambda_401_loss: 0.0786 - lambda_406_loss: 0.0706 - val_loss: 0.0830 - val_lambda_401_loss: 0.0945 - val_lambda_406_loss: 0.0830\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0706 - lambda_401_loss: 0.0793 - lambda_406_loss: 0.0706 - val_loss: 0.0882 - val_lambda_401_loss: 0.0972 - val_lambda_406_loss: 0.0882\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0708 - lambda_401_loss: 0.0790 - lambda_406_loss: 0.0708 - val_loss: 0.0857 - val_lambda_401_loss: 0.0964 - val_lambda_406_loss: 0.0857\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0701 - lambda_401_loss: 0.0783 - lambda_406_loss: 0.0701 - val_loss: 0.0827 - val_lambda_401_loss: 0.0905 - val_lambda_406_loss: 0.0827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0700 - lambda_401_loss: 0.0780 - lambda_406_loss: 0.0700 - val_loss: 0.0788 - val_lambda_401_loss: 0.0898 - val_lambda_406_loss: 0.0788\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0701 - lambda_401_loss: 0.0783 - lambda_406_loss: 0.0701 - val_loss: 0.0848 - val_lambda_401_loss: 0.0938 - val_lambda_406_loss: 0.0848\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0695 - lambda_401_loss: 0.0778 - lambda_406_loss: 0.0695 - val_loss: 0.0916 - val_lambda_401_loss: 0.1017 - val_lambda_406_loss: 0.0916\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0694 - lambda_401_loss: 0.0773 - lambda_406_loss: 0.0694 - val_loss: 0.0812 - val_lambda_401_loss: 0.0890 - val_lambda_406_loss: 0.0812\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0691 - lambda_401_loss: 0.0769 - lambda_406_loss: 0.0691 - val_loss: 0.0826 - val_lambda_401_loss: 0.0905 - val_lambda_406_loss: 0.0826\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0693 - lambda_401_loss: 0.0769 - lambda_406_loss: 0.0693 - val_loss: 0.0829 - val_lambda_401_loss: 0.0909 - val_lambda_406_loss: 0.0829\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0694 - lambda_401_loss: 0.0778 - lambda_406_loss: 0.0694 - val_loss: 0.0794 - val_lambda_401_loss: 0.0910 - val_lambda_406_loss: 0.0794\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0686 - lambda_401_loss: 0.0760 - lambda_406_loss: 0.0686 - val_loss: 0.0849 - val_lambda_401_loss: 0.0923 - val_lambda_406_loss: 0.0849\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0687 - lambda_401_loss: 0.0766 - lambda_406_loss: 0.0687 - val_loss: 0.0905 - val_lambda_401_loss: 0.1041 - val_lambda_406_loss: 0.0905\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0687 - lambda_401_loss: 0.0765 - lambda_406_loss: 0.0687 - val_loss: 0.0817 - val_lambda_401_loss: 0.0912 - val_lambda_406_loss: 0.0817\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0679 - lambda_401_loss: 0.0754 - lambda_406_loss: 0.0679 - val_loss: 0.0759 - val_lambda_401_loss: 0.0834 - val_lambda_406_loss: 0.0759\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0681 - lambda_401_loss: 0.0759 - lambda_406_loss: 0.0681 - val_loss: 0.0825 - val_lambda_401_loss: 0.0922 - val_lambda_406_loss: 0.0825\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 256, 256, 48) 912         input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 256, 256, 2)  98          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 256, 256, 2)  0           conv2d_258[0][0]                 \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 256, 256, 2)  0           add_85[0][0]                     \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 256, 256, 2)  0           multiply_43[0][0]                \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 256, 256, 48) 912         add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 256, 256, 2)  98          conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 256, 256, 2)  0           conv2d_264[0][0]                 \n",
      "                                                                 add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 256, 256, 2)  0           add_87[0][0]                     \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 256, 256, 2)  0           multiply_44[0][0]                \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 256, 256, 48) 912         add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 256, 256, 2)  98          conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 256, 256, 2)  0           conv2d_270[0][0]                 \n",
      "                                                                 add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 256, 256, 2)  0           add_89[0][0]                     \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 256, 256, 2)  0           multiply_45[0][0]                \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 256, 256, 48) 912         add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 256, 256, 2)  98          conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 256, 256, 2)  0           conv2d_276[0][0]                 \n",
      "                                                                 add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 256, 256, 2)  0           add_91[0][0]                     \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 256, 256, 2)  0           multiply_46[0][0]                \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_411 (Lambda)             (None, 256, 256, 2)  0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_416 (Lambda)             (None, 256, 256, 1)  0           lambda_411[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkkk_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.3776 - lambda_411_loss: 0.4484 - lambda_416_loss: 0.3776 - val_loss: 0.3248 - val_lambda_411_loss: 0.4006 - val_lambda_416_loss: 0.3248\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.3142 - lambda_411_loss: 0.3832 - lambda_416_loss: 0.3142 - val_loss: 0.2858 - val_lambda_411_loss: 0.3591 - val_lambda_416_loss: 0.2858\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2985 - lambda_411_loss: 0.3653 - lambda_416_loss: 0.2985 - val_loss: 0.2905 - val_lambda_411_loss: 0.3599 - val_lambda_416_loss: 0.2905\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2881 - lambda_411_loss: 0.3537 - lambda_416_loss: 0.2881 - val_loss: 0.2786 - val_lambda_411_loss: 0.3511 - val_lambda_416_loss: 0.2786\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2796 - lambda_411_loss: 0.3443 - lambda_416_loss: 0.2796 - val_loss: 0.2658 - val_lambda_411_loss: 0.3335 - val_lambda_416_loss: 0.2658\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2752 - lambda_411_loss: 0.3393 - lambda_416_loss: 0.2752 - val_loss: 0.2624 - val_lambda_411_loss: 0.3225 - val_lambda_416_loss: 0.2624\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2724 - lambda_411_loss: 0.3364 - lambda_416_loss: 0.2724 - val_loss: 0.2590 - val_lambda_411_loss: 0.3199 - val_lambda_416_loss: 0.2590\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2676 - lambda_411_loss: 0.3306 - lambda_416_loss: 0.2676 - val_loss: 0.2615 - val_lambda_411_loss: 0.3268 - val_lambda_416_loss: 0.2615\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2650 - lambda_411_loss: 0.3275 - lambda_416_loss: 0.2650 - val_loss: 0.2679 - val_lambda_411_loss: 0.3364 - val_lambda_416_loss: 0.2679\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2608 - lambda_411_loss: 0.3230 - lambda_416_loss: 0.2608 - val_loss: 0.2519 - val_lambda_411_loss: 0.3135 - val_lambda_416_loss: 0.2519\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2597 - lambda_411_loss: 0.3220 - lambda_416_loss: 0.2597 - val_loss: 0.2494 - val_lambda_411_loss: 0.3141 - val_lambda_416_loss: 0.2494\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2579 - lambda_411_loss: 0.3197 - lambda_416_loss: 0.2579 - val_loss: 0.2534 - val_lambda_411_loss: 0.3168 - val_lambda_416_loss: 0.2534\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2554 - lambda_411_loss: 0.3168 - lambda_416_loss: 0.2554 - val_loss: 0.2460 - val_lambda_411_loss: 0.3075 - val_lambda_416_loss: 0.2460\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2529 - lambda_411_loss: 0.3144 - lambda_416_loss: 0.2529 - val_loss: 0.2412 - val_lambda_411_loss: 0.3051 - val_lambda_416_loss: 0.2412\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2531 - lambda_411_loss: 0.3144 - lambda_416_loss: 0.2531 - val_loss: 0.2471 - val_lambda_411_loss: 0.3126 - val_lambda_416_loss: 0.2471\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2515 - lambda_411_loss: 0.3130 - lambda_416_loss: 0.2515 - val_loss: 0.2372 - val_lambda_411_loss: 0.2981 - val_lambda_416_loss: 0.2372\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2516 - lambda_411_loss: 0.3127 - lambda_416_loss: 0.2516 - val_loss: 0.2405 - val_lambda_411_loss: 0.3005 - val_lambda_416_loss: 0.2405\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2481 - lambda_411_loss: 0.3092 - lambda_416_loss: 0.2481 - val_loss: 0.2362 - val_lambda_411_loss: 0.3038 - val_lambda_416_loss: 0.2362\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2480 - lambda_411_loss: 0.3087 - lambda_416_loss: 0.2480 - val_loss: 0.2348 - val_lambda_411_loss: 0.2958 - val_lambda_416_loss: 0.2348\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2441 - lambda_411_loss: 0.3047 - lambda_416_loss: 0.2441 - val_loss: 0.2378 - val_lambda_411_loss: 0.3009 - val_lambda_416_loss: 0.2378\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2432 - lambda_411_loss: 0.3033 - lambda_416_loss: 0.2432 - val_loss: 0.2364 - val_lambda_411_loss: 0.2993 - val_lambda_416_loss: 0.2364\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2461 - lambda_411_loss: 0.3070 - lambda_416_loss: 0.2461 - val_loss: 0.2314 - val_lambda_411_loss: 0.2944 - val_lambda_416_loss: 0.2314\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2428 - lambda_411_loss: 0.3031 - lambda_416_loss: 0.2428 - val_loss: 0.2336 - val_lambda_411_loss: 0.2951 - val_lambda_416_loss: 0.2336\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2432 - lambda_411_loss: 0.3034 - lambda_416_loss: 0.2432 - val_loss: 0.2328 - val_lambda_411_loss: 0.2935 - val_lambda_416_loss: 0.2328\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2397 - lambda_411_loss: 0.2999 - lambda_416_loss: 0.2397 - val_loss: 0.2309 - val_lambda_411_loss: 0.2882 - val_lambda_416_loss: 0.2309\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2398 - lambda_411_loss: 0.2997 - lambda_416_loss: 0.2398 - val_loss: 0.2282 - val_lambda_411_loss: 0.2878 - val_lambda_416_loss: 0.2282\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2405 - lambda_411_loss: 0.3009 - lambda_416_loss: 0.2405 - val_loss: 0.2403 - val_lambda_411_loss: 0.3048 - val_lambda_416_loss: 0.2403\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2383 - lambda_411_loss: 0.2983 - lambda_416_loss: 0.2383 - val_loss: 0.2253 - val_lambda_411_loss: 0.2845 - val_lambda_416_loss: 0.2253\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2391 - lambda_411_loss: 0.2987 - lambda_416_loss: 0.2391 - val_loss: 0.2286 - val_lambda_411_loss: 0.2868 - val_lambda_416_loss: 0.2286\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2361 - lambda_411_loss: 0.2956 - lambda_416_loss: 0.2361 - val_loss: 0.2251 - val_lambda_411_loss: 0.2825 - val_lambda_416_loss: 0.2251\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2365 - lambda_411_loss: 0.2966 - lambda_416_loss: 0.2365 - val_loss: 0.2284 - val_lambda_411_loss: 0.2890 - val_lambda_416_loss: 0.2284\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2352 - lambda_411_loss: 0.2945 - lambda_416_loss: 0.2352 - val_loss: 0.2255 - val_lambda_411_loss: 0.2829 - val_lambda_416_loss: 0.2255\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 104s 155ms/step - loss: 0.2352 - lambda_411_loss: 0.2948 - lambda_416_loss: 0.2352 - val_loss: 0.2221 - val_lambda_411_loss: 0.2826 - val_lambda_416_loss: 0.2221\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2345 - lambda_411_loss: 0.2937 - lambda_416_loss: 0.2345 - val_loss: 0.2228 - val_lambda_411_loss: 0.2818 - val_lambda_416_loss: 0.2228\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2327 - lambda_411_loss: 0.2918 - lambda_416_loss: 0.2327 - val_loss: 0.2242 - val_lambda_411_loss: 0.2814 - val_lambda_416_loss: 0.2242\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2303 - lambda_411_loss: 0.2892 - lambda_416_loss: 0.2303 - val_loss: 0.2188 - val_lambda_411_loss: 0.2802 - val_lambda_416_loss: 0.2188\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2321 - lambda_411_loss: 0.2913 - lambda_416_loss: 0.2321 - val_loss: 0.2257 - val_lambda_411_loss: 0.2800 - val_lambda_416_loss: 0.2257\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2323 - lambda_411_loss: 0.2910 - lambda_416_loss: 0.2323 - val_loss: 0.2206 - val_lambda_411_loss: 0.2761 - val_lambda_416_loss: 0.2206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2308 - lambda_411_loss: 0.2898 - lambda_416_loss: 0.2308 - val_loss: 0.2191 - val_lambda_411_loss: 0.2784 - val_lambda_416_loss: 0.2191\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2313 - lambda_411_loss: 0.2902 - lambda_416_loss: 0.2313 - val_loss: 0.2216 - val_lambda_411_loss: 0.2792 - val_lambda_416_loss: 0.2216\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2310 - lambda_411_loss: 0.2897 - lambda_416_loss: 0.2310 - val_loss: 0.2280 - val_lambda_411_loss: 0.2803 - val_lambda_416_loss: 0.2280\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2291 - lambda_411_loss: 0.2883 - lambda_416_loss: 0.2291 - val_loss: 0.2219 - val_lambda_411_loss: 0.2815 - val_lambda_416_loss: 0.2219\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2292 - lambda_411_loss: 0.2879 - lambda_416_loss: 0.2292 - val_loss: 0.2202 - val_lambda_411_loss: 0.2793 - val_lambda_416_loss: 0.2202\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2270 - lambda_411_loss: 0.2857 - lambda_416_loss: 0.2270 - val_loss: 0.2182 - val_lambda_411_loss: 0.2746 - val_lambda_416_loss: 0.2182\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.2282 - lambda_411_loss: 0.2867 - lambda_416_loss: 0.2282 - val_loss: 0.2218 - val_lambda_411_loss: 0.2838 - val_lambda_416_loss: 0.2218\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2282 - lambda_411_loss: 0.2868 - lambda_416_loss: 0.2282 - val_loss: 0.2196 - val_lambda_411_loss: 0.2788 - val_lambda_416_loss: 0.2196\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2262 - lambda_411_loss: 0.2849 - lambda_416_loss: 0.2262 - val_loss: 0.2171 - val_lambda_411_loss: 0.2740 - val_lambda_416_loss: 0.2171\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2278 - lambda_411_loss: 0.2865 - lambda_416_loss: 0.2278 - val_loss: 0.2156 - val_lambda_411_loss: 0.2737 - val_lambda_416_loss: 0.2156\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2272 - lambda_411_loss: 0.2855 - lambda_416_loss: 0.2272 - val_loss: 0.2273 - val_lambda_411_loss: 0.2899 - val_lambda_416_loss: 0.2273\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2263 - lambda_411_loss: 0.2852 - lambda_416_loss: 0.2263 - val_loss: 0.2176 - val_lambda_411_loss: 0.2765 - val_lambda_416_loss: 0.2176\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 256, 256, 48) 912         input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 256, 256, 2)  98          conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 256, 256, 2)  0           conv2d_282[0][0]                 \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 256, 256, 2)  0           add_93[0][0]                     \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 256, 256, 2)  0           multiply_47[0][0]                \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_421 (Lambda)             (None, 256, 256, 2)  0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 256, 256, 48) 912         lambda_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 256, 256, 2)  98          conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 256, 256, 2)  0           conv2d_288[0][0]                 \n",
      "                                                                 lambda_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_426 (Lambda)             (None, 256, 256, 2)  0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 256, 256, 2)  0           lambda_426[0][0]                 \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 256, 256, 2)  0           multiply_48[0][0]                \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_431 (Lambda)             (None, 256, 256, 2)  0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 256, 256, 48) 912         lambda_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 256, 256, 2)  98          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 256, 256, 2)  0           conv2d_294[0][0]                 \n",
      "                                                                 lambda_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_436 (Lambda)             (None, 256, 256, 2)  0           add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 256, 256, 2)  0           lambda_436[0][0]                 \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 256, 256, 2)  0           multiply_49[0][0]                \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_441 (Lambda)             (None, 256, 256, 2)  0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 256, 256, 48) 912         lambda_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 256, 256, 2)  98          conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 256, 256, 2)  0           conv2d_300[0][0]                 \n",
      "                                                                 lambda_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_446 (Lambda)             (None, 256, 256, 2)  0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 256, 256, 2)  0           lambda_446[0][0]                 \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 256, 256, 2)  0           multiply_50[0][0]                \n",
      "                                                                 input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_451 (Lambda)             (None, 256, 256, 2)  0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_456 (Lambda)             (None, 256, 256, 1)  0           lambda_451[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 113s 169ms/step - loss: 0.1843 - lambda_451_loss: 0.2093 - lambda_456_loss: 0.1843 - val_loss: 0.1510 - val_lambda_451_loss: 0.1746 - val_lambda_456_loss: 0.1510\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1308 - lambda_451_loss: 0.1544 - lambda_456_loss: 0.1308 - val_loss: 0.1219 - val_lambda_451_loss: 0.1408 - val_lambda_456_loss: 0.1219\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1189 - lambda_451_loss: 0.1401 - lambda_456_loss: 0.1189 - val_loss: 0.1091 - val_lambda_451_loss: 0.1260 - val_lambda_456_loss: 0.1091\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1067 - lambda_451_loss: 0.1256 - lambda_456_loss: 0.1067 - val_loss: 0.1005 - val_lambda_451_loss: 0.1216 - val_lambda_456_loss: 0.1005\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1015 - lambda_451_loss: 0.1172 - lambda_456_loss: 0.1015 - val_loss: 0.1051 - val_lambda_451_loss: 0.1145 - val_lambda_456_loss: 0.1051\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0978 - lambda_451_loss: 0.1131 - lambda_456_loss: 0.0978 - val_loss: 0.0985 - val_lambda_451_loss: 0.1098 - val_lambda_456_loss: 0.0985\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0967 - lambda_451_loss: 0.1131 - lambda_456_loss: 0.0967 - val_loss: 0.1038 - val_lambda_451_loss: 0.1219 - val_lambda_456_loss: 0.1038\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0935 - lambda_451_loss: 0.1075 - lambda_456_loss: 0.0935 - val_loss: 0.0976 - val_lambda_451_loss: 0.1142 - val_lambda_456_loss: 0.0976\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0914 - lambda_451_loss: 0.1050 - lambda_456_loss: 0.0914 - val_loss: 0.0928 - val_lambda_451_loss: 0.1030 - val_lambda_456_loss: 0.0928\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0897 - lambda_451_loss: 0.1038 - lambda_456_loss: 0.0897 - val_loss: 0.1020 - val_lambda_451_loss: 0.1175 - val_lambda_456_loss: 0.1020\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0897 - lambda_451_loss: 0.1028 - lambda_456_loss: 0.0897 - val_loss: 0.0954 - val_lambda_451_loss: 0.1082 - val_lambda_456_loss: 0.0954\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0882 - lambda_451_loss: 0.1016 - lambda_456_loss: 0.0882 - val_loss: 0.0912 - val_lambda_451_loss: 0.0999 - val_lambda_456_loss: 0.0912\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0857 - lambda_451_loss: 0.0981 - lambda_456_loss: 0.0857 - val_loss: 0.0907 - val_lambda_451_loss: 0.1018 - val_lambda_456_loss: 0.0907\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0849 - lambda_451_loss: 0.0966 - lambda_456_loss: 0.0849 - val_loss: 0.0865 - val_lambda_451_loss: 0.0969 - val_lambda_456_loss: 0.0865\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0852 - lambda_451_loss: 0.0978 - lambda_456_loss: 0.0852 - val_loss: 0.0921 - val_lambda_451_loss: 0.1028 - val_lambda_456_loss: 0.0921\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0830 - lambda_451_loss: 0.0948 - lambda_456_loss: 0.0830 - val_loss: 0.0917 - val_lambda_451_loss: 0.1048 - val_lambda_456_loss: 0.0917\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0830 - lambda_451_loss: 0.0951 - lambda_456_loss: 0.0830 - val_loss: 0.0867 - val_lambda_451_loss: 0.1037 - val_lambda_456_loss: 0.0867\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0814 - lambda_451_loss: 0.0922 - lambda_456_loss: 0.0814 - val_loss: 0.0887 - val_lambda_451_loss: 0.0966 - val_lambda_456_loss: 0.0887\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0812 - lambda_451_loss: 0.0924 - lambda_456_loss: 0.0812 - val_loss: 0.0884 - val_lambda_451_loss: 0.0996 - val_lambda_456_loss: 0.0884\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0828 - lambda_451_loss: 0.0950 - lambda_456_loss: 0.0828 - val_loss: 0.0945 - val_lambda_451_loss: 0.1061 - val_lambda_456_loss: 0.0945\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0797 - lambda_451_loss: 0.0898 - lambda_456_loss: 0.0797 - val_loss: 0.0849 - val_lambda_451_loss: 0.0950 - val_lambda_456_loss: 0.0849\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0793 - lambda_451_loss: 0.0894 - lambda_456_loss: 0.0793 - val_loss: 0.0847 - val_lambda_451_loss: 0.0953 - val_lambda_456_loss: 0.0847\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0792 - lambda_451_loss: 0.0902 - lambda_456_loss: 0.0792 - val_loss: 0.0891 - val_lambda_451_loss: 0.0991 - val_lambda_456_loss: 0.0891\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0789 - lambda_451_loss: 0.0892 - lambda_456_loss: 0.0789 - val_loss: 0.0856 - val_lambda_451_loss: 0.1004 - val_lambda_456_loss: 0.0856\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0779 - lambda_451_loss: 0.0880 - lambda_456_loss: 0.0779 - val_loss: 0.0946 - val_lambda_451_loss: 0.1023 - val_lambda_456_loss: 0.0946\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0771 - lambda_451_loss: 0.0867 - lambda_456_loss: 0.0771 - val_loss: 0.0856 - val_lambda_451_loss: 0.0944 - val_lambda_456_loss: 0.0856\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0772 - lambda_451_loss: 0.0875 - lambda_456_loss: 0.0772 - val_loss: 0.0854 - val_lambda_451_loss: 0.0975 - val_lambda_456_loss: 0.0854\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0771 - lambda_451_loss: 0.0871 - lambda_456_loss: 0.0771 - val_loss: 0.0841 - val_lambda_451_loss: 0.0943 - val_lambda_456_loss: 0.0841\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0785 - lambda_451_loss: 0.0898 - lambda_456_loss: 0.0785 - val_loss: 0.0871 - val_lambda_451_loss: 0.1094 - val_lambda_456_loss: 0.0871\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0771 - lambda_451_loss: 0.0872 - lambda_456_loss: 0.0771 - val_loss: 0.0851 - val_lambda_451_loss: 0.0944 - val_lambda_456_loss: 0.0851\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0766 - lambda_451_loss: 0.0864 - lambda_456_loss: 0.0766 - val_loss: 0.0865 - val_lambda_451_loss: 0.0988 - val_lambda_456_loss: 0.0865\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0751 - lambda_451_loss: 0.0849 - lambda_456_loss: 0.0751 - val_loss: 0.0857 - val_lambda_451_loss: 0.0967 - val_lambda_456_loss: 0.0857\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0744 - lambda_451_loss: 0.0834 - lambda_456_loss: 0.0744 - val_loss: 0.0842 - val_lambda_451_loss: 0.0927 - val_lambda_456_loss: 0.0842\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0750 - lambda_451_loss: 0.0846 - lambda_456_loss: 0.0750 - val_loss: 0.0824 - val_lambda_451_loss: 0.0917 - val_lambda_456_loss: 0.0824\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0751 - lambda_451_loss: 0.0848 - lambda_456_loss: 0.0751 - val_loss: 0.1005 - val_lambda_451_loss: 0.1187 - val_lambda_456_loss: 0.1005\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0765 - lambda_451_loss: 0.0867 - lambda_456_loss: 0.0765 - val_loss: 0.0878 - val_lambda_451_loss: 0.1001 - val_lambda_456_loss: 0.0878\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0737 - lambda_451_loss: 0.0830 - lambda_456_loss: 0.0737 - val_loss: 0.0901 - val_lambda_451_loss: 0.1016 - val_lambda_456_loss: 0.0901\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0736 - lambda_451_loss: 0.0828 - lambda_456_loss: 0.0736 - val_loss: 0.0850 - val_lambda_451_loss: 0.0924 - val_lambda_456_loss: 0.0850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0738 - lambda_451_loss: 0.0830 - lambda_456_loss: 0.0738 - val_loss: 0.0800 - val_lambda_451_loss: 0.0908 - val_lambda_456_loss: 0.0800\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0735 - lambda_451_loss: 0.0825 - lambda_456_loss: 0.0735 - val_loss: 0.0806 - val_lambda_451_loss: 0.0905 - val_lambda_456_loss: 0.0806\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0733 - lambda_451_loss: 0.0822 - lambda_456_loss: 0.0733 - val_loss: 0.0812 - val_lambda_451_loss: 0.0924 - val_lambda_456_loss: 0.0812\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0728 - lambda_451_loss: 0.0814 - lambda_456_loss: 0.0728 - val_loss: 0.0829 - val_lambda_451_loss: 0.0971 - val_lambda_456_loss: 0.0829\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0727 - lambda_451_loss: 0.0815 - lambda_456_loss: 0.0727 - val_loss: 0.0813 - val_lambda_451_loss: 0.0902 - val_lambda_456_loss: 0.0813\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0728 - lambda_451_loss: 0.0819 - lambda_456_loss: 0.0728 - val_loss: 0.0852 - val_lambda_451_loss: 0.0947 - val_lambda_456_loss: 0.0852\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0717 - lambda_451_loss: 0.0799 - lambda_456_loss: 0.0717 - val_loss: 0.0809 - val_lambda_451_loss: 0.0903 - val_lambda_456_loss: 0.0809\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0711 - lambda_451_loss: 0.0798 - lambda_456_loss: 0.0711 - val_loss: 0.0784 - val_lambda_451_loss: 0.0866 - val_lambda_456_loss: 0.0784\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0720 - lambda_451_loss: 0.0805 - lambda_456_loss: 0.0720 - val_loss: 0.0794 - val_lambda_451_loss: 0.0888 - val_lambda_456_loss: 0.0794\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0713 - lambda_451_loss: 0.0797 - lambda_456_loss: 0.0713 - val_loss: 0.0780 - val_lambda_451_loss: 0.0868 - val_lambda_456_loss: 0.0780\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0714 - lambda_451_loss: 0.0802 - lambda_456_loss: 0.0714 - val_loss: 0.0873 - val_lambda_451_loss: 0.1006 - val_lambda_456_loss: 0.0873\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0713 - lambda_451_loss: 0.0799 - lambda_456_loss: 0.0713 - val_loss: 0.0812 - val_lambda_451_loss: 0.0894 - val_lambda_456_loss: 0.0812\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 256, 256, 48) 912         input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 256, 256, 2)  98          conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 256, 256, 2)  0           conv2d_306[0][0]                 \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 256, 256, 2)  0           add_101[0][0]                    \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 256, 256, 2)  0           multiply_51[0][0]                \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 256, 256, 48) 912         add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 256, 256, 2)  98          conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 256, 256, 2)  0           conv2d_312[0][0]                 \n",
      "                                                                 add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 256, 256, 2)  0           add_103[0][0]                    \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 256, 256, 2)  0           multiply_52[0][0]                \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_461 (Lambda)             (None, 256, 256, 2)  0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 256, 256, 48) 912         lambda_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 256, 256, 2)  98          conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 256, 256, 2)  0           conv2d_318[0][0]                 \n",
      "                                                                 lambda_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_466 (Lambda)             (None, 256, 256, 2)  0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 256, 256, 2)  0           lambda_466[0][0]                 \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 256, 256, 2)  0           multiply_53[0][0]                \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_471 (Lambda)             (None, 256, 256, 2)  0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 256, 256, 48) 912         lambda_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 256, 256, 2)  98          conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 256, 256, 2)  0           conv2d_324[0][0]                 \n",
      "                                                                 lambda_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_476 (Lambda)             (None, 256, 256, 2)  0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 256, 256, 2)  0           lambda_476[0][0]                 \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 256, 256, 2)  0           multiply_54[0][0]                \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_481 (Lambda)             (None, 256, 256, 2)  0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_486 (Lambda)             (None, 256, 256, 1)  0           lambda_481[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkii_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 113s 169ms/step - loss: 0.2146 - lambda_481_loss: 0.2442 - lambda_486_loss: 0.2146 - val_loss: 0.1537 - val_lambda_481_loss: 0.1862 - val_lambda_486_loss: 0.1537\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1549 - lambda_481_loss: 0.1818 - lambda_486_loss: 0.1549 - val_loss: 0.1399 - val_lambda_481_loss: 0.1649 - val_lambda_486_loss: 0.1399\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1386 - lambda_481_loss: 0.1623 - lambda_486_loss: 0.1386 - val_loss: 0.1330 - val_lambda_481_loss: 0.1558 - val_lambda_486_loss: 0.1330\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1312 - lambda_481_loss: 0.1542 - lambda_486_loss: 0.1312 - val_loss: 0.1310 - val_lambda_481_loss: 0.1533 - val_lambda_486_loss: 0.1310\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1280 - lambda_481_loss: 0.1518 - lambda_486_loss: 0.1280 - val_loss: 0.1238 - val_lambda_481_loss: 0.1471 - val_lambda_486_loss: 0.1238\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1233 - lambda_481_loss: 0.1470 - lambda_486_loss: 0.1233 - val_loss: 0.1174 - val_lambda_481_loss: 0.1396 - val_lambda_486_loss: 0.1174\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1211 - lambda_481_loss: 0.1442 - lambda_486_loss: 0.1211 - val_loss: 0.1288 - val_lambda_481_loss: 0.1590 - val_lambda_486_loss: 0.1288\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1187 - lambda_481_loss: 0.1414 - lambda_486_loss: 0.1187 - val_loss: 0.1229 - val_lambda_481_loss: 0.1455 - val_lambda_486_loss: 0.1229\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1155 - lambda_481_loss: 0.1371 - lambda_486_loss: 0.1155 - val_loss: 0.1146 - val_lambda_481_loss: 0.1346 - val_lambda_486_loss: 0.1146\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1153 - lambda_481_loss: 0.1372 - lambda_486_loss: 0.1153 - val_loss: 0.1157 - val_lambda_481_loss: 0.1334 - val_lambda_486_loss: 0.1157\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1137 - lambda_481_loss: 0.1357 - lambda_486_loss: 0.1137 - val_loss: 0.1203 - val_lambda_481_loss: 0.1478 - val_lambda_486_loss: 0.1203\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1127 - lambda_481_loss: 0.1345 - lambda_486_loss: 0.1127 - val_loss: 0.1145 - val_lambda_481_loss: 0.1370 - val_lambda_486_loss: 0.1145\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1117 - lambda_481_loss: 0.1326 - lambda_486_loss: 0.1117 - val_loss: 0.1123 - val_lambda_481_loss: 0.1314 - val_lambda_486_loss: 0.1123\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1098 - lambda_481_loss: 0.1313 - lambda_486_loss: 0.1098 - val_loss: 0.1197 - val_lambda_481_loss: 0.1506 - val_lambda_486_loss: 0.1197\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1091 - lambda_481_loss: 0.1301 - lambda_486_loss: 0.1091 - val_loss: 0.1155 - val_lambda_481_loss: 0.1455 - val_lambda_486_loss: 0.1155\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1084 - lambda_481_loss: 0.1292 - lambda_486_loss: 0.1084 - val_loss: 0.1149 - val_lambda_481_loss: 0.1376 - val_lambda_486_loss: 0.1149\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1069 - lambda_481_loss: 0.1276 - lambda_486_loss: 0.1069 - val_loss: 0.1168 - val_lambda_481_loss: 0.1434 - val_lambda_486_loss: 0.1168\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1067 - lambda_481_loss: 0.1277 - lambda_486_loss: 0.1067 - val_loss: 0.1097 - val_lambda_481_loss: 0.1354 - val_lambda_486_loss: 0.1097\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1062 - lambda_481_loss: 0.1266 - lambda_486_loss: 0.1062 - val_loss: 0.1137 - val_lambda_481_loss: 0.1324 - val_lambda_486_loss: 0.1137\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1031 - lambda_481_loss: 0.1230 - lambda_486_loss: 0.1031 - val_loss: 0.1078 - val_lambda_481_loss: 0.1233 - val_lambda_486_loss: 0.1078\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1035 - lambda_481_loss: 0.1227 - lambda_486_loss: 0.1035 - val_loss: 0.1040 - val_lambda_481_loss: 0.1223 - val_lambda_486_loss: 0.1040\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1021 - lambda_481_loss: 0.1213 - lambda_486_loss: 0.1021 - val_loss: 0.1064 - val_lambda_481_loss: 0.1294 - val_lambda_486_loss: 0.1064\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1016 - lambda_481_loss: 0.1199 - lambda_486_loss: 0.1016 - val_loss: 0.1078 - val_lambda_481_loss: 0.1298 - val_lambda_486_loss: 0.1078\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1000 - lambda_481_loss: 0.1172 - lambda_486_loss: 0.1000 - val_loss: 0.1075 - val_lambda_481_loss: 0.1314 - val_lambda_486_loss: 0.1075\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1007 - lambda_481_loss: 0.1186 - lambda_486_loss: 0.1007 - val_loss: 0.1025 - val_lambda_481_loss: 0.1266 - val_lambda_486_loss: 0.1025\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0980 - lambda_481_loss: 0.1143 - lambda_486_loss: 0.0980 - val_loss: 0.1022 - val_lambda_481_loss: 0.1229 - val_lambda_486_loss: 0.1022\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0979 - lambda_481_loss: 0.1146 - lambda_486_loss: 0.0979 - val_loss: 0.1050 - val_lambda_481_loss: 0.1221 - val_lambda_486_loss: 0.1050\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0987 - lambda_481_loss: 0.1147 - lambda_486_loss: 0.0987 - val_loss: 0.1015 - val_lambda_481_loss: 0.1213 - val_lambda_486_loss: 0.1015\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0967 - lambda_481_loss: 0.1120 - lambda_486_loss: 0.0967 - val_loss: 0.1076 - val_lambda_481_loss: 0.1297 - val_lambda_486_loss: 0.1076\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0955 - lambda_481_loss: 0.1104 - lambda_486_loss: 0.0955 - val_loss: 0.1003 - val_lambda_481_loss: 0.1211 - val_lambda_486_loss: 0.1003\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0953 - lambda_481_loss: 0.1103 - lambda_486_loss: 0.0953 - val_loss: 0.1041 - val_lambda_481_loss: 0.1192 - val_lambda_486_loss: 0.1041\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0977 - lambda_481_loss: 0.1128 - lambda_486_loss: 0.0977 - val_loss: 0.1031 - val_lambda_481_loss: 0.1183 - val_lambda_486_loss: 0.1031\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0952 - lambda_481_loss: 0.1098 - lambda_486_loss: 0.0952 - val_loss: 0.0984 - val_lambda_481_loss: 0.1144 - val_lambda_486_loss: 0.0984\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0942 - lambda_481_loss: 0.1083 - lambda_486_loss: 0.0942 - val_loss: 0.0978 - val_lambda_481_loss: 0.1133 - val_lambda_486_loss: 0.0978\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0944 - lambda_481_loss: 0.1089 - lambda_486_loss: 0.0944 - val_loss: 0.1040 - val_lambda_481_loss: 0.1180 - val_lambda_486_loss: 0.1040\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0939 - lambda_481_loss: 0.1084 - lambda_486_loss: 0.0939 - val_loss: 0.0964 - val_lambda_481_loss: 0.1114 - val_lambda_486_loss: 0.0964\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0925 - lambda_481_loss: 0.1057 - lambda_486_loss: 0.0925 - val_loss: 0.0954 - val_lambda_481_loss: 0.1100 - val_lambda_486_loss: 0.0954\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0933 - lambda_481_loss: 0.1072 - lambda_486_loss: 0.0933 - val_loss: 0.0984 - val_lambda_481_loss: 0.1098 - val_lambda_486_loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0921 - lambda_481_loss: 0.1049 - lambda_486_loss: 0.0921 - val_loss: 0.0945 - val_lambda_481_loss: 0.1087 - val_lambda_486_loss: 0.0945\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0920 - lambda_481_loss: 0.1054 - lambda_486_loss: 0.0920 - val_loss: 0.0958 - val_lambda_481_loss: 0.1090 - val_lambda_486_loss: 0.0958\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0911 - lambda_481_loss: 0.1035 - lambda_486_loss: 0.0911 - val_loss: 0.0931 - val_lambda_481_loss: 0.1051 - val_lambda_486_loss: 0.0931\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0909 - lambda_481_loss: 0.1036 - lambda_486_loss: 0.0909 - val_loss: 0.1014 - val_lambda_481_loss: 0.1248 - val_lambda_486_loss: 0.1014\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0909 - lambda_481_loss: 0.1041 - lambda_486_loss: 0.0909 - val_loss: 0.0987 - val_lambda_481_loss: 0.1157 - val_lambda_486_loss: 0.0987\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0918 - lambda_481_loss: 0.1046 - lambda_486_loss: 0.0918 - val_loss: 0.0997 - val_lambda_481_loss: 0.1131 - val_lambda_486_loss: 0.0997\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0904 - lambda_481_loss: 0.1029 - lambda_486_loss: 0.0904 - val_loss: 0.0949 - val_lambda_481_loss: 0.1095 - val_lambda_486_loss: 0.0949\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0899 - lambda_481_loss: 0.1023 - lambda_486_loss: 0.0899 - val_loss: 0.0926 - val_lambda_481_loss: 0.1040 - val_lambda_486_loss: 0.0926\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0896 - lambda_481_loss: 0.1022 - lambda_486_loss: 0.0896 - val_loss: 0.0948 - val_lambda_481_loss: 0.1110 - val_lambda_486_loss: 0.0948\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0895 - lambda_481_loss: 0.1020 - lambda_486_loss: 0.0895 - val_loss: 0.0947 - val_lambda_481_loss: 0.1065 - val_lambda_486_loss: 0.0947\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0897 - lambda_481_loss: 0.1022 - lambda_486_loss: 0.0897 - val_loss: 0.0934 - val_lambda_481_loss: 0.1063 - val_lambda_486_loss: 0.0934\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0893 - lambda_481_loss: 0.1017 - lambda_486_loss: 0.0893 - val_loss: 0.0928 - val_lambda_481_loss: 0.1056 - val_lambda_486_loss: 0.0928\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 256, 256, 48) 912         input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 256, 256, 2)  98          conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 256, 256, 2)  0           conv2d_330[0][0]                 \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 256, 256, 2)  0           add_109[0][0]                    \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 256, 256, 2)  0           multiply_55[0][0]                \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 256, 256, 48) 912         add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 256, 256, 2)  98          conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 256, 256, 2)  0           conv2d_336[0][0]                 \n",
      "                                                                 add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 256, 256, 2)  0           add_111[0][0]                    \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 256, 256, 2)  0           multiply_56[0][0]                \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_491 (Lambda)             (None, 256, 256, 2)  0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 256, 256, 48) 912         lambda_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 256, 256, 2)  98          conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 256, 256, 2)  0           conv2d_342[0][0]                 \n",
      "                                                                 lambda_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_496 (Lambda)             (None, 256, 256, 2)  0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 256, 256, 2)  0           lambda_496[0][0]                 \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 256, 256, 2)  0           multiply_57[0][0]                \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 256, 256, 48) 912         add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 256, 256, 2)  98          conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 256, 256, 2)  0           conv2d_348[0][0]                 \n",
      "                                                                 add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 256, 256, 2)  0           add_115[0][0]                    \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 256, 256, 2)  0           multiply_58[0][0]                \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_501 (Lambda)             (None, 256, 256, 2)  0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_506 (Lambda)             (None, 256, 256, 1)  0           lambda_501[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 112s 168ms/step - loss: 0.2472 - lambda_501_loss: 0.2859 - lambda_506_loss: 0.2472 - val_loss: 0.2017 - val_lambda_501_loss: 0.2393 - val_lambda_506_loss: 0.2017\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1881 - lambda_501_loss: 0.2244 - lambda_506_loss: 0.1881 - val_loss: 0.1690 - val_lambda_501_loss: 0.2013 - val_lambda_506_loss: 0.1690\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1719 - lambda_501_loss: 0.2069 - lambda_506_loss: 0.1719 - val_loss: 0.1710 - val_lambda_501_loss: 0.2059 - val_lambda_506_loss: 0.1710\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1670 - lambda_501_loss: 0.2014 - lambda_506_loss: 0.1670 - val_loss: 0.1651 - val_lambda_501_loss: 0.1922 - val_lambda_506_loss: 0.1651\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1605 - lambda_501_loss: 0.1935 - lambda_506_loss: 0.1605 - val_loss: 0.1537 - val_lambda_501_loss: 0.1890 - val_lambda_506_loss: 0.1537\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1557 - lambda_501_loss: 0.1879 - lambda_506_loss: 0.1557 - val_loss: 0.1518 - val_lambda_501_loss: 0.1831 - val_lambda_506_loss: 0.1518\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1527 - lambda_501_loss: 0.1847 - lambda_506_loss: 0.1527 - val_loss: 0.1507 - val_lambda_501_loss: 0.1810 - val_lambda_506_loss: 0.1507\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1495 - lambda_501_loss: 0.1809 - lambda_506_loss: 0.1495 - val_loss: 0.1534 - val_lambda_501_loss: 0.1864 - val_lambda_506_loss: 0.1534\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1464 - lambda_501_loss: 0.1774 - lambda_506_loss: 0.1464 - val_loss: 0.1493 - val_lambda_501_loss: 0.1854 - val_lambda_506_loss: 0.1493\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1468 - lambda_501_loss: 0.1782 - lambda_506_loss: 0.1468 - val_loss: 0.1417 - val_lambda_501_loss: 0.1721 - val_lambda_506_loss: 0.1417\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1431 - lambda_501_loss: 0.1735 - lambda_506_loss: 0.1431 - val_loss: 0.1442 - val_lambda_501_loss: 0.1820 - val_lambda_506_loss: 0.1442\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1432 - lambda_501_loss: 0.1734 - lambda_506_loss: 0.1432 - val_loss: 0.1375 - val_lambda_501_loss: 0.1653 - val_lambda_506_loss: 0.1375\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1394 - lambda_501_loss: 0.1690 - lambda_506_loss: 0.1394 - val_loss: 0.1372 - val_lambda_501_loss: 0.1643 - val_lambda_506_loss: 0.1372\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1400 - lambda_501_loss: 0.1700 - lambda_506_loss: 0.1400 - val_loss: 0.1379 - val_lambda_501_loss: 0.1688 - val_lambda_506_loss: 0.1379\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1386 - lambda_501_loss: 0.1681 - lambda_506_loss: 0.1386 - val_loss: 0.1369 - val_lambda_501_loss: 0.1601 - val_lambda_506_loss: 0.1369\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1368 - lambda_501_loss: 0.1658 - lambda_506_loss: 0.1368 - val_loss: 0.1370 - val_lambda_501_loss: 0.1661 - val_lambda_506_loss: 0.1370\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1347 - lambda_501_loss: 0.1634 - lambda_506_loss: 0.1347 - val_loss: 0.1316 - val_lambda_501_loss: 0.1591 - val_lambda_506_loss: 0.1316\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1340 - lambda_501_loss: 0.1628 - lambda_506_loss: 0.1340 - val_loss: 0.1425 - val_lambda_501_loss: 0.1698 - val_lambda_506_loss: 0.1425\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1341 - lambda_501_loss: 0.1626 - lambda_506_loss: 0.1341 - val_loss: 0.1361 - val_lambda_501_loss: 0.1670 - val_lambda_506_loss: 0.1361\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1323 - lambda_501_loss: 0.1605 - lambda_506_loss: 0.1323 - val_loss: 0.1315 - val_lambda_501_loss: 0.1569 - val_lambda_506_loss: 0.1315\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1305 - lambda_501_loss: 0.1584 - lambda_506_loss: 0.1305 - val_loss: 0.1322 - val_lambda_501_loss: 0.1591 - val_lambda_506_loss: 0.1322\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1312 - lambda_501_loss: 0.1589 - lambda_506_loss: 0.1312 - val_loss: 0.1319 - val_lambda_501_loss: 0.1593 - val_lambda_506_loss: 0.1319\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1301 - lambda_501_loss: 0.1577 - lambda_506_loss: 0.1301 - val_loss: 0.1344 - val_lambda_501_loss: 0.1673 - val_lambda_506_loss: 0.1344\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1310 - lambda_501_loss: 0.1585 - lambda_506_loss: 0.1310 - val_loss: 0.1325 - val_lambda_501_loss: 0.1629 - val_lambda_506_loss: 0.1325\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1297 - lambda_501_loss: 0.1575 - lambda_506_loss: 0.1297 - val_loss: 0.1314 - val_lambda_501_loss: 0.1595 - val_lambda_506_loss: 0.1314\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1279 - lambda_501_loss: 0.1548 - lambda_506_loss: 0.1279 - val_loss: 0.1275 - val_lambda_501_loss: 0.1536 - val_lambda_506_loss: 0.1275\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1276 - lambda_501_loss: 0.1547 - lambda_506_loss: 0.1276 - val_loss: 0.1250 - val_lambda_501_loss: 0.1514 - val_lambda_506_loss: 0.1250\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1269 - lambda_501_loss: 0.1536 - lambda_506_loss: 0.1269 - val_loss: 0.1326 - val_lambda_501_loss: 0.1566 - val_lambda_506_loss: 0.1326\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1268 - lambda_501_loss: 0.1536 - lambda_506_loss: 0.1268 - val_loss: 0.1313 - val_lambda_501_loss: 0.1548 - val_lambda_506_loss: 0.1313\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1267 - lambda_501_loss: 0.1534 - lambda_506_loss: 0.1267 - val_loss: 0.1262 - val_lambda_501_loss: 0.1534 - val_lambda_506_loss: 0.1262\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1257 - lambda_501_loss: 0.1523 - lambda_506_loss: 0.1257 - val_loss: 0.1299 - val_lambda_501_loss: 0.1583 - val_lambda_506_loss: 0.1299\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1250 - lambda_501_loss: 0.1512 - lambda_506_loss: 0.1250 - val_loss: 0.1311 - val_lambda_501_loss: 0.1596 - val_lambda_506_loss: 0.1311\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1249 - lambda_501_loss: 0.1514 - lambda_506_loss: 0.1249 - val_loss: 0.1263 - val_lambda_501_loss: 0.1547 - val_lambda_506_loss: 0.1263\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1245 - lambda_501_loss: 0.1509 - lambda_506_loss: 0.1245 - val_loss: 0.1241 - val_lambda_501_loss: 0.1467 - val_lambda_506_loss: 0.1241\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1242 - lambda_501_loss: 0.1502 - lambda_506_loss: 0.1242 - val_loss: 0.1264 - val_lambda_501_loss: 0.1527 - val_lambda_506_loss: 0.1264\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1238 - lambda_501_loss: 0.1497 - lambda_506_loss: 0.1238 - val_loss: 0.1230 - val_lambda_501_loss: 0.1501 - val_lambda_506_loss: 0.1230\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1227 - lambda_501_loss: 0.1484 - lambda_506_loss: 0.1227 - val_loss: 0.1251 - val_lambda_501_loss: 0.1510 - val_lambda_506_loss: 0.1251\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1243 - lambda_501_loss: 0.1502 - lambda_506_loss: 0.1243 - val_loss: 0.1255 - val_lambda_501_loss: 0.1472 - val_lambda_506_loss: 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1218 - lambda_501_loss: 0.1470 - lambda_506_loss: 0.1218 - val_loss: 0.1259 - val_lambda_501_loss: 0.1513 - val_lambda_506_loss: 0.1259\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1220 - lambda_501_loss: 0.1475 - lambda_506_loss: 0.1220 - val_loss: 0.1322 - val_lambda_501_loss: 0.1594 - val_lambda_506_loss: 0.1322\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1217 - lambda_501_loss: 0.1471 - lambda_506_loss: 0.1217 - val_loss: 0.1205 - val_lambda_501_loss: 0.1447 - val_lambda_506_loss: 0.1205\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1209 - lambda_501_loss: 0.1460 - lambda_506_loss: 0.1209 - val_loss: 0.1232 - val_lambda_501_loss: 0.1470 - val_lambda_506_loss: 0.1232\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1214 - lambda_501_loss: 0.1469 - lambda_506_loss: 0.1214 - val_loss: 0.1353 - val_lambda_501_loss: 0.1608 - val_lambda_506_loss: 0.1353\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1209 - lambda_501_loss: 0.1461 - lambda_506_loss: 0.1209 - val_loss: 0.1204 - val_lambda_501_loss: 0.1430 - val_lambda_506_loss: 0.1204\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1210 - lambda_501_loss: 0.1461 - lambda_506_loss: 0.1210 - val_loss: 0.1228 - val_lambda_501_loss: 0.1477 - val_lambda_506_loss: 0.1228\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1208 - lambda_501_loss: 0.1462 - lambda_506_loss: 0.1208 - val_loss: 0.1241 - val_lambda_501_loss: 0.1484 - val_lambda_506_loss: 0.1241\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1197 - lambda_501_loss: 0.1445 - lambda_506_loss: 0.1197 - val_loss: 0.1182 - val_lambda_501_loss: 0.1403 - val_lambda_506_loss: 0.1182\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1191 - lambda_501_loss: 0.1439 - lambda_506_loss: 0.1191 - val_loss: 0.1257 - val_lambda_501_loss: 0.1506 - val_lambda_506_loss: 0.1257\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1204 - lambda_501_loss: 0.1456 - lambda_506_loss: 0.1204 - val_loss: 0.1209 - val_lambda_501_loss: 0.1433 - val_lambda_506_loss: 0.1209\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1198 - lambda_501_loss: 0.1447 - lambda_506_loss: 0.1198 - val_loss: 0.1241 - val_lambda_501_loss: 0.1499 - val_lambda_506_loss: 0.1241\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 256, 256, 48) 912         input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 256, 256, 2)  98          conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 256, 256, 2)  0           conv2d_354[0][0]                 \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 256, 256, 2)  0           add_117[0][0]                    \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 256, 256, 2)  0           multiply_59[0][0]                \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 256, 256, 48) 912         add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 256, 256, 2)  98          conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 256, 256, 2)  0           conv2d_360[0][0]                 \n",
      "                                                                 add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 256, 256, 2)  0           add_119[0][0]                    \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 256, 256, 2)  0           multiply_60[0][0]                \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 256, 256, 48) 912         add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 256, 256, 2)  98          conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 256, 256, 2)  0           conv2d_366[0][0]                 \n",
      "                                                                 add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 256, 256, 2)  0           add_121[0][0]                    \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 256, 256, 2)  0           multiply_61[0][0]                \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_511 (Lambda)             (None, 256, 256, 2)  0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 256, 256, 48) 912         lambda_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 256, 256, 2)  98          conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 256, 256, 2)  0           conv2d_372[0][0]                 \n",
      "                                                                 lambda_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_516 (Lambda)             (None, 256, 256, 2)  0           add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 256, 256, 2)  0           lambda_516[0][0]                 \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 256, 256, 2)  0           multiply_62[0][0]                \n",
      "                                                                 input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_521 (Lambda)             (None, 256, 256, 2)  0           add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_526 (Lambda)             (None, 256, 256, 1)  0           lambda_521[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 113s 169ms/step - loss: 0.2612 - lambda_521_loss: 0.2955 - lambda_526_loss: 0.2612 - val_loss: 0.2011 - val_lambda_521_loss: 0.2276 - val_lambda_526_loss: 0.2011\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1989 - lambda_521_loss: 0.2311 - lambda_526_loss: 0.1989 - val_loss: 0.1793 - val_lambda_521_loss: 0.2042 - val_lambda_526_loss: 0.1793\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1824 - lambda_521_loss: 0.2155 - lambda_526_loss: 0.1824 - val_loss: 0.1696 - val_lambda_521_loss: 0.2055 - val_lambda_526_loss: 0.1696\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1742 - lambda_521_loss: 0.2059 - lambda_526_loss: 0.1742 - val_loss: 0.1808 - val_lambda_521_loss: 0.2330 - val_lambda_526_loss: 0.1808\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1691 - lambda_521_loss: 0.2008 - lambda_526_loss: 0.1691 - val_loss: 0.1602 - val_lambda_521_loss: 0.1945 - val_lambda_526_loss: 0.1602\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1653 - lambda_521_loss: 0.1962 - lambda_526_loss: 0.1653 - val_loss: 0.1558 - val_lambda_521_loss: 0.1913 - val_lambda_526_loss: 0.1558\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1613 - lambda_521_loss: 0.1916 - lambda_526_loss: 0.1613 - val_loss: 0.1521 - val_lambda_521_loss: 0.1775 - val_lambda_526_loss: 0.1521\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1584 - lambda_521_loss: 0.1887 - lambda_526_loss: 0.1584 - val_loss: 0.1506 - val_lambda_521_loss: 0.1801 - val_lambda_526_loss: 0.1506\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1580 - lambda_521_loss: 0.1873 - lambda_526_loss: 0.1580 - val_loss: 0.1561 - val_lambda_521_loss: 0.1916 - val_lambda_526_loss: 0.1561\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1536 - lambda_521_loss: 0.1828 - lambda_526_loss: 0.1536 - val_loss: 0.1472 - val_lambda_521_loss: 0.1899 - val_lambda_526_loss: 0.1472\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1519 - lambda_521_loss: 0.1800 - lambda_526_loss: 0.1519 - val_loss: 0.1460 - val_lambda_521_loss: 0.1695 - val_lambda_526_loss: 0.1460\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1506 - lambda_521_loss: 0.1785 - lambda_526_loss: 0.1506 - val_loss: 0.1486 - val_lambda_521_loss: 0.1832 - val_lambda_526_loss: 0.1486\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1504 - lambda_521_loss: 0.1789 - lambda_526_loss: 0.1504 - val_loss: 0.1468 - val_lambda_521_loss: 0.1791 - val_lambda_526_loss: 0.1468\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1479 - lambda_521_loss: 0.1758 - lambda_526_loss: 0.1479 - val_loss: 0.1449 - val_lambda_521_loss: 0.1762 - val_lambda_526_loss: 0.1449\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1467 - lambda_521_loss: 0.1740 - lambda_526_loss: 0.1467 - val_loss: 0.1488 - val_lambda_521_loss: 0.1816 - val_lambda_526_loss: 0.1488\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1462 - lambda_521_loss: 0.1732 - lambda_526_loss: 0.1462 - val_loss: 0.1391 - val_lambda_521_loss: 0.1706 - val_lambda_526_loss: 0.1391\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1441 - lambda_521_loss: 0.1708 - lambda_526_loss: 0.1441 - val_loss: 0.1450 - val_lambda_521_loss: 0.1781 - val_lambda_526_loss: 0.1450\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1449 - lambda_521_loss: 0.1715 - lambda_526_loss: 0.1449 - val_loss: 0.1383 - val_lambda_521_loss: 0.1614 - val_lambda_526_loss: 0.1383\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1431 - lambda_521_loss: 0.1693 - lambda_526_loss: 0.1431 - val_loss: 0.1372 - val_lambda_521_loss: 0.1660 - val_lambda_526_loss: 0.1372\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1424 - lambda_521_loss: 0.1691 - lambda_526_loss: 0.1424 - val_loss: 0.1389 - val_lambda_521_loss: 0.1676 - val_lambda_526_loss: 0.1389\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1419 - lambda_521_loss: 0.1681 - lambda_526_loss: 0.1419 - val_loss: 0.1390 - val_lambda_521_loss: 0.1674 - val_lambda_526_loss: 0.1390\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1413 - lambda_521_loss: 0.1672 - lambda_526_loss: 0.1413 - val_loss: 0.1347 - val_lambda_521_loss: 0.1623 - val_lambda_526_loss: 0.1347\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1399 - lambda_521_loss: 0.1656 - lambda_526_loss: 0.1399 - val_loss: 0.1378 - val_lambda_521_loss: 0.1604 - val_lambda_526_loss: 0.1378\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1387 - lambda_521_loss: 0.1641 - lambda_526_loss: 0.1387 - val_loss: 0.1359 - val_lambda_521_loss: 0.1634 - val_lambda_526_loss: 0.1359\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1379 - lambda_521_loss: 0.1628 - lambda_526_loss: 0.1379 - val_loss: 0.1357 - val_lambda_521_loss: 0.1609 - val_lambda_526_loss: 0.1357\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1381 - lambda_521_loss: 0.1629 - lambda_526_loss: 0.1381 - val_loss: 0.1328 - val_lambda_521_loss: 0.1538 - val_lambda_526_loss: 0.1328\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1369 - lambda_521_loss: 0.1614 - lambda_526_loss: 0.1369 - val_loss: 0.1345 - val_lambda_521_loss: 0.1598 - val_lambda_526_loss: 0.1345\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1360 - lambda_521_loss: 0.1606 - lambda_526_loss: 0.1360 - val_loss: 0.1370 - val_lambda_521_loss: 0.1713 - val_lambda_526_loss: 0.1370\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1376 - lambda_521_loss: 0.1624 - lambda_526_loss: 0.1376 - val_loss: 0.1354 - val_lambda_521_loss: 0.1606 - val_lambda_526_loss: 0.1354\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1350 - lambda_521_loss: 0.1595 - lambda_526_loss: 0.1350 - val_loss: 0.1335 - val_lambda_521_loss: 0.1619 - val_lambda_526_loss: 0.1335\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1341 - lambda_521_loss: 0.1584 - lambda_526_loss: 0.1341 - val_loss: 0.1348 - val_lambda_521_loss: 0.1565 - val_lambda_526_loss: 0.1348\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1346 - lambda_521_loss: 0.1591 - lambda_526_loss: 0.1346 - val_loss: 0.1353 - val_lambda_521_loss: 0.1634 - val_lambda_526_loss: 0.1353\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1351 - lambda_521_loss: 0.1592 - lambda_526_loss: 0.1351 - val_loss: 0.1356 - val_lambda_521_loss: 0.1618 - val_lambda_526_loss: 0.1356\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1336 - lambda_521_loss: 0.1575 - lambda_526_loss: 0.1336 - val_loss: 0.1338 - val_lambda_521_loss: 0.1632 - val_lambda_526_loss: 0.1338\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1335 - lambda_521_loss: 0.1576 - lambda_526_loss: 0.1335 - val_loss: 0.1309 - val_lambda_521_loss: 0.1518 - val_lambda_526_loss: 0.1309\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1324 - lambda_521_loss: 0.1562 - lambda_526_loss: 0.1324 - val_loss: 0.1304 - val_lambda_521_loss: 0.1606 - val_lambda_526_loss: 0.1304\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1330 - lambda_521_loss: 0.1569 - lambda_526_loss: 0.1330 - val_loss: 0.1425 - val_lambda_521_loss: 0.1676 - val_lambda_526_loss: 0.1425\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1317 - lambda_521_loss: 0.1553 - lambda_526_loss: 0.1317 - val_loss: 0.1296 - val_lambda_521_loss: 0.1526 - val_lambda_526_loss: 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1321 - lambda_521_loss: 0.1556 - lambda_526_loss: 0.1321 - val_loss: 0.1304 - val_lambda_521_loss: 0.1533 - val_lambda_526_loss: 0.1304\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1319 - lambda_521_loss: 0.1561 - lambda_526_loss: 0.1319 - val_loss: 0.1315 - val_lambda_521_loss: 0.1580 - val_lambda_526_loss: 0.1315\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1301 - lambda_521_loss: 0.1531 - lambda_526_loss: 0.1301 - val_loss: 0.1335 - val_lambda_521_loss: 0.1639 - val_lambda_526_loss: 0.1335\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1309 - lambda_521_loss: 0.1542 - lambda_526_loss: 0.1309 - val_loss: 0.1309 - val_lambda_521_loss: 0.1540 - val_lambda_526_loss: 0.1309\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1297 - lambda_521_loss: 0.1528 - lambda_526_loss: 0.1297 - val_loss: 0.1270 - val_lambda_521_loss: 0.1495 - val_lambda_526_loss: 0.1270\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1293 - lambda_521_loss: 0.1527 - lambda_526_loss: 0.1293 - val_loss: 0.1286 - val_lambda_521_loss: 0.1480 - val_lambda_526_loss: 0.1286\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1308 - lambda_521_loss: 0.1541 - lambda_526_loss: 0.1308 - val_loss: 0.1274 - val_lambda_521_loss: 0.1543 - val_lambda_526_loss: 0.1274\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1299 - lambda_521_loss: 0.1529 - lambda_526_loss: 0.1299 - val_loss: 0.1304 - val_lambda_521_loss: 0.1547 - val_lambda_526_loss: 0.1304\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1286 - lambda_521_loss: 0.1514 - lambda_526_loss: 0.1286 - val_loss: 0.1282 - val_lambda_521_loss: 0.1503 - val_lambda_526_loss: 0.1282\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1284 - lambda_521_loss: 0.1511 - lambda_526_loss: 0.1284 - val_loss: 0.1278 - val_lambda_521_loss: 0.1611 - val_lambda_526_loss: 0.1278\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1293 - lambda_521_loss: 0.1519 - lambda_526_loss: 0.1293 - val_loss: 0.1256 - val_lambda_521_loss: 0.1538 - val_lambda_526_loss: 0.1256\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1268 - lambda_521_loss: 0.1494 - lambda_526_loss: 0.1268 - val_loss: 0.1271 - val_lambda_521_loss: 0.1537 - val_lambda_526_loss: 0.1271\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 256, 256, 48) 912         input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 256, 256, 2)  98          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 256, 256, 2)  0           conv2d_378[0][0]                 \n",
      "                                                                 input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 256, 256, 2)  0           add_125[0][0]                    \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 256, 256, 2)  0           multiply_63[0][0]                \n",
      "                                                                 input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_531 (Lambda)             (None, 256, 256, 2)  0           add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 256, 256, 48) 912         lambda_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 256, 256, 2)  98          conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 256, 256, 2)  0           conv2d_384[0][0]                 \n",
      "                                                                 lambda_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_536 (Lambda)             (None, 256, 256, 2)  0           add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 256, 256, 2)  0           lambda_536[0][0]                 \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 256, 256, 2)  0           multiply_64[0][0]                \n",
      "                                                                 input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_541 (Lambda)             (None, 256, 256, 2)  0           add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 256, 256, 48) 912         lambda_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 256, 256, 2)  98          conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 256, 256, 2)  0           conv2d_390[0][0]                 \n",
      "                                                                 lambda_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_546 (Lambda)             (None, 256, 256, 2)  0           add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_65 (Multiply)          (None, 256, 256, 2)  0           lambda_546[0][0]                 \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 256, 256, 2)  0           multiply_65[0][0]                \n",
      "                                                                 input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 256, 256, 48) 912         add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 256, 256, 2)  98          conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_131 (Add)                   (None, 256, 256, 2)  0           conv2d_396[0][0]                 \n",
      "                                                                 add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_66 (Multiply)          (None, 256, 256, 2)  0           add_131[0][0]                    \n",
      "                                                                 input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 256, 256, 2)  0           multiply_66[0][0]                \n",
      "                                                                 input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_551 (Lambda)             (None, 256, 256, 2)  0           add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_556 (Lambda)             (None, 256, 256, 1)  0           lambda_551[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 114s 171ms/step - loss: 0.2145 - lambda_551_loss: 0.2459 - lambda_556_loss: 0.2145 - val_loss: 0.1605 - val_lambda_551_loss: 0.1865 - val_lambda_556_loss: 0.1605\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1539 - lambda_551_loss: 0.1815 - lambda_556_loss: 0.1539 - val_loss: 0.1454 - val_lambda_551_loss: 0.1743 - val_lambda_556_loss: 0.1454\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1373 - lambda_551_loss: 0.1613 - lambda_556_loss: 0.1373 - val_loss: 0.1344 - val_lambda_551_loss: 0.1524 - val_lambda_556_loss: 0.1344\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1298 - lambda_551_loss: 0.1520 - lambda_556_loss: 0.1298 - val_loss: 0.1284 - val_lambda_551_loss: 0.1494 - val_lambda_556_loss: 0.1284\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1234 - lambda_551_loss: 0.1455 - lambda_556_loss: 0.1234 - val_loss: 0.1304 - val_lambda_551_loss: 0.1580 - val_lambda_556_loss: 0.1304\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1195 - lambda_551_loss: 0.1404 - lambda_556_loss: 0.1195 - val_loss: 0.1182 - val_lambda_551_loss: 0.1387 - val_lambda_556_loss: 0.1182\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1179 - lambda_551_loss: 0.1389 - lambda_556_loss: 0.1179 - val_loss: 0.1226 - val_lambda_551_loss: 0.1475 - val_lambda_556_loss: 0.1226\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1157 - lambda_551_loss: 0.1361 - lambda_556_loss: 0.1157 - val_loss: 0.1174 - val_lambda_551_loss: 0.1358 - val_lambda_556_loss: 0.1174\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1134 - lambda_551_loss: 0.1326 - lambda_556_loss: 0.1134 - val_loss: 0.1204 - val_lambda_551_loss: 0.1384 - val_lambda_556_loss: 0.1204\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1118 - lambda_551_loss: 0.1317 - lambda_556_loss: 0.1118 - val_loss: 0.1176 - val_lambda_551_loss: 0.1341 - val_lambda_556_loss: 0.1176\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1102 - lambda_551_loss: 0.1292 - lambda_556_loss: 0.1102 - val_loss: 0.1181 - val_lambda_551_loss: 0.1373 - val_lambda_556_loss: 0.1181\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1078 - lambda_551_loss: 0.1261 - lambda_556_loss: 0.1078 - val_loss: 0.1073 - val_lambda_551_loss: 0.1248 - val_lambda_556_loss: 0.1073\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1072 - lambda_551_loss: 0.1260 - lambda_556_loss: 0.1072 - val_loss: 0.1112 - val_lambda_551_loss: 0.1336 - val_lambda_556_loss: 0.1112\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1060 - lambda_551_loss: 0.1245 - lambda_556_loss: 0.1060 - val_loss: 0.1092 - val_lambda_551_loss: 0.1308 - val_lambda_556_loss: 0.1092\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1054 - lambda_551_loss: 0.1235 - lambda_556_loss: 0.1054 - val_loss: 0.1095 - val_lambda_551_loss: 0.1263 - val_lambda_556_loss: 0.1095\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1045 - lambda_551_loss: 0.1220 - lambda_556_loss: 0.1045 - val_loss: 0.1102 - val_lambda_551_loss: 0.1337 - val_lambda_556_loss: 0.1102\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1026 - lambda_551_loss: 0.1202 - lambda_556_loss: 0.1026 - val_loss: 0.1088 - val_lambda_551_loss: 0.1278 - val_lambda_556_loss: 0.1088\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1029 - lambda_551_loss: 0.1212 - lambda_556_loss: 0.1029 - val_loss: 0.1127 - val_lambda_551_loss: 0.1323 - val_lambda_556_loss: 0.1127\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1018 - lambda_551_loss: 0.1189 - lambda_556_loss: 0.1018 - val_loss: 0.1052 - val_lambda_551_loss: 0.1231 - val_lambda_556_loss: 0.1052\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1007 - lambda_551_loss: 0.1180 - lambda_556_loss: 0.1007 - val_loss: 0.1125 - val_lambda_551_loss: 0.1286 - val_lambda_556_loss: 0.1125\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1006 - lambda_551_loss: 0.1181 - lambda_556_loss: 0.1006 - val_loss: 0.1058 - val_lambda_551_loss: 0.1234 - val_lambda_556_loss: 0.1058\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0994 - lambda_551_loss: 0.1162 - lambda_556_loss: 0.0994 - val_loss: 0.1024 - val_lambda_551_loss: 0.1170 - val_lambda_556_loss: 0.1024\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0993 - lambda_551_loss: 0.1163 - lambda_556_loss: 0.0993 - val_loss: 0.1074 - val_lambda_551_loss: 0.1246 - val_lambda_556_loss: 0.1074\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0978 - lambda_551_loss: 0.1142 - lambda_556_loss: 0.0978 - val_loss: 0.1005 - val_lambda_551_loss: 0.1174 - val_lambda_556_loss: 0.1005\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0973 - lambda_551_loss: 0.1137 - lambda_556_loss: 0.0973 - val_loss: 0.1040 - val_lambda_551_loss: 0.1212 - val_lambda_556_loss: 0.1040\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0972 - lambda_551_loss: 0.1136 - lambda_556_loss: 0.0972 - val_loss: 0.1069 - val_lambda_551_loss: 0.1256 - val_lambda_556_loss: 0.1069\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0973 - lambda_551_loss: 0.1138 - lambda_556_loss: 0.0973 - val_loss: 0.1083 - val_lambda_551_loss: 0.1273 - val_lambda_556_loss: 0.1083\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0958 - lambda_551_loss: 0.1121 - lambda_556_loss: 0.0958 - val_loss: 0.1100 - val_lambda_551_loss: 0.1280 - val_lambda_556_loss: 0.1100\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0956 - lambda_551_loss: 0.1116 - lambda_556_loss: 0.0956 - val_loss: 0.1058 - val_lambda_551_loss: 0.1223 - val_lambda_556_loss: 0.1058\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0950 - lambda_551_loss: 0.1111 - lambda_556_loss: 0.0950 - val_loss: 0.1014 - val_lambda_551_loss: 0.1149 - val_lambda_556_loss: 0.1014\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0949 - lambda_551_loss: 0.1108 - lambda_556_loss: 0.0949 - val_loss: 0.1022 - val_lambda_551_loss: 0.1170 - val_lambda_556_loss: 0.1022\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0945 - lambda_551_loss: 0.1108 - lambda_556_loss: 0.0945 - val_loss: 0.1052 - val_lambda_551_loss: 0.1251 - val_lambda_556_loss: 0.1052\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0934 - lambda_551_loss: 0.1090 - lambda_556_loss: 0.0934 - val_loss: 0.1063 - val_lambda_551_loss: 0.1269 - val_lambda_556_loss: 0.1063\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0943 - lambda_551_loss: 0.1100 - lambda_556_loss: 0.0943 - val_loss: 0.1021 - val_lambda_551_loss: 0.1209 - val_lambda_556_loss: 0.1021\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0934 - lambda_551_loss: 0.1091 - lambda_556_loss: 0.0934 - val_loss: 0.0984 - val_lambda_551_loss: 0.1140 - val_lambda_556_loss: 0.0984\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0928 - lambda_551_loss: 0.1083 - lambda_556_loss: 0.0928 - val_loss: 0.0964 - val_lambda_551_loss: 0.1108 - val_lambda_556_loss: 0.0964\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0928 - lambda_551_loss: 0.1085 - lambda_556_loss: 0.0928 - val_loss: 0.1010 - val_lambda_551_loss: 0.1170 - val_lambda_556_loss: 0.1010\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0926 - lambda_551_loss: 0.1081 - lambda_556_loss: 0.0926 - val_loss: 0.0983 - val_lambda_551_loss: 0.1126 - val_lambda_556_loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0916 - lambda_551_loss: 0.1070 - lambda_556_loss: 0.0916 - val_loss: 0.0982 - val_lambda_551_loss: 0.1135 - val_lambda_556_loss: 0.0982\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0913 - lambda_551_loss: 0.1063 - lambda_556_loss: 0.0913 - val_loss: 0.1076 - val_lambda_551_loss: 0.1247 - val_lambda_556_loss: 0.1076\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0912 - lambda_551_loss: 0.1063 - lambda_556_loss: 0.0912 - val_loss: 0.0995 - val_lambda_551_loss: 0.1149 - val_lambda_556_loss: 0.0995\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0895 - lambda_551_loss: 0.1038 - lambda_556_loss: 0.0895 - val_loss: 0.1007 - val_lambda_551_loss: 0.1175 - val_lambda_556_loss: 0.1007\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0901 - lambda_551_loss: 0.1045 - lambda_556_loss: 0.0901 - val_loss: 0.1023 - val_lambda_551_loss: 0.1196 - val_lambda_556_loss: 0.1023\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0900 - lambda_551_loss: 0.1046 - lambda_556_loss: 0.0900 - val_loss: 0.0963 - val_lambda_551_loss: 0.1120 - val_lambda_556_loss: 0.0963\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0888 - lambda_551_loss: 0.1027 - lambda_556_loss: 0.0888 - val_loss: 0.0995 - val_lambda_551_loss: 0.1154 - val_lambda_556_loss: 0.0995\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0890 - lambda_551_loss: 0.1033 - lambda_556_loss: 0.0890 - val_loss: 0.0969 - val_lambda_551_loss: 0.1101 - val_lambda_556_loss: 0.0969\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0881 - lambda_551_loss: 0.1018 - lambda_556_loss: 0.0881 - val_loss: 0.0978 - val_lambda_551_loss: 0.1111 - val_lambda_556_loss: 0.0978\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0885 - lambda_551_loss: 0.1026 - lambda_556_loss: 0.0885 - val_loss: 0.0954 - val_lambda_551_loss: 0.1079 - val_lambda_556_loss: 0.0954\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0877 - lambda_551_loss: 0.1012 - lambda_556_loss: 0.0877 - val_loss: 0.0924 - val_lambda_551_loss: 0.1052 - val_lambda_556_loss: 0.0924\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0869 - lambda_551_loss: 0.1007 - lambda_556_loss: 0.0869 - val_loss: 0.0932 - val_lambda_551_loss: 0.1095 - val_lambda_556_loss: 0.0932\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 256, 256, 48) 912         input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 256, 256, 2)  98          conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_133 (Add)                   (None, 256, 256, 2)  0           conv2d_402[0][0]                 \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_67 (Multiply)          (None, 256, 256, 2)  0           add_133[0][0]                    \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_134 (Add)                   (None, 256, 256, 2)  0           multiply_67[0][0]                \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_561 (Lambda)             (None, 256, 256, 2)  0           add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 256, 256, 48) 912         lambda_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 256, 256, 2)  98          conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_135 (Add)                   (None, 256, 256, 2)  0           conv2d_408[0][0]                 \n",
      "                                                                 lambda_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_566 (Lambda)             (None, 256, 256, 2)  0           add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_68 (Multiply)          (None, 256, 256, 2)  0           lambda_566[0][0]                 \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_136 (Add)                   (None, 256, 256, 2)  0           multiply_68[0][0]                \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 256, 256, 48) 912         add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 256, 256, 2)  98          conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 256, 256, 2)  0           conv2d_414[0][0]                 \n",
      "                                                                 add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_69 (Multiply)          (None, 256, 256, 2)  0           add_137[0][0]                    \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 256, 256, 2)  0           multiply_69[0][0]                \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_571 (Lambda)             (None, 256, 256, 2)  0           add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 256, 256, 48) 912         lambda_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 256, 256, 2)  98          conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 256, 256, 2)  0           conv2d_420[0][0]                 \n",
      "                                                                 lambda_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_576 (Lambda)             (None, 256, 256, 2)  0           add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_70 (Multiply)          (None, 256, 256, 2)  0           lambda_576[0][0]                 \n",
      "                                                                 input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 256, 256, 2)  0           multiply_70[0][0]                \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_581 (Lambda)             (None, 256, 256, 2)  0           add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_586 (Lambda)             (None, 256, 256, 1)  0           lambda_581[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 115s 172ms/step - loss: 0.2029 - lambda_581_loss: 0.2297 - lambda_586_loss: 0.2029 - val_loss: 0.1616 - val_lambda_581_loss: 0.1856 - val_lambda_586_loss: 0.1616\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1468 - lambda_581_loss: 0.1702 - lambda_586_loss: 0.1468 - val_loss: 0.1332 - val_lambda_581_loss: 0.1547 - val_lambda_586_loss: 0.1332\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1346 - lambda_581_loss: 0.1554 - lambda_586_loss: 0.1346 - val_loss: 0.1248 - val_lambda_581_loss: 0.1440 - val_lambda_586_loss: 0.1248\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1265 - lambda_581_loss: 0.1460 - lambda_586_loss: 0.1265 - val_loss: 0.1266 - val_lambda_581_loss: 0.1463 - val_lambda_586_loss: 0.1266\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1228 - lambda_581_loss: 0.1427 - lambda_586_loss: 0.1228 - val_loss: 0.1242 - val_lambda_581_loss: 0.1432 - val_lambda_586_loss: 0.1242\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1195 - lambda_581_loss: 0.1386 - lambda_586_loss: 0.1195 - val_loss: 0.1208 - val_lambda_581_loss: 0.1548 - val_lambda_586_loss: 0.1208\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1176 - lambda_581_loss: 0.1363 - lambda_586_loss: 0.1176 - val_loss: 0.1229 - val_lambda_581_loss: 0.1518 - val_lambda_586_loss: 0.1229\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1145 - lambda_581_loss: 0.1326 - lambda_586_loss: 0.1145 - val_loss: 0.1145 - val_lambda_581_loss: 0.1307 - val_lambda_586_loss: 0.1145\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1125 - lambda_581_loss: 0.1304 - lambda_586_loss: 0.1125 - val_loss: 0.1307 - val_lambda_581_loss: 0.1465 - val_lambda_586_loss: 0.1307\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1116 - lambda_581_loss: 0.1296 - lambda_586_loss: 0.1116 - val_loss: 0.1195 - val_lambda_581_loss: 0.1373 - val_lambda_586_loss: 0.1195\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1101 - lambda_581_loss: 0.1280 - lambda_586_loss: 0.1101 - val_loss: 0.1171 - val_lambda_581_loss: 0.1402 - val_lambda_586_loss: 0.1171\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1083 - lambda_581_loss: 0.1263 - lambda_586_loss: 0.1083 - val_loss: 0.1230 - val_lambda_581_loss: 0.1431 - val_lambda_586_loss: 0.1230\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1072 - lambda_581_loss: 0.1249 - lambda_586_loss: 0.1072 - val_loss: 0.1145 - val_lambda_581_loss: 0.1415 - val_lambda_586_loss: 0.1145\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1062 - lambda_581_loss: 0.1237 - lambda_586_loss: 0.1062 - val_loss: 0.1128 - val_lambda_581_loss: 0.1297 - val_lambda_586_loss: 0.1128\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1041 - lambda_581_loss: 0.1211 - lambda_586_loss: 0.1041 - val_loss: 0.1157 - val_lambda_581_loss: 0.1431 - val_lambda_586_loss: 0.1157\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1024 - lambda_581_loss: 0.1194 - lambda_586_loss: 0.1024 - val_loss: 0.1054 - val_lambda_581_loss: 0.1223 - val_lambda_586_loss: 0.1054\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1019 - lambda_581_loss: 0.1190 - lambda_586_loss: 0.1019 - val_loss: 0.1079 - val_lambda_581_loss: 0.1250 - val_lambda_586_loss: 0.1079\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1017 - lambda_581_loss: 0.1185 - lambda_586_loss: 0.1017 - val_loss: 0.1047 - val_lambda_581_loss: 0.1237 - val_lambda_586_loss: 0.1047\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1003 - lambda_581_loss: 0.1170 - lambda_586_loss: 0.1003 - val_loss: 0.1102 - val_lambda_581_loss: 0.1335 - val_lambda_586_loss: 0.1102\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0995 - lambda_581_loss: 0.1162 - lambda_586_loss: 0.0995 - val_loss: 0.1165 - val_lambda_581_loss: 0.1350 - val_lambda_586_loss: 0.1165\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0984 - lambda_581_loss: 0.1147 - lambda_586_loss: 0.0984 - val_loss: 0.1042 - val_lambda_581_loss: 0.1230 - val_lambda_586_loss: 0.1042\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0992 - lambda_581_loss: 0.1158 - lambda_586_loss: 0.0992 - val_loss: 0.1091 - val_lambda_581_loss: 0.1256 - val_lambda_586_loss: 0.1091\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0977 - lambda_581_loss: 0.1137 - lambda_586_loss: 0.0977 - val_loss: 0.1093 - val_lambda_581_loss: 0.1272 - val_lambda_586_loss: 0.1093\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0969 - lambda_581_loss: 0.1129 - lambda_586_loss: 0.0969 - val_loss: 0.1041 - val_lambda_581_loss: 0.1201 - val_lambda_586_loss: 0.1041\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0972 - lambda_581_loss: 0.1137 - lambda_586_loss: 0.0972 - val_loss: 0.1067 - val_lambda_581_loss: 0.1254 - val_lambda_586_loss: 0.1067\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0964 - lambda_581_loss: 0.1124 - lambda_586_loss: 0.0964 - val_loss: 0.1161 - val_lambda_581_loss: 0.1390 - val_lambda_586_loss: 0.1161\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0948 - lambda_581_loss: 0.1106 - lambda_586_loss: 0.0948 - val_loss: 0.1008 - val_lambda_581_loss: 0.1220 - val_lambda_586_loss: 0.1008\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0954 - lambda_581_loss: 0.1111 - lambda_586_loss: 0.0954 - val_loss: 0.1002 - val_lambda_581_loss: 0.1152 - val_lambda_586_loss: 0.1002\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0949 - lambda_581_loss: 0.1107 - lambda_586_loss: 0.0949 - val_loss: 0.1064 - val_lambda_581_loss: 0.1227 - val_lambda_586_loss: 0.1064\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0946 - lambda_581_loss: 0.1104 - lambda_586_loss: 0.0946 - val_loss: 0.0977 - val_lambda_581_loss: 0.1156 - val_lambda_586_loss: 0.0977\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0942 - lambda_581_loss: 0.1098 - lambda_586_loss: 0.0942 - val_loss: 0.0997 - val_lambda_581_loss: 0.1165 - val_lambda_586_loss: 0.0997\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0934 - lambda_581_loss: 0.1090 - lambda_586_loss: 0.0934 - val_loss: 0.1018 - val_lambda_581_loss: 0.1183 - val_lambda_586_loss: 0.1018\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0941 - lambda_581_loss: 0.1099 - lambda_586_loss: 0.0941 - val_loss: 0.1014 - val_lambda_581_loss: 0.1158 - val_lambda_586_loss: 0.1014\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0931 - lambda_581_loss: 0.1083 - lambda_586_loss: 0.0931 - val_loss: 0.1050 - val_lambda_581_loss: 0.1245 - val_lambda_586_loss: 0.1050\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0923 - lambda_581_loss: 0.1075 - lambda_586_loss: 0.0923 - val_loss: 0.0970 - val_lambda_581_loss: 0.1137 - val_lambda_586_loss: 0.0970\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0926 - lambda_581_loss: 0.1079 - lambda_586_loss: 0.0926 - val_loss: 0.1008 - val_lambda_581_loss: 0.1144 - val_lambda_586_loss: 0.1008\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0916 - lambda_581_loss: 0.1067 - lambda_586_loss: 0.0916 - val_loss: 0.0977 - val_lambda_581_loss: 0.1153 - val_lambda_586_loss: 0.0977\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0920 - lambda_581_loss: 0.1071 - lambda_586_loss: 0.0920 - val_loss: 0.0968 - val_lambda_581_loss: 0.1134 - val_lambda_586_loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0913 - lambda_581_loss: 0.1065 - lambda_586_loss: 0.0913 - val_loss: 0.0992 - val_lambda_581_loss: 0.1155 - val_lambda_586_loss: 0.0992\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0905 - lambda_581_loss: 0.1054 - lambda_586_loss: 0.0905 - val_loss: 0.1001 - val_lambda_581_loss: 0.1134 - val_lambda_586_loss: 0.1001\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0904 - lambda_581_loss: 0.1052 - lambda_586_loss: 0.0904 - val_loss: 0.0955 - val_lambda_581_loss: 0.1124 - val_lambda_586_loss: 0.0955\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0903 - lambda_581_loss: 0.1053 - lambda_586_loss: 0.0903 - val_loss: 0.1021 - val_lambda_581_loss: 0.1205 - val_lambda_586_loss: 0.1021\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0899 - lambda_581_loss: 0.1048 - lambda_586_loss: 0.0899 - val_loss: 0.1026 - val_lambda_581_loss: 0.1182 - val_lambda_586_loss: 0.1026\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0902 - lambda_581_loss: 0.1049 - lambda_586_loss: 0.0902 - val_loss: 0.1025 - val_lambda_581_loss: 0.1201 - val_lambda_586_loss: 0.1025\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0895 - lambda_581_loss: 0.1044 - lambda_586_loss: 0.0895 - val_loss: 0.0943 - val_lambda_581_loss: 0.1089 - val_lambda_586_loss: 0.0943\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0896 - lambda_581_loss: 0.1044 - lambda_586_loss: 0.0896 - val_loss: 0.0974 - val_lambda_581_loss: 0.1205 - val_lambda_586_loss: 0.0974\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0896 - lambda_581_loss: 0.1043 - lambda_586_loss: 0.0896 - val_loss: 0.0962 - val_lambda_581_loss: 0.1156 - val_lambda_586_loss: 0.0962\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0886 - lambda_581_loss: 0.1033 - lambda_586_loss: 0.0886 - val_loss: 0.1023 - val_lambda_581_loss: 0.1192 - val_lambda_586_loss: 0.1023\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0898 - lambda_581_loss: 0.1051 - lambda_586_loss: 0.0898 - val_loss: 0.0968 - val_lambda_581_loss: 0.1154 - val_lambda_586_loss: 0.0968\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0884 - lambda_581_loss: 0.1031 - lambda_586_loss: 0.0884 - val_loss: 0.1018 - val_lambda_581_loss: 0.1173 - val_lambda_586_loss: 0.1018\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 256, 256, 48) 912         input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 256, 256, 2)  98          conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 256, 256, 2)  0           conv2d_426[0][0]                 \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_71 (Multiply)          (None, 256, 256, 2)  0           add_141[0][0]                    \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 256, 256, 2)  0           multiply_71[0][0]                \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_591 (Lambda)             (None, 256, 256, 2)  0           add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 256, 256, 48) 912         lambda_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 256, 256, 2)  98          conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 256, 256, 2)  0           conv2d_432[0][0]                 \n",
      "                                                                 lambda_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_596 (Lambda)             (None, 256, 256, 2)  0           add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_72 (Multiply)          (None, 256, 256, 2)  0           lambda_596[0][0]                 \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 256, 256, 2)  0           multiply_72[0][0]                \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_601 (Lambda)             (None, 256, 256, 2)  0           add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 256, 256, 48) 912         lambda_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 256, 256, 2)  98          conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 256, 256, 2)  0           conv2d_438[0][0]                 \n",
      "                                                                 lambda_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_606 (Lambda)             (None, 256, 256, 2)  0           add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_73 (Multiply)          (None, 256, 256, 2)  0           lambda_606[0][0]                 \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 256, 256, 2)  0           multiply_73[0][0]                \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 256, 256, 48) 912         add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 256, 256, 2)  98          conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 256, 256, 2)  0           conv2d_444[0][0]                 \n",
      "                                                                 add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_74 (Multiply)          (None, 256, 256, 2)  0           add_147[0][0]                    \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 256, 256, 2)  0           multiply_74[0][0]                \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_611 (Lambda)             (None, 256, 256, 2)  0           add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_616 (Lambda)             (None, 256, 256, 1)  0           lambda_611[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 115s 172ms/step - loss: 0.2058 - lambda_611_loss: 0.2358 - lambda_616_loss: 0.2058 - val_loss: 0.1665 - val_lambda_611_loss: 0.2041 - val_lambda_616_loss: 0.1665\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1480 - lambda_611_loss: 0.1738 - lambda_616_loss: 0.1480 - val_loss: 0.1399 - val_lambda_611_loss: 0.1607 - val_lambda_616_loss: 0.1399\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1363 - lambda_611_loss: 0.1608 - lambda_616_loss: 0.1363 - val_loss: 0.1542 - val_lambda_611_loss: 0.2597 - val_lambda_616_loss: 0.1542\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1290 - lambda_611_loss: 0.1520 - lambda_616_loss: 0.1290 - val_loss: 0.1292 - val_lambda_611_loss: 0.1446 - val_lambda_616_loss: 0.1292\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1223 - lambda_611_loss: 0.1437 - lambda_616_loss: 0.1223 - val_loss: 0.1215 - val_lambda_611_loss: 0.1473 - val_lambda_616_loss: 0.1215\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1180 - lambda_611_loss: 0.1390 - lambda_616_loss: 0.1180 - val_loss: 0.1176 - val_lambda_611_loss: 0.1382 - val_lambda_616_loss: 0.1176\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1168 - lambda_611_loss: 0.1375 - lambda_616_loss: 0.1168 - val_loss: 0.1170 - val_lambda_611_loss: 0.1386 - val_lambda_616_loss: 0.1170\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1140 - lambda_611_loss: 0.1347 - lambda_616_loss: 0.1140 - val_loss: 0.1282 - val_lambda_611_loss: 0.1536 - val_lambda_616_loss: 0.1282\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1123 - lambda_611_loss: 0.1325 - lambda_616_loss: 0.1123 - val_loss: 0.1262 - val_lambda_611_loss: 0.1511 - val_lambda_616_loss: 0.1262\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1102 - lambda_611_loss: 0.1301 - lambda_616_loss: 0.1102 - val_loss: 0.1195 - val_lambda_611_loss: 0.1415 - val_lambda_616_loss: 0.1195\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1099 - lambda_611_loss: 0.1295 - lambda_616_loss: 0.1099 - val_loss: 0.1109 - val_lambda_611_loss: 0.1293 - val_lambda_616_loss: 0.1109\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1076 - lambda_611_loss: 0.1270 - lambda_616_loss: 0.1076 - val_loss: 0.1102 - val_lambda_611_loss: 0.1325 - val_lambda_616_loss: 0.1102\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1061 - lambda_611_loss: 0.1252 - lambda_616_loss: 0.1061 - val_loss: 0.1159 - val_lambda_611_loss: 0.1341 - val_lambda_616_loss: 0.1159\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1052 - lambda_611_loss: 0.1240 - lambda_616_loss: 0.1052 - val_loss: 0.1144 - val_lambda_611_loss: 0.1304 - val_lambda_616_loss: 0.1144\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1057 - lambda_611_loss: 0.1249 - lambda_616_loss: 0.1057 - val_loss: 0.1103 - val_lambda_611_loss: 0.1291 - val_lambda_616_loss: 0.1103\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1040 - lambda_611_loss: 0.1222 - lambda_616_loss: 0.1040 - val_loss: 0.1073 - val_lambda_611_loss: 0.1283 - val_lambda_616_loss: 0.1073\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1027 - lambda_611_loss: 0.1210 - lambda_616_loss: 0.1027 - val_loss: 0.1103 - val_lambda_611_loss: 0.1310 - val_lambda_616_loss: 0.1103\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1022 - lambda_611_loss: 0.1208 - lambda_616_loss: 0.1022 - val_loss: 0.1129 - val_lambda_611_loss: 0.1352 - val_lambda_616_loss: 0.1129\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1020 - lambda_611_loss: 0.1198 - lambda_616_loss: 0.1020 - val_loss: 0.1116 - val_lambda_611_loss: 0.1282 - val_lambda_616_loss: 0.1116\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.1002 - lambda_611_loss: 0.1181 - lambda_616_loss: 0.1002 - val_loss: 0.1061 - val_lambda_611_loss: 0.1237 - val_lambda_616_loss: 0.1061\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0996 - lambda_611_loss: 0.1172 - lambda_616_loss: 0.0996 - val_loss: 0.1075 - val_lambda_611_loss: 0.1252 - val_lambda_616_loss: 0.1075\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0998 - lambda_611_loss: 0.1176 - lambda_616_loss: 0.0998 - val_loss: 0.1054 - val_lambda_611_loss: 0.1236 - val_lambda_616_loss: 0.1054\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0993 - lambda_611_loss: 0.1168 - lambda_616_loss: 0.0993 - val_loss: 0.1151 - val_lambda_611_loss: 0.1360 - val_lambda_616_loss: 0.1151\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.0982 - lambda_611_loss: 0.1157 - lambda_616_loss: 0.0982 - val_loss: 0.1101 - val_lambda_611_loss: 0.1259 - val_lambda_616_loss: 0.1101\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0986 - lambda_611_loss: 0.1160 - lambda_616_loss: 0.0986 - val_loss: 0.1061 - val_lambda_611_loss: 0.1252 - val_lambda_616_loss: 0.1061\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0976 - lambda_611_loss: 0.1147 - lambda_616_loss: 0.0976 - val_loss: 0.1041 - val_lambda_611_loss: 0.1227 - val_lambda_616_loss: 0.1041\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0961 - lambda_611_loss: 0.1130 - lambda_616_loss: 0.0961 - val_loss: 0.1020 - val_lambda_611_loss: 0.1194 - val_lambda_616_loss: 0.1020\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0961 - lambda_611_loss: 0.1131 - lambda_616_loss: 0.0961 - val_loss: 0.1061 - val_lambda_611_loss: 0.1202 - val_lambda_616_loss: 0.1061\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0955 - lambda_611_loss: 0.1122 - lambda_616_loss: 0.0955 - val_loss: 0.1031 - val_lambda_611_loss: 0.1210 - val_lambda_616_loss: 0.1031\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0947 - lambda_611_loss: 0.1112 - lambda_616_loss: 0.0947 - val_loss: 0.1041 - val_lambda_611_loss: 0.1209 - val_lambda_616_loss: 0.1041\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0951 - lambda_611_loss: 0.1117 - lambda_616_loss: 0.0951 - val_loss: 0.1006 - val_lambda_611_loss: 0.1168 - val_lambda_616_loss: 0.1006\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0935 - lambda_611_loss: 0.1101 - lambda_616_loss: 0.0935 - val_loss: 0.1004 - val_lambda_611_loss: 0.1182 - val_lambda_616_loss: 0.1004\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0943 - lambda_611_loss: 0.1108 - lambda_616_loss: 0.0943 - val_loss: 0.1015 - val_lambda_611_loss: 0.1185 - val_lambda_616_loss: 0.1015\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0931 - lambda_611_loss: 0.1092 - lambda_616_loss: 0.0931 - val_loss: 0.1051 - val_lambda_611_loss: 0.1244 - val_lambda_616_loss: 0.1051\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0932 - lambda_611_loss: 0.1090 - lambda_616_loss: 0.0932 - val_loss: 0.0997 - val_lambda_611_loss: 0.1157 - val_lambda_616_loss: 0.0997\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0913 - lambda_611_loss: 0.1069 - lambda_616_loss: 0.0913 - val_loss: 0.0971 - val_lambda_611_loss: 0.1151 - val_lambda_616_loss: 0.0971\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0919 - lambda_611_loss: 0.1074 - lambda_616_loss: 0.0919 - val_loss: 0.0969 - val_lambda_611_loss: 0.1117 - val_lambda_616_loss: 0.0969\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0915 - lambda_611_loss: 0.1064 - lambda_616_loss: 0.0915 - val_loss: 0.1014 - val_lambda_611_loss: 0.1197 - val_lambda_616_loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0899 - lambda_611_loss: 0.1049 - lambda_616_loss: 0.0899 - val_loss: 0.0965 - val_lambda_611_loss: 0.1095 - val_lambda_616_loss: 0.0965\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0905 - lambda_611_loss: 0.1053 - lambda_616_loss: 0.0905 - val_loss: 0.0971 - val_lambda_611_loss: 0.1125 - val_lambda_616_loss: 0.0971\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0894 - lambda_611_loss: 0.1036 - lambda_616_loss: 0.0894 - val_loss: 0.0958 - val_lambda_611_loss: 0.1114 - val_lambda_616_loss: 0.0958\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0893 - lambda_611_loss: 0.1035 - lambda_616_loss: 0.0893 - val_loss: 0.1000 - val_lambda_611_loss: 0.1136 - val_lambda_616_loss: 0.1000\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0896 - lambda_611_loss: 0.1043 - lambda_616_loss: 0.0896 - val_loss: 0.1008 - val_lambda_611_loss: 0.1150 - val_lambda_616_loss: 0.1008\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0884 - lambda_611_loss: 0.1026 - lambda_616_loss: 0.0884 - val_loss: 0.0955 - val_lambda_611_loss: 0.1088 - val_lambda_616_loss: 0.0955\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0878 - lambda_611_loss: 0.1014 - lambda_616_loss: 0.0878 - val_loss: 0.0941 - val_lambda_611_loss: 0.1071 - val_lambda_616_loss: 0.0941\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0883 - lambda_611_loss: 0.1023 - lambda_616_loss: 0.0883 - val_loss: 0.0970 - val_lambda_611_loss: 0.1099 - val_lambda_616_loss: 0.0970\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0880 - lambda_611_loss: 0.1019 - lambda_616_loss: 0.0880 - val_loss: 0.0957 - val_lambda_611_loss: 0.1068 - val_lambda_616_loss: 0.0957\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.0873 - lambda_611_loss: 0.1007 - lambda_616_loss: 0.0873 - val_loss: 0.0957 - val_lambda_611_loss: 0.1101 - val_lambda_616_loss: 0.0957\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0871 - lambda_611_loss: 0.1007 - lambda_616_loss: 0.0871 - val_loss: 0.0960 - val_lambda_611_loss: 0.1116 - val_lambda_616_loss: 0.0960\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0873 - lambda_611_loss: 0.1006 - lambda_616_loss: 0.0873 - val_loss: 0.0923 - val_lambda_611_loss: 0.1060 - val_lambda_616_loss: 0.0923\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_49 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_621 (Lambda)             (None, 256, 256, 2)  0           input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 256, 256, 48) 912         lambda_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 256, 256, 2)  98          conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_149 (Add)                   (None, 256, 256, 2)  0           conv2d_450[0][0]                 \n",
      "                                                                 lambda_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_626 (Lambda)             (None, 256, 256, 2)  0           add_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_75 (Multiply)          (None, 256, 256, 2)  0           lambda_626[0][0]                 \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_150 (Add)                   (None, 256, 256, 2)  0           multiply_75[0][0]                \n",
      "                                                                 input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 256, 256, 48) 912         add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 256, 256, 2)  98          conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_151 (Add)                   (None, 256, 256, 2)  0           conv2d_456[0][0]                 \n",
      "                                                                 add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_76 (Multiply)          (None, 256, 256, 2)  0           add_151[0][0]                    \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_152 (Add)                   (None, 256, 256, 2)  0           multiply_76[0][0]                \n",
      "                                                                 input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 256, 256, 48) 912         add_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 256, 256, 2)  98          conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_153 (Add)                   (None, 256, 256, 2)  0           conv2d_462[0][0]                 \n",
      "                                                                 add_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_77 (Multiply)          (None, 256, 256, 2)  0           add_153[0][0]                    \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_154 (Add)                   (None, 256, 256, 2)  0           multiply_77[0][0]                \n",
      "                                                                 input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 256, 256, 48) 912         add_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 256, 256, 2)  98          conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_155 (Add)                   (None, 256, 256, 2)  0           conv2d_468[0][0]                 \n",
      "                                                                 add_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_78 (Multiply)          (None, 256, 256, 2)  0           add_155[0][0]                    \n",
      "                                                                 input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_156 (Add)                   (None, 256, 256, 2)  0           multiply_78[0][0]                \n",
      "                                                                 input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_631 (Lambda)             (None, 256, 256, 2)  0           add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_636 (Lambda)             (None, 256, 256, 1)  0           lambda_631[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ikkk_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 113s 169ms/step - loss: 0.2482 - lambda_631_loss: 0.2931 - lambda_636_loss: 0.2482 - val_loss: 0.2048 - val_lambda_631_loss: 0.2552 - val_lambda_636_loss: 0.2048\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1999 - lambda_631_loss: 0.2419 - lambda_636_loss: 0.1999 - val_loss: 0.1831 - val_lambda_631_loss: 0.2232 - val_lambda_636_loss: 0.1831\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1889 - lambda_631_loss: 0.2293 - lambda_636_loss: 0.1889 - val_loss: 0.1802 - val_lambda_631_loss: 0.2173 - val_lambda_636_loss: 0.1802\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1805 - lambda_631_loss: 0.2204 - lambda_636_loss: 0.1805 - val_loss: 0.1738 - val_lambda_631_loss: 0.2128 - val_lambda_636_loss: 0.1738\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1745 - lambda_631_loss: 0.2142 - lambda_636_loss: 0.1745 - val_loss: 0.1861 - val_lambda_631_loss: 0.2244 - val_lambda_636_loss: 0.1861\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1691 - lambda_631_loss: 0.2084 - lambda_636_loss: 0.1691 - val_loss: 0.1713 - val_lambda_631_loss: 0.2122 - val_lambda_636_loss: 0.1713\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1677 - lambda_631_loss: 0.2061 - lambda_636_loss: 0.1677 - val_loss: 0.1591 - val_lambda_631_loss: 0.1972 - val_lambda_636_loss: 0.1591\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1629 - lambda_631_loss: 0.2012 - lambda_636_loss: 0.1629 - val_loss: 0.1595 - val_lambda_631_loss: 0.1971 - val_lambda_636_loss: 0.1595\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1619 - lambda_631_loss: 0.1999 - lambda_636_loss: 0.1619 - val_loss: 0.1561 - val_lambda_631_loss: 0.2006 - val_lambda_636_loss: 0.1561\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1584 - lambda_631_loss: 0.1958 - lambda_636_loss: 0.1584 - val_loss: 0.1545 - val_lambda_631_loss: 0.1917 - val_lambda_636_loss: 0.1545\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1563 - lambda_631_loss: 0.1932 - lambda_636_loss: 0.1563 - val_loss: 0.1657 - val_lambda_631_loss: 0.2004 - val_lambda_636_loss: 0.1657\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1564 - lambda_631_loss: 0.1938 - lambda_636_loss: 0.1564 - val_loss: 0.1654 - val_lambda_631_loss: 0.1994 - val_lambda_636_loss: 0.1654\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1560 - lambda_631_loss: 0.1933 - lambda_636_loss: 0.1560 - val_loss: 0.1544 - val_lambda_631_loss: 0.1871 - val_lambda_636_loss: 0.1544\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1534 - lambda_631_loss: 0.1900 - lambda_636_loss: 0.1534 - val_loss: 0.1686 - val_lambda_631_loss: 0.2005 - val_lambda_636_loss: 0.1686\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1509 - lambda_631_loss: 0.1875 - lambda_636_loss: 0.1509 - val_loss: 0.1535 - val_lambda_631_loss: 0.1861 - val_lambda_636_loss: 0.1535\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1511 - lambda_631_loss: 0.1877 - lambda_636_loss: 0.1511 - val_loss: 0.1553 - val_lambda_631_loss: 0.1924 - val_lambda_636_loss: 0.1553\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1501 - lambda_631_loss: 0.1864 - lambda_636_loss: 0.1501 - val_loss: 0.1547 - val_lambda_631_loss: 0.1925 - val_lambda_636_loss: 0.1547\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1489 - lambda_631_loss: 0.1853 - lambda_636_loss: 0.1489 - val_loss: 0.1612 - val_lambda_631_loss: 0.1948 - val_lambda_636_loss: 0.1612\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1479 - lambda_631_loss: 0.1836 - lambda_636_loss: 0.1479 - val_loss: 0.1668 - val_lambda_631_loss: 0.2001 - val_lambda_636_loss: 0.1668\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1467 - lambda_631_loss: 0.1831 - lambda_636_loss: 0.1467 - val_loss: 0.1544 - val_lambda_631_loss: 0.1890 - val_lambda_636_loss: 0.1544\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1476 - lambda_631_loss: 0.1835 - lambda_636_loss: 0.1476 - val_loss: 0.1460 - val_lambda_631_loss: 0.1783 - val_lambda_636_loss: 0.1460\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1454 - lambda_631_loss: 0.1811 - lambda_636_loss: 0.1454 - val_loss: 0.1450 - val_lambda_631_loss: 0.1746 - val_lambda_636_loss: 0.1450\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1445 - lambda_631_loss: 0.1798 - lambda_636_loss: 0.1445 - val_loss: 0.1472 - val_lambda_631_loss: 0.1779 - val_lambda_636_loss: 0.1472\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1440 - lambda_631_loss: 0.1792 - lambda_636_loss: 0.1440 - val_loss: 0.1444 - val_lambda_631_loss: 0.1772 - val_lambda_636_loss: 0.1444\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1427 - lambda_631_loss: 0.1780 - lambda_636_loss: 0.1427 - val_loss: 0.1478 - val_lambda_631_loss: 0.1765 - val_lambda_636_loss: 0.1478\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1443 - lambda_631_loss: 0.1798 - lambda_636_loss: 0.1443 - val_loss: 0.1491 - val_lambda_631_loss: 0.1804 - val_lambda_636_loss: 0.1491\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1414 - lambda_631_loss: 0.1763 - lambda_636_loss: 0.1414 - val_loss: 0.1493 - val_lambda_631_loss: 0.1805 - val_lambda_636_loss: 0.1493\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1418 - lambda_631_loss: 0.1766 - lambda_636_loss: 0.1418 - val_loss: 0.1468 - val_lambda_631_loss: 0.1766 - val_lambda_636_loss: 0.1468\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1413 - lambda_631_loss: 0.1762 - lambda_636_loss: 0.1413 - val_loss: 0.1476 - val_lambda_631_loss: 0.1816 - val_lambda_636_loss: 0.1476\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1403 - lambda_631_loss: 0.1749 - lambda_636_loss: 0.1403 - val_loss: 0.1485 - val_lambda_631_loss: 0.1774 - val_lambda_636_loss: 0.1485\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1387 - lambda_631_loss: 0.1729 - lambda_636_loss: 0.1387 - val_loss: 0.1465 - val_lambda_631_loss: 0.1757 - val_lambda_636_loss: 0.1465\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1402 - lambda_631_loss: 0.1749 - lambda_636_loss: 0.1402 - val_loss: 0.1453 - val_lambda_631_loss: 0.1813 - val_lambda_636_loss: 0.1453\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1382 - lambda_631_loss: 0.1727 - lambda_636_loss: 0.1382 - val_loss: 0.1415 - val_lambda_631_loss: 0.1694 - val_lambda_636_loss: 0.1415\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1372 - lambda_631_loss: 0.1709 - lambda_636_loss: 0.1372 - val_loss: 0.1401 - val_lambda_631_loss: 0.1726 - val_lambda_636_loss: 0.1401\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1381 - lambda_631_loss: 0.1723 - lambda_636_loss: 0.1381 - val_loss: 0.1377 - val_lambda_631_loss: 0.1675 - val_lambda_636_loss: 0.1377\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1378 - lambda_631_loss: 0.1719 - lambda_636_loss: 0.1378 - val_loss: 0.1408 - val_lambda_631_loss: 0.1710 - val_lambda_636_loss: 0.1408\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1366 - lambda_631_loss: 0.1701 - lambda_636_loss: 0.1366 - val_loss: 0.1397 - val_lambda_631_loss: 0.1708 - val_lambda_636_loss: 0.1397\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1369 - lambda_631_loss: 0.1706 - lambda_636_loss: 0.1369 - val_loss: 0.1374 - val_lambda_631_loss: 0.1645 - val_lambda_636_loss: 0.1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1353 - lambda_631_loss: 0.1691 - lambda_636_loss: 0.1353 - val_loss: 0.1445 - val_lambda_631_loss: 0.1777 - val_lambda_636_loss: 0.1445\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1360 - lambda_631_loss: 0.1697 - lambda_636_loss: 0.1360 - val_loss: 0.1506 - val_lambda_631_loss: 0.1796 - val_lambda_636_loss: 0.1506\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1357 - lambda_631_loss: 0.1691 - lambda_636_loss: 0.1357 - val_loss: 0.1511 - val_lambda_631_loss: 0.1820 - val_lambda_636_loss: 0.1511\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1344 - lambda_631_loss: 0.1676 - lambda_636_loss: 0.1344 - val_loss: 0.1388 - val_lambda_631_loss: 0.1698 - val_lambda_636_loss: 0.1388\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1347 - lambda_631_loss: 0.1679 - lambda_636_loss: 0.1347 - val_loss: 0.1394 - val_lambda_631_loss: 0.1665 - val_lambda_636_loss: 0.1394\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1338 - lambda_631_loss: 0.1669 - lambda_636_loss: 0.1338 - val_loss: 0.1401 - val_lambda_631_loss: 0.1713 - val_lambda_636_loss: 0.1401\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1340 - lambda_631_loss: 0.1676 - lambda_636_loss: 0.1340 - val_loss: 0.1381 - val_lambda_631_loss: 0.1675 - val_lambda_636_loss: 0.1381\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1344 - lambda_631_loss: 0.1676 - lambda_636_loss: 0.1344 - val_loss: 0.1370 - val_lambda_631_loss: 0.1635 - val_lambda_636_loss: 0.1370\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1332 - lambda_631_loss: 0.1658 - lambda_636_loss: 0.1332 - val_loss: 0.1347 - val_lambda_631_loss: 0.1642 - val_lambda_636_loss: 0.1347\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1326 - lambda_631_loss: 0.1655 - lambda_636_loss: 0.1326 - val_loss: 0.1448 - val_lambda_631_loss: 0.1738 - val_lambda_636_loss: 0.1448\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1333 - lambda_631_loss: 0.1664 - lambda_636_loss: 0.1333 - val_loss: 0.1436 - val_lambda_631_loss: 0.1734 - val_lambda_636_loss: 0.1436\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.1321 - lambda_631_loss: 0.1650 - lambda_636_loss: 0.1321 - val_loss: 0.1381 - val_lambda_631_loss: 0.1669 - val_lambda_636_loss: 0.1381\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_641 (Lambda)             (None, 256, 256, 2)  0           input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 256, 256, 48) 912         lambda_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 256, 256, 2)  98          conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_157 (Add)                   (None, 256, 256, 2)  0           conv2d_474[0][0]                 \n",
      "                                                                 lambda_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_646 (Lambda)             (None, 256, 256, 2)  0           add_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_79 (Multiply)          (None, 256, 256, 2)  0           lambda_646[0][0]                 \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_158 (Add)                   (None, 256, 256, 2)  0           multiply_79[0][0]                \n",
      "                                                                 input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 256, 256, 48) 912         add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 256, 256, 2)  98          conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_159 (Add)                   (None, 256, 256, 2)  0           conv2d_480[0][0]                 \n",
      "                                                                 add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_80 (Multiply)          (None, 256, 256, 2)  0           add_159[0][0]                    \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_160 (Add)                   (None, 256, 256, 2)  0           multiply_80[0][0]                \n",
      "                                                                 input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_651 (Lambda)             (None, 256, 256, 2)  0           add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 256, 256, 48) 912         lambda_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 256, 256, 2)  98          conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_161 (Add)                   (None, 256, 256, 2)  0           conv2d_486[0][0]                 \n",
      "                                                                 lambda_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_656 (Lambda)             (None, 256, 256, 2)  0           add_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_81 (Multiply)          (None, 256, 256, 2)  0           lambda_656[0][0]                 \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_162 (Add)                   (None, 256, 256, 2)  0           multiply_81[0][0]                \n",
      "                                                                 input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 256, 256, 48) 912         add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 256, 256, 2)  98          conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_163 (Add)                   (None, 256, 256, 2)  0           conv2d_492[0][0]                 \n",
      "                                                                 add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)          (None, 256, 256, 2)  0           add_163[0][0]                    \n",
      "                                                                 input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_164 (Add)                   (None, 256, 256, 2)  0           multiply_82[0][0]                \n",
      "                                                                 input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_661 (Lambda)             (None, 256, 256, 2)  0           add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_666 (Lambda)             (None, 256, 256, 1)  0           lambda_661[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ikik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 114s 171ms/step - loss: 0.2036 - lambda_661_loss: 0.2338 - lambda_666_loss: 0.2036 - val_loss: 0.1452 - val_lambda_661_loss: 0.1664 - val_lambda_666_loss: 0.1452\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1433 - lambda_661_loss: 0.1684 - lambda_666_loss: 0.1433 - val_loss: 0.1301 - val_lambda_661_loss: 0.1576 - val_lambda_666_loss: 0.1301\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1294 - lambda_661_loss: 0.1513 - lambda_666_loss: 0.1294 - val_loss: 0.1396 - val_lambda_661_loss: 0.1644 - val_lambda_666_loss: 0.1396\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1245 - lambda_661_loss: 0.1455 - lambda_666_loss: 0.1245 - val_loss: 0.1186 - val_lambda_661_loss: 0.1354 - val_lambda_666_loss: 0.1186\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1186 - lambda_661_loss: 0.1383 - lambda_666_loss: 0.1186 - val_loss: 0.1288 - val_lambda_661_loss: 0.1514 - val_lambda_666_loss: 0.1288\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1159 - lambda_661_loss: 0.1357 - lambda_666_loss: 0.1159 - val_loss: 0.1149 - val_lambda_661_loss: 0.1358 - val_lambda_666_loss: 0.1149\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1117 - lambda_661_loss: 0.1306 - lambda_666_loss: 0.1117 - val_loss: 0.1111 - val_lambda_661_loss: 0.1291 - val_lambda_666_loss: 0.1111\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1102 - lambda_661_loss: 0.1291 - lambda_666_loss: 0.1102 - val_loss: 0.1207 - val_lambda_661_loss: 0.1353 - val_lambda_666_loss: 0.1207\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1085 - lambda_661_loss: 0.1267 - lambda_666_loss: 0.1085 - val_loss: 0.1259 - val_lambda_661_loss: 0.1499 - val_lambda_666_loss: 0.1259\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1063 - lambda_661_loss: 0.1241 - lambda_666_loss: 0.1063 - val_loss: 0.1197 - val_lambda_661_loss: 0.1393 - val_lambda_666_loss: 0.1197\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1057 - lambda_661_loss: 0.1232 - lambda_666_loss: 0.1057 - val_loss: 0.1250 - val_lambda_661_loss: 0.1458 - val_lambda_666_loss: 0.1250\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1037 - lambda_661_loss: 0.1212 - lambda_666_loss: 0.1037 - val_loss: 0.1262 - val_lambda_661_loss: 0.1607 - val_lambda_666_loss: 0.1262\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1025 - lambda_661_loss: 0.1198 - lambda_666_loss: 0.1025 - val_loss: 0.1116 - val_lambda_661_loss: 0.1316 - val_lambda_666_loss: 0.1116\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1035 - lambda_661_loss: 0.1208 - lambda_666_loss: 0.1035 - val_loss: 0.1126 - val_lambda_661_loss: 0.1303 - val_lambda_666_loss: 0.1126\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1010 - lambda_661_loss: 0.1181 - lambda_666_loss: 0.1010 - val_loss: 0.1159 - val_lambda_661_loss: 0.1371 - val_lambda_666_loss: 0.1159\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1003 - lambda_661_loss: 0.1170 - lambda_666_loss: 0.1003 - val_loss: 0.1045 - val_lambda_661_loss: 0.1225 - val_lambda_666_loss: 0.1045\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.1001 - lambda_661_loss: 0.1174 - lambda_666_loss: 0.1001 - val_loss: 0.1075 - val_lambda_661_loss: 0.1298 - val_lambda_666_loss: 0.1075\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0987 - lambda_661_loss: 0.1150 - lambda_666_loss: 0.0987 - val_loss: 0.1087 - val_lambda_661_loss: 0.1283 - val_lambda_666_loss: 0.1087\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0973 - lambda_661_loss: 0.1134 - lambda_666_loss: 0.0973 - val_loss: 0.1114 - val_lambda_661_loss: 0.1335 - val_lambda_666_loss: 0.1114\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0983 - lambda_661_loss: 0.1145 - lambda_666_loss: 0.0983 - val_loss: 0.1052 - val_lambda_661_loss: 0.1268 - val_lambda_666_loss: 0.1052\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0972 - lambda_661_loss: 0.1133 - lambda_666_loss: 0.0972 - val_loss: 0.1144 - val_lambda_661_loss: 0.1361 - val_lambda_666_loss: 0.1144\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0958 - lambda_661_loss: 0.1117 - lambda_666_loss: 0.0958 - val_loss: 0.1119 - val_lambda_661_loss: 0.1288 - val_lambda_666_loss: 0.1119\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0960 - lambda_661_loss: 0.1118 - lambda_666_loss: 0.0960 - val_loss: 0.1054 - val_lambda_661_loss: 0.1220 - val_lambda_666_loss: 0.1054\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0950 - lambda_661_loss: 0.1106 - lambda_666_loss: 0.0950 - val_loss: 0.1105 - val_lambda_661_loss: 0.1319 - val_lambda_666_loss: 0.1105\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0950 - lambda_661_loss: 0.1108 - lambda_666_loss: 0.0950 - val_loss: 0.1075 - val_lambda_661_loss: 0.1338 - val_lambda_666_loss: 0.1075\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0937 - lambda_661_loss: 0.1091 - lambda_666_loss: 0.0937 - val_loss: 0.1069 - val_lambda_661_loss: 0.1279 - val_lambda_666_loss: 0.1069\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0937 - lambda_661_loss: 0.1092 - lambda_666_loss: 0.0937 - val_loss: 0.1058 - val_lambda_661_loss: 0.1239 - val_lambda_666_loss: 0.1058\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0933 - lambda_661_loss: 0.1086 - lambda_666_loss: 0.0933 - val_loss: 0.1062 - val_lambda_661_loss: 0.1241 - val_lambda_666_loss: 0.1062\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0929 - lambda_661_loss: 0.1080 - lambda_666_loss: 0.0929 - val_loss: 0.1025 - val_lambda_661_loss: 0.1197 - val_lambda_666_loss: 0.1025\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0927 - lambda_661_loss: 0.1082 - lambda_666_loss: 0.0927 - val_loss: 0.1028 - val_lambda_661_loss: 0.1200 - val_lambda_666_loss: 0.1028\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0927 - lambda_661_loss: 0.1083 - lambda_666_loss: 0.0927 - val_loss: 0.0968 - val_lambda_661_loss: 0.1119 - val_lambda_666_loss: 0.0968\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0924 - lambda_661_loss: 0.1072 - lambda_666_loss: 0.0924 - val_loss: 0.1041 - val_lambda_661_loss: 0.1246 - val_lambda_666_loss: 0.1041\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0920 - lambda_661_loss: 0.1071 - lambda_666_loss: 0.0920 - val_loss: 0.1043 - val_lambda_661_loss: 0.1225 - val_lambda_666_loss: 0.1043\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0908 - lambda_661_loss: 0.1056 - lambda_666_loss: 0.0908 - val_loss: 0.0977 - val_lambda_661_loss: 0.1145 - val_lambda_666_loss: 0.0977\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0913 - lambda_661_loss: 0.1062 - lambda_666_loss: 0.0913 - val_loss: 0.1083 - val_lambda_661_loss: 0.1252 - val_lambda_666_loss: 0.1083\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0904 - lambda_661_loss: 0.1051 - lambda_666_loss: 0.0904 - val_loss: 0.1063 - val_lambda_661_loss: 0.1197 - val_lambda_666_loss: 0.1063\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0904 - lambda_661_loss: 0.1049 - lambda_666_loss: 0.0904 - val_loss: 0.1115 - val_lambda_661_loss: 0.1297 - val_lambda_666_loss: 0.1115\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0903 - lambda_661_loss: 0.1051 - lambda_666_loss: 0.0903 - val_loss: 0.1018 - val_lambda_661_loss: 0.1162 - val_lambda_666_loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0900 - lambda_661_loss: 0.1046 - lambda_666_loss: 0.0900 - val_loss: 0.1075 - val_lambda_661_loss: 0.1292 - val_lambda_666_loss: 0.1075\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0901 - lambda_661_loss: 0.1046 - lambda_666_loss: 0.0901 - val_loss: 0.1014 - val_lambda_661_loss: 0.1164 - val_lambda_666_loss: 0.1014\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0886 - lambda_661_loss: 0.1030 - lambda_666_loss: 0.0886 - val_loss: 0.0966 - val_lambda_661_loss: 0.1101 - val_lambda_666_loss: 0.0966\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0892 - lambda_661_loss: 0.1036 - lambda_666_loss: 0.0892 - val_loss: 0.1032 - val_lambda_661_loss: 0.1206 - val_lambda_666_loss: 0.1032\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0885 - lambda_661_loss: 0.1028 - lambda_666_loss: 0.0885 - val_loss: 0.1006 - val_lambda_661_loss: 0.1173 - val_lambda_666_loss: 0.1006\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0884 - lambda_661_loss: 0.1027 - lambda_666_loss: 0.0884 - val_loss: 0.1002 - val_lambda_661_loss: 0.1175 - val_lambda_666_loss: 0.1002\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0885 - lambda_661_loss: 0.1025 - lambda_666_loss: 0.0885 - val_loss: 0.1095 - val_lambda_661_loss: 0.1254 - val_lambda_666_loss: 0.1095\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0888 - lambda_661_loss: 0.1029 - lambda_666_loss: 0.0888 - val_loss: 0.1007 - val_lambda_661_loss: 0.1196 - val_lambda_666_loss: 0.1007\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0887 - lambda_661_loss: 0.1030 - lambda_666_loss: 0.0887 - val_loss: 0.0997 - val_lambda_661_loss: 0.1179 - val_lambda_666_loss: 0.0997\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.0876 - lambda_661_loss: 0.1017 - lambda_666_loss: 0.0876 - val_loss: 0.0971 - val_lambda_661_loss: 0.1137 - val_lambda_666_loss: 0.0971\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0880 - lambda_661_loss: 0.1021 - lambda_666_loss: 0.0880 - val_loss: 0.1017 - val_lambda_661_loss: 0.1184 - val_lambda_666_loss: 0.1017\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0871 - lambda_661_loss: 0.1010 - lambda_666_loss: 0.0871 - val_loss: 0.0957 - val_lambda_661_loss: 0.1121 - val_lambda_666_loss: 0.0957\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_671 (Lambda)             (None, 256, 256, 2)  0           input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 256, 256, 48) 912         lambda_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 256, 256, 2)  98          conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_165 (Add)                   (None, 256, 256, 2)  0           conv2d_498[0][0]                 \n",
      "                                                                 lambda_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_676 (Lambda)             (None, 256, 256, 2)  0           add_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)          (None, 256, 256, 2)  0           lambda_676[0][0]                 \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_166 (Add)                   (None, 256, 256, 2)  0           multiply_83[0][0]                \n",
      "                                                                 input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 256, 256, 48) 912         add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 256, 256, 2)  98          conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_167 (Add)                   (None, 256, 256, 2)  0           conv2d_504[0][0]                 \n",
      "                                                                 add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_84 (Multiply)          (None, 256, 256, 2)  0           add_167[0][0]                    \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_168 (Add)                   (None, 256, 256, 2)  0           multiply_84[0][0]                \n",
      "                                                                 input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 256, 256, 48) 912         add_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 256, 256, 2)  98          conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_169 (Add)                   (None, 256, 256, 2)  0           conv2d_510[0][0]                 \n",
      "                                                                 add_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_85 (Multiply)          (None, 256, 256, 2)  0           add_169[0][0]                    \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_170 (Add)                   (None, 256, 256, 2)  0           multiply_85[0][0]                \n",
      "                                                                 input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_681 (Lambda)             (None, 256, 256, 2)  0           add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 256, 256, 48) 912         lambda_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 256, 256, 2)  98          conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 256, 256, 2)  0           conv2d_516[0][0]                 \n",
      "                                                                 lambda_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_686 (Lambda)             (None, 256, 256, 2)  0           add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_86 (Multiply)          (None, 256, 256, 2)  0           lambda_686[0][0]                 \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 256, 256, 2)  0           multiply_86[0][0]                \n",
      "                                                                 input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_691 (Lambda)             (None, 256, 256, 2)  0           add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_696 (Lambda)             (None, 256, 256, 1)  0           lambda_691[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ikki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 115s 172ms/step - loss: 0.2034 - lambda_691_loss: 0.2313 - lambda_696_loss: 0.2034 - val_loss: 0.1491 - val_lambda_691_loss: 0.1724 - val_lambda_696_loss: 0.1491\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 105s 158ms/step - loss: 0.1436 - lambda_691_loss: 0.1664 - lambda_696_loss: 0.1436 - val_loss: 0.1294 - val_lambda_691_loss: 0.1544 - val_lambda_696_loss: 0.1294\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1321 - lambda_691_loss: 0.1539 - lambda_696_loss: 0.1321 - val_loss: 0.1317 - val_lambda_691_loss: 0.1556 - val_lambda_696_loss: 0.1317\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1238 - lambda_691_loss: 0.1440 - lambda_696_loss: 0.1238 - val_loss: 0.1310 - val_lambda_691_loss: 0.1502 - val_lambda_696_loss: 0.1310\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1207 - lambda_691_loss: 0.1404 - lambda_696_loss: 0.1207 - val_loss: 0.1231 - val_lambda_691_loss: 0.1493 - val_lambda_696_loss: 0.1231\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1172 - lambda_691_loss: 0.1363 - lambda_696_loss: 0.1172 - val_loss: 0.1406 - val_lambda_691_loss: 0.1582 - val_lambda_696_loss: 0.1406\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1153 - lambda_691_loss: 0.1338 - lambda_696_loss: 0.1153 - val_loss: 0.1181 - val_lambda_691_loss: 0.1387 - val_lambda_696_loss: 0.1181\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1124 - lambda_691_loss: 0.1308 - lambda_696_loss: 0.1124 - val_loss: 0.1328 - val_lambda_691_loss: 0.1600 - val_lambda_696_loss: 0.1328\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1123 - lambda_691_loss: 0.1299 - lambda_696_loss: 0.1123 - val_loss: 0.1208 - val_lambda_691_loss: 0.1412 - val_lambda_696_loss: 0.1208\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1087 - lambda_691_loss: 0.1260 - lambda_696_loss: 0.1087 - val_loss: 0.1115 - val_lambda_691_loss: 0.1325 - val_lambda_696_loss: 0.1115\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1082 - lambda_691_loss: 0.1252 - lambda_696_loss: 0.1082 - val_loss: 0.1081 - val_lambda_691_loss: 0.1233 - val_lambda_696_loss: 0.1081\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1064 - lambda_691_loss: 0.1231 - lambda_696_loss: 0.1064 - val_loss: 0.1081 - val_lambda_691_loss: 0.1282 - val_lambda_696_loss: 0.1081\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1064 - lambda_691_loss: 0.1237 - lambda_696_loss: 0.1064 - val_loss: 0.1071 - val_lambda_691_loss: 0.1291 - val_lambda_696_loss: 0.1071\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1040 - lambda_691_loss: 0.1203 - lambda_696_loss: 0.1040 - val_loss: 0.1123 - val_lambda_691_loss: 0.1313 - val_lambda_696_loss: 0.1123\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1031 - lambda_691_loss: 0.1191 - lambda_696_loss: 0.1031 - val_loss: 0.1285 - val_lambda_691_loss: 0.1547 - val_lambda_696_loss: 0.1285\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1025 - lambda_691_loss: 0.1185 - lambda_696_loss: 0.1025 - val_loss: 0.1076 - val_lambda_691_loss: 0.1273 - val_lambda_696_loss: 0.1076\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1029 - lambda_691_loss: 0.1188 - lambda_696_loss: 0.1029 - val_loss: 0.1079 - val_lambda_691_loss: 0.1288 - val_lambda_696_loss: 0.1079\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1020 - lambda_691_loss: 0.1176 - lambda_696_loss: 0.1020 - val_loss: 0.1115 - val_lambda_691_loss: 0.1336 - val_lambda_696_loss: 0.1115\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1002 - lambda_691_loss: 0.1157 - lambda_696_loss: 0.1002 - val_loss: 0.1065 - val_lambda_691_loss: 0.1262 - val_lambda_696_loss: 0.1065\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0993 - lambda_691_loss: 0.1143 - lambda_696_loss: 0.0993 - val_loss: 0.1134 - val_lambda_691_loss: 0.1326 - val_lambda_696_loss: 0.1134\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0990 - lambda_691_loss: 0.1141 - lambda_696_loss: 0.0990 - val_loss: 0.1142 - val_lambda_691_loss: 0.1398 - val_lambda_696_loss: 0.1142\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0992 - lambda_691_loss: 0.1142 - lambda_696_loss: 0.0992 - val_loss: 0.1074 - val_lambda_691_loss: 0.1262 - val_lambda_696_loss: 0.1074\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0979 - lambda_691_loss: 0.1126 - lambda_696_loss: 0.0979 - val_loss: 0.1127 - val_lambda_691_loss: 0.1363 - val_lambda_696_loss: 0.1127\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0978 - lambda_691_loss: 0.1127 - lambda_696_loss: 0.0978 - val_loss: 0.1047 - val_lambda_691_loss: 0.1277 - val_lambda_696_loss: 0.1047\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0970 - lambda_691_loss: 0.1116 - lambda_696_loss: 0.0970 - val_loss: 0.1094 - val_lambda_691_loss: 0.1332 - val_lambda_696_loss: 0.1094\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0965 - lambda_691_loss: 0.1111 - lambda_696_loss: 0.0965 - val_loss: 0.1122 - val_lambda_691_loss: 0.1332 - val_lambda_696_loss: 0.1122\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0959 - lambda_691_loss: 0.1105 - lambda_696_loss: 0.0959 - val_loss: 0.1027 - val_lambda_691_loss: 0.1225 - val_lambda_696_loss: 0.1027\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0961 - lambda_691_loss: 0.1104 - lambda_696_loss: 0.0961 - val_loss: 0.1173 - val_lambda_691_loss: 0.1378 - val_lambda_696_loss: 0.1173\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0955 - lambda_691_loss: 0.1097 - lambda_696_loss: 0.0955 - val_loss: 0.1074 - val_lambda_691_loss: 0.1259 - val_lambda_696_loss: 0.1074\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0944 - lambda_691_loss: 0.1084 - lambda_696_loss: 0.0944 - val_loss: 0.1244 - val_lambda_691_loss: 0.1476 - val_lambda_696_loss: 0.1244\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0958 - lambda_691_loss: 0.1104 - lambda_696_loss: 0.0958 - val_loss: 0.0991 - val_lambda_691_loss: 0.1135 - val_lambda_696_loss: 0.0991\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0942 - lambda_691_loss: 0.1081 - lambda_696_loss: 0.0942 - val_loss: 0.1112 - val_lambda_691_loss: 0.1317 - val_lambda_696_loss: 0.1112\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0934 - lambda_691_loss: 0.1073 - lambda_696_loss: 0.0934 - val_loss: 0.1142 - val_lambda_691_loss: 0.1334 - val_lambda_696_loss: 0.1142\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0935 - lambda_691_loss: 0.1074 - lambda_696_loss: 0.0935 - val_loss: 0.1064 - val_lambda_691_loss: 0.1283 - val_lambda_696_loss: 0.1064\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0931 - lambda_691_loss: 0.1069 - lambda_696_loss: 0.0931 - val_loss: 0.0994 - val_lambda_691_loss: 0.1154 - val_lambda_696_loss: 0.0994\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0933 - lambda_691_loss: 0.1071 - lambda_696_loss: 0.0933 - val_loss: 0.1061 - val_lambda_691_loss: 0.1278 - val_lambda_696_loss: 0.1061\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0921 - lambda_691_loss: 0.1058 - lambda_696_loss: 0.0921 - val_loss: 0.0993 - val_lambda_691_loss: 0.1167 - val_lambda_696_loss: 0.0993\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0922 - lambda_691_loss: 0.1059 - lambda_696_loss: 0.0922 - val_loss: 0.1046 - val_lambda_691_loss: 0.1285 - val_lambda_696_loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.0919 - lambda_691_loss: 0.1055 - lambda_696_loss: 0.0919 - val_loss: 0.1039 - val_lambda_691_loss: 0.1207 - val_lambda_696_loss: 0.1039\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0918 - lambda_691_loss: 0.1054 - lambda_696_loss: 0.0918 - val_loss: 0.1024 - val_lambda_691_loss: 0.1226 - val_lambda_696_loss: 0.1024\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0915 - lambda_691_loss: 0.1050 - lambda_696_loss: 0.0915 - val_loss: 0.1015 - val_lambda_691_loss: 0.1189 - val_lambda_696_loss: 0.1015\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0913 - lambda_691_loss: 0.1047 - lambda_696_loss: 0.0913 - val_loss: 0.1156 - val_lambda_691_loss: 0.1326 - val_lambda_696_loss: 0.1156\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0909 - lambda_691_loss: 0.1041 - lambda_696_loss: 0.0909 - val_loss: 0.0979 - val_lambda_691_loss: 0.1145 - val_lambda_696_loss: 0.0979\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0904 - lambda_691_loss: 0.1038 - lambda_696_loss: 0.0904 - val_loss: 0.1052 - val_lambda_691_loss: 0.1238 - val_lambda_696_loss: 0.1052\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0908 - lambda_691_loss: 0.1038 - lambda_696_loss: 0.0908 - val_loss: 0.1081 - val_lambda_691_loss: 0.1325 - val_lambda_696_loss: 0.1081\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0899 - lambda_691_loss: 0.1031 - lambda_696_loss: 0.0899 - val_loss: 0.1022 - val_lambda_691_loss: 0.1198 - val_lambda_696_loss: 0.1022\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0893 - lambda_691_loss: 0.1021 - lambda_696_loss: 0.0893 - val_loss: 0.0996 - val_lambda_691_loss: 0.1177 - val_lambda_696_loss: 0.0996\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0902 - lambda_691_loss: 0.1034 - lambda_696_loss: 0.0902 - val_loss: 0.1029 - val_lambda_691_loss: 0.1184 - val_lambda_696_loss: 0.1029\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0894 - lambda_691_loss: 0.1023 - lambda_696_loss: 0.0894 - val_loss: 0.1006 - val_lambda_691_loss: 0.1187 - val_lambda_696_loss: 0.1006\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0894 - lambda_691_loss: 0.1022 - lambda_696_loss: 0.0894 - val_loss: 0.0997 - val_lambda_691_loss: 0.1142 - val_lambda_696_loss: 0.0997\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_701 (Lambda)             (None, 256, 256, 2)  0           input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 256, 256, 48) 912         lambda_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 256, 256, 2)  98          conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_173 (Add)                   (None, 256, 256, 2)  0           conv2d_522[0][0]                 \n",
      "                                                                 lambda_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_706 (Lambda)             (None, 256, 256, 2)  0           add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_87 (Multiply)          (None, 256, 256, 2)  0           lambda_706[0][0]                 \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_174 (Add)                   (None, 256, 256, 2)  0           multiply_87[0][0]                \n",
      "                                                                 input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_711 (Lambda)             (None, 256, 256, 2)  0           add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 256, 256, 48) 912         lambda_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 256, 256, 2)  98          conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_175 (Add)                   (None, 256, 256, 2)  0           conv2d_528[0][0]                 \n",
      "                                                                 lambda_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_716 (Lambda)             (None, 256, 256, 2)  0           add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_88 (Multiply)          (None, 256, 256, 2)  0           lambda_716[0][0]                 \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_176 (Add)                   (None, 256, 256, 2)  0           multiply_88[0][0]                \n",
      "                                                                 input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_721 (Lambda)             (None, 256, 256, 2)  0           add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 256, 256, 48) 912         lambda_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 256, 256, 2)  98          conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_177 (Add)                   (None, 256, 256, 2)  0           conv2d_534[0][0]                 \n",
      "                                                                 lambda_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_726 (Lambda)             (None, 256, 256, 2)  0           add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_89 (Multiply)          (None, 256, 256, 2)  0           lambda_726[0][0]                 \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 256, 256, 2)  0           multiply_89[0][0]                \n",
      "                                                                 input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 256, 256, 48) 912         add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 256, 256, 2)  98          conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 256, 256, 2)  0           conv2d_540[0][0]                 \n",
      "                                                                 add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_90 (Multiply)          (None, 256, 256, 2)  0           add_179[0][0]                    \n",
      "                                                                 input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 256, 256, 2)  0           multiply_90[0][0]                \n",
      "                                                                 input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_731 (Lambda)             (None, 256, 256, 2)  0           add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_736 (Lambda)             (None, 256, 256, 1)  0           lambda_731[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iiik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 116s 174ms/step - loss: 0.2009 - lambda_731_loss: 0.2403 - lambda_736_loss: 0.2009 - val_loss: 0.1533 - val_lambda_731_loss: 0.1911 - val_lambda_736_loss: 0.1533\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1405 - lambda_731_loss: 0.1683 - lambda_736_loss: 0.1405 - val_loss: 0.1322 - val_lambda_731_loss: 0.1560 - val_lambda_736_loss: 0.1322\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1243 - lambda_731_loss: 0.1487 - lambda_736_loss: 0.1243 - val_loss: 0.1245 - val_lambda_731_loss: 0.1454 - val_lambda_736_loss: 0.1245\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1184 - lambda_731_loss: 0.1412 - lambda_736_loss: 0.1184 - val_loss: 0.1228 - val_lambda_731_loss: 0.1443 - val_lambda_736_loss: 0.1228\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1110 - lambda_731_loss: 0.1315 - lambda_736_loss: 0.1110 - val_loss: 0.1309 - val_lambda_731_loss: 0.1476 - val_lambda_736_loss: 0.1309\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1074 - lambda_731_loss: 0.1272 - lambda_736_loss: 0.1074 - val_loss: 0.1234 - val_lambda_731_loss: 0.1530 - val_lambda_736_loss: 0.1234\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1052 - lambda_731_loss: 0.1250 - lambda_736_loss: 0.1052 - val_loss: 0.1158 - val_lambda_731_loss: 0.1331 - val_lambda_736_loss: 0.1158\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1035 - lambda_731_loss: 0.1220 - lambda_736_loss: 0.1035 - val_loss: 0.1080 - val_lambda_731_loss: 0.1246 - val_lambda_736_loss: 0.1080\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1020 - lambda_731_loss: 0.1203 - lambda_736_loss: 0.1020 - val_loss: 0.1096 - val_lambda_731_loss: 0.1285 - val_lambda_736_loss: 0.1096\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1002 - lambda_731_loss: 0.1178 - lambda_736_loss: 0.1002 - val_loss: 0.1106 - val_lambda_731_loss: 0.1264 - val_lambda_736_loss: 0.1106\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0964 - lambda_731_loss: 0.1132 - lambda_736_loss: 0.0964 - val_loss: 0.1000 - val_lambda_731_loss: 0.1154 - val_lambda_736_loss: 0.1000\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0984 - lambda_731_loss: 0.1160 - lambda_736_loss: 0.0984 - val_loss: 0.1142 - val_lambda_731_loss: 0.1368 - val_lambda_736_loss: 0.1142\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0958 - lambda_731_loss: 0.1116 - lambda_736_loss: 0.0958 - val_loss: 0.1014 - val_lambda_731_loss: 0.1215 - val_lambda_736_loss: 0.1014\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0938 - lambda_731_loss: 0.1102 - lambda_736_loss: 0.0938 - val_loss: 0.1000 - val_lambda_731_loss: 0.1163 - val_lambda_736_loss: 0.1000\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0944 - lambda_731_loss: 0.1099 - lambda_736_loss: 0.0944 - val_loss: 0.0983 - val_lambda_731_loss: 0.1165 - val_lambda_736_loss: 0.0983\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0926 - lambda_731_loss: 0.1080 - lambda_736_loss: 0.0926 - val_loss: 0.0972 - val_lambda_731_loss: 0.1122 - val_lambda_736_loss: 0.0972\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0913 - lambda_731_loss: 0.1066 - lambda_736_loss: 0.0913 - val_loss: 0.1033 - val_lambda_731_loss: 0.1167 - val_lambda_736_loss: 0.1033\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0925 - lambda_731_loss: 0.1081 - lambda_736_loss: 0.0925 - val_loss: 0.1062 - val_lambda_731_loss: 0.1257 - val_lambda_736_loss: 0.1062\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0901 - lambda_731_loss: 0.1047 - lambda_736_loss: 0.0901 - val_loss: 0.0970 - val_lambda_731_loss: 0.1132 - val_lambda_736_loss: 0.0970\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0897 - lambda_731_loss: 0.1047 - lambda_736_loss: 0.0897 - val_loss: 0.1032 - val_lambda_731_loss: 0.1158 - val_lambda_736_loss: 0.1032\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0884 - lambda_731_loss: 0.1026 - lambda_736_loss: 0.0884 - val_loss: 0.0951 - val_lambda_731_loss: 0.1087 - val_lambda_736_loss: 0.0951\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0907 - lambda_731_loss: 0.1061 - lambda_736_loss: 0.0907 - val_loss: 0.1003 - val_lambda_731_loss: 0.1149 - val_lambda_736_loss: 0.1003\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0892 - lambda_731_loss: 0.1039 - lambda_736_loss: 0.0892 - val_loss: 0.0964 - val_lambda_731_loss: 0.1104 - val_lambda_736_loss: 0.0964\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0871 - lambda_731_loss: 0.1008 - lambda_736_loss: 0.0871 - val_loss: 0.0960 - val_lambda_731_loss: 0.1099 - val_lambda_736_loss: 0.0960\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0873 - lambda_731_loss: 0.1018 - lambda_736_loss: 0.0873 - val_loss: 0.0938 - val_lambda_731_loss: 0.1064 - val_lambda_736_loss: 0.0938\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0872 - lambda_731_loss: 0.1018 - lambda_736_loss: 0.0872 - val_loss: 0.0965 - val_lambda_731_loss: 0.1104 - val_lambda_736_loss: 0.0965\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0861 - lambda_731_loss: 0.1001 - lambda_736_loss: 0.0861 - val_loss: 0.0977 - val_lambda_731_loss: 0.1151 - val_lambda_736_loss: 0.0977\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0866 - lambda_731_loss: 0.1004 - lambda_736_loss: 0.0866 - val_loss: 0.0980 - val_lambda_731_loss: 0.1113 - val_lambda_736_loss: 0.0980\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0862 - lambda_731_loss: 0.0999 - lambda_736_loss: 0.0862 - val_loss: 0.0935 - val_lambda_731_loss: 0.1067 - val_lambda_736_loss: 0.0935\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0861 - lambda_731_loss: 0.1004 - lambda_736_loss: 0.0861 - val_loss: 0.0921 - val_lambda_731_loss: 0.1056 - val_lambda_736_loss: 0.0921\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0849 - lambda_731_loss: 0.0984 - lambda_736_loss: 0.0849 - val_loss: 0.0909 - val_lambda_731_loss: 0.1036 - val_lambda_736_loss: 0.0909\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0858 - lambda_731_loss: 0.0998 - lambda_736_loss: 0.0858 - val_loss: 0.0955 - val_lambda_731_loss: 0.1089 - val_lambda_736_loss: 0.0955\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0849 - lambda_731_loss: 0.0982 - lambda_736_loss: 0.0849 - val_loss: 0.0989 - val_lambda_731_loss: 0.1141 - val_lambda_736_loss: 0.0989\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0849 - lambda_731_loss: 0.0986 - lambda_736_loss: 0.0849 - val_loss: 0.0934 - val_lambda_731_loss: 0.1067 - val_lambda_736_loss: 0.0934\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0840 - lambda_731_loss: 0.0971 - lambda_736_loss: 0.0840 - val_loss: 0.0962 - val_lambda_731_loss: 0.1096 - val_lambda_736_loss: 0.0962\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0842 - lambda_731_loss: 0.0975 - lambda_736_loss: 0.0842 - val_loss: 0.1008 - val_lambda_731_loss: 0.1153 - val_lambda_736_loss: 0.1008\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0837 - lambda_731_loss: 0.0970 - lambda_736_loss: 0.0837 - val_loss: 0.0929 - val_lambda_731_loss: 0.1059 - val_lambda_736_loss: 0.0929\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0826 - lambda_731_loss: 0.0956 - lambda_736_loss: 0.0826 - val_loss: 0.0908 - val_lambda_731_loss: 0.1027 - val_lambda_736_loss: 0.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0838 - lambda_731_loss: 0.0971 - lambda_736_loss: 0.0838 - val_loss: 0.0990 - val_lambda_731_loss: 0.1108 - val_lambda_736_loss: 0.0990\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0824 - lambda_731_loss: 0.0955 - lambda_736_loss: 0.0824 - val_loss: 0.0936 - val_lambda_731_loss: 0.1068 - val_lambda_736_loss: 0.0936\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0817 - lambda_731_loss: 0.0945 - lambda_736_loss: 0.0817 - val_loss: 0.0939 - val_lambda_731_loss: 0.1075 - val_lambda_736_loss: 0.0939\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0830 - lambda_731_loss: 0.0964 - lambda_736_loss: 0.0830 - val_loss: 0.0939 - val_lambda_731_loss: 0.1103 - val_lambda_736_loss: 0.0939\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0821 - lambda_731_loss: 0.0951 - lambda_736_loss: 0.0821 - val_loss: 0.0966 - val_lambda_731_loss: 0.1082 - val_lambda_736_loss: 0.0966\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0816 - lambda_731_loss: 0.0945 - lambda_736_loss: 0.0816 - val_loss: 0.0959 - val_lambda_731_loss: 0.1102 - val_lambda_736_loss: 0.0959\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0807 - lambda_731_loss: 0.0935 - lambda_736_loss: 0.0807 - val_loss: 0.0909 - val_lambda_731_loss: 0.1038 - val_lambda_736_loss: 0.0909\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0808 - lambda_731_loss: 0.0935 - lambda_736_loss: 0.0808 - val_loss: 0.0974 - val_lambda_731_loss: 0.1082 - val_lambda_736_loss: 0.0974\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0810 - lambda_731_loss: 0.0938 - lambda_736_loss: 0.0810 - val_loss: 0.0960 - val_lambda_731_loss: 0.1082 - val_lambda_736_loss: 0.0960\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0817 - lambda_731_loss: 0.0950 - lambda_736_loss: 0.0817 - val_loss: 0.0900 - val_lambda_731_loss: 0.1038 - val_lambda_736_loss: 0.0900\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0806 - lambda_731_loss: 0.0935 - lambda_736_loss: 0.0806 - val_loss: 0.0965 - val_lambda_731_loss: 0.1084 - val_lambda_736_loss: 0.0965\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0806 - lambda_731_loss: 0.0932 - lambda_736_loss: 0.0806 - val_loss: 0.0899 - val_lambda_731_loss: 0.1021 - val_lambda_736_loss: 0.0899\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_741 (Lambda)             (None, 256, 256, 2)  0           input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 256, 256, 48) 912         lambda_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 256, 256, 2)  98          conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 256, 256, 2)  0           conv2d_546[0][0]                 \n",
      "                                                                 lambda_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_746 (Lambda)             (None, 256, 256, 2)  0           add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_91 (Multiply)          (None, 256, 256, 2)  0           lambda_746[0][0]                 \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 256, 256, 2)  0           multiply_91[0][0]                \n",
      "                                                                 input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_751 (Lambda)             (None, 256, 256, 2)  0           add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 256, 256, 48) 912         lambda_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 256, 256, 2)  98          conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 256, 256, 2)  0           conv2d_552[0][0]                 \n",
      "                                                                 lambda_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_756 (Lambda)             (None, 256, 256, 2)  0           add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_92 (Multiply)          (None, 256, 256, 2)  0           lambda_756[0][0]                 \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 256, 256, 2)  0           multiply_92[0][0]                \n",
      "                                                                 input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 256, 256, 48) 912         add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 256, 256, 2)  98          conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 256, 256, 2)  0           conv2d_558[0][0]                 \n",
      "                                                                 add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_93 (Multiply)          (None, 256, 256, 2)  0           add_185[0][0]                    \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_186 (Add)                   (None, 256, 256, 2)  0           multiply_93[0][0]                \n",
      "                                                                 input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_761 (Lambda)             (None, 256, 256, 2)  0           add_186[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 256, 256, 48) 912         lambda_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 256, 256, 2)  98          conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_187 (Add)                   (None, 256, 256, 2)  0           conv2d_564[0][0]                 \n",
      "                                                                 lambda_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_766 (Lambda)             (None, 256, 256, 2)  0           add_187[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_94 (Multiply)          (None, 256, 256, 2)  0           lambda_766[0][0]                 \n",
      "                                                                 input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_188 (Add)                   (None, 256, 256, 2)  0           multiply_94[0][0]                \n",
      "                                                                 input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_771 (Lambda)             (None, 256, 256, 2)  0           add_188[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_776 (Lambda)             (None, 256, 256, 1)  0           lambda_771[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iiki_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 116s 174ms/step - loss: 0.1867 - lambda_771_loss: 0.2111 - lambda_776_loss: 0.1867 - val_loss: 0.1348 - val_lambda_771_loss: 0.1533 - val_lambda_776_loss: 0.1348\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.1330 - lambda_771_loss: 0.1564 - lambda_776_loss: 0.1330 - val_loss: 0.1341 - val_lambda_771_loss: 0.1619 - val_lambda_776_loss: 0.1341\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1159 - lambda_771_loss: 0.1336 - lambda_776_loss: 0.1159 - val_loss: 0.1273 - val_lambda_771_loss: 0.1465 - val_lambda_776_loss: 0.1273\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1098 - lambda_771_loss: 0.1282 - lambda_776_loss: 0.1098 - val_loss: 0.1062 - val_lambda_771_loss: 0.1187 - val_lambda_776_loss: 0.1062\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1049 - lambda_771_loss: 0.1223 - lambda_776_loss: 0.1049 - val_loss: 0.1040 - val_lambda_771_loss: 0.1219 - val_lambda_776_loss: 0.1040\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1006 - lambda_771_loss: 0.1176 - lambda_776_loss: 0.1006 - val_loss: 0.1071 - val_lambda_771_loss: 0.1326 - val_lambda_776_loss: 0.1071\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0982 - lambda_771_loss: 0.1146 - lambda_776_loss: 0.0982 - val_loss: 0.1100 - val_lambda_771_loss: 0.1283 - val_lambda_776_loss: 0.1100\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0966 - lambda_771_loss: 0.1131 - lambda_776_loss: 0.0966 - val_loss: 0.1011 - val_lambda_771_loss: 0.1236 - val_lambda_776_loss: 0.1011\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0957 - lambda_771_loss: 0.1120 - lambda_776_loss: 0.0957 - val_loss: 0.1018 - val_lambda_771_loss: 0.1160 - val_lambda_776_loss: 0.1018\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0924 - lambda_771_loss: 0.1083 - lambda_776_loss: 0.0924 - val_loss: 0.1161 - val_lambda_771_loss: 0.1389 - val_lambda_776_loss: 0.1161\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0942 - lambda_771_loss: 0.1104 - lambda_776_loss: 0.0942 - val_loss: 0.0982 - val_lambda_771_loss: 0.1159 - val_lambda_776_loss: 0.0982\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0903 - lambda_771_loss: 0.1057 - lambda_776_loss: 0.0903 - val_loss: 0.0962 - val_lambda_771_loss: 0.1124 - val_lambda_776_loss: 0.0962\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0901 - lambda_771_loss: 0.1056 - lambda_776_loss: 0.0901 - val_loss: 0.1031 - val_lambda_771_loss: 0.1209 - val_lambda_776_loss: 0.1031\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0891 - lambda_771_loss: 0.1044 - lambda_776_loss: 0.0891 - val_loss: 0.1080 - val_lambda_771_loss: 0.1247 - val_lambda_776_loss: 0.1080\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0883 - lambda_771_loss: 0.1038 - lambda_776_loss: 0.0883 - val_loss: 0.1020 - val_lambda_771_loss: 0.1210 - val_lambda_776_loss: 0.1020\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0872 - lambda_771_loss: 0.1023 - lambda_776_loss: 0.0872 - val_loss: 0.0924 - val_lambda_771_loss: 0.1076 - val_lambda_776_loss: 0.0924\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0869 - lambda_771_loss: 0.1023 - lambda_776_loss: 0.0869 - val_loss: 0.1017 - val_lambda_771_loss: 0.1188 - val_lambda_776_loss: 0.1017\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0862 - lambda_771_loss: 0.1015 - lambda_776_loss: 0.0862 - val_loss: 0.0946 - val_lambda_771_loss: 0.1129 - val_lambda_776_loss: 0.0946\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0865 - lambda_771_loss: 0.1020 - lambda_776_loss: 0.0865 - val_loss: 0.0949 - val_lambda_771_loss: 0.1127 - val_lambda_776_loss: 0.0949\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0842 - lambda_771_loss: 0.0991 - lambda_776_loss: 0.0842 - val_loss: 0.0972 - val_lambda_771_loss: 0.1099 - val_lambda_776_loss: 0.0972\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0839 - lambda_771_loss: 0.0985 - lambda_776_loss: 0.0839 - val_loss: 0.0920 - val_lambda_771_loss: 0.1065 - val_lambda_776_loss: 0.0920\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0838 - lambda_771_loss: 0.0986 - lambda_776_loss: 0.0838 - val_loss: 0.0900 - val_lambda_771_loss: 0.1053 - val_lambda_776_loss: 0.0900\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0835 - lambda_771_loss: 0.0982 - lambda_776_loss: 0.0835 - val_loss: 0.0896 - val_lambda_771_loss: 0.1074 - val_lambda_776_loss: 0.0896\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0827 - lambda_771_loss: 0.0976 - lambda_776_loss: 0.0827 - val_loss: 0.0942 - val_lambda_771_loss: 0.1081 - val_lambda_776_loss: 0.0942\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0847 - lambda_771_loss: 0.0999 - lambda_776_loss: 0.0847 - val_loss: 0.0892 - val_lambda_771_loss: 0.1021 - val_lambda_776_loss: 0.0892\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0823 - lambda_771_loss: 0.0969 - lambda_776_loss: 0.0823 - val_loss: 0.0939 - val_lambda_771_loss: 0.1143 - val_lambda_776_loss: 0.0939\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0829 - lambda_771_loss: 0.0977 - lambda_776_loss: 0.0829 - val_loss: 0.0919 - val_lambda_771_loss: 0.1146 - val_lambda_776_loss: 0.0919\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0817 - lambda_771_loss: 0.0964 - lambda_776_loss: 0.0817 - val_loss: 0.0907 - val_lambda_771_loss: 0.1100 - val_lambda_776_loss: 0.0907\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0814 - lambda_771_loss: 0.0958 - lambda_776_loss: 0.0814 - val_loss: 0.0878 - val_lambda_771_loss: 0.0994 - val_lambda_776_loss: 0.0878\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0810 - lambda_771_loss: 0.0956 - lambda_776_loss: 0.0810 - val_loss: 0.0939 - val_lambda_771_loss: 0.1106 - val_lambda_776_loss: 0.0939\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0826 - lambda_771_loss: 0.0975 - lambda_776_loss: 0.0826 - val_loss: 0.0932 - val_lambda_771_loss: 0.1068 - val_lambda_776_loss: 0.0932\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0813 - lambda_771_loss: 0.0958 - lambda_776_loss: 0.0813 - val_loss: 0.0901 - val_lambda_771_loss: 0.1066 - val_lambda_776_loss: 0.0901\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0798 - lambda_771_loss: 0.0940 - lambda_776_loss: 0.0798 - val_loss: 0.0997 - val_lambda_771_loss: 0.1208 - val_lambda_776_loss: 0.0997\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0793 - lambda_771_loss: 0.0935 - lambda_776_loss: 0.0793 - val_loss: 0.0864 - val_lambda_771_loss: 0.1014 - val_lambda_776_loss: 0.0864\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0800 - lambda_771_loss: 0.0944 - lambda_776_loss: 0.0800 - val_loss: 0.0974 - val_lambda_771_loss: 0.1162 - val_lambda_776_loss: 0.0974\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0793 - lambda_771_loss: 0.0937 - lambda_776_loss: 0.0793 - val_loss: 0.0890 - val_lambda_771_loss: 0.1059 - val_lambda_776_loss: 0.0890\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0780 - lambda_771_loss: 0.0921 - lambda_776_loss: 0.0780 - val_loss: 0.0872 - val_lambda_771_loss: 0.1040 - val_lambda_776_loss: 0.0872\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0796 - lambda_771_loss: 0.0938 - lambda_776_loss: 0.0796 - val_loss: 0.0903 - val_lambda_771_loss: 0.1040 - val_lambda_776_loss: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0786 - lambda_771_loss: 0.0926 - lambda_776_loss: 0.0786 - val_loss: 0.0874 - val_lambda_771_loss: 0.1021 - val_lambda_776_loss: 0.0874\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0781 - lambda_771_loss: 0.0920 - lambda_776_loss: 0.0781 - val_loss: 0.0846 - val_lambda_771_loss: 0.0986 - val_lambda_776_loss: 0.0846\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0789 - lambda_771_loss: 0.0932 - lambda_776_loss: 0.0789 - val_loss: 0.0863 - val_lambda_771_loss: 0.1016 - val_lambda_776_loss: 0.0863\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0775 - lambda_771_loss: 0.0915 - lambda_776_loss: 0.0775 - val_loss: 0.0954 - val_lambda_771_loss: 0.1090 - val_lambda_776_loss: 0.0954\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0780 - lambda_771_loss: 0.0919 - lambda_776_loss: 0.0780 - val_loss: 0.0887 - val_lambda_771_loss: 0.1053 - val_lambda_776_loss: 0.0887\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0774 - lambda_771_loss: 0.0912 - lambda_776_loss: 0.0774 - val_loss: 0.0906 - val_lambda_771_loss: 0.1032 - val_lambda_776_loss: 0.0906\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0777 - lambda_771_loss: 0.0915 - lambda_776_loss: 0.0777 - val_loss: 0.0969 - val_lambda_771_loss: 0.1110 - val_lambda_776_loss: 0.0969\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0775 - lambda_771_loss: 0.0912 - lambda_776_loss: 0.0775 - val_loss: 0.0933 - val_lambda_771_loss: 0.1087 - val_lambda_776_loss: 0.0933\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0755 - lambda_771_loss: 0.0890 - lambda_776_loss: 0.0755 - val_loss: 0.0878 - val_lambda_771_loss: 0.0993 - val_lambda_776_loss: 0.0878\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0772 - lambda_771_loss: 0.0911 - lambda_776_loss: 0.0772 - val_loss: 0.0878 - val_lambda_771_loss: 0.1034 - val_lambda_776_loss: 0.0878\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0765 - lambda_771_loss: 0.0904 - lambda_776_loss: 0.0765 - val_loss: 0.0978 - val_lambda_771_loss: 0.1122 - val_lambda_776_loss: 0.0978\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0766 - lambda_771_loss: 0.0905 - lambda_776_loss: 0.0766 - val_loss: 0.0880 - val_lambda_771_loss: 0.1057 - val_lambda_776_loss: 0.0880\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_781 (Lambda)             (None, 256, 256, 2)  0           input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 256, 256, 48) 912         lambda_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 256, 256, 2)  98          conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_189 (Add)                   (None, 256, 256, 2)  0           conv2d_570[0][0]                 \n",
      "                                                                 lambda_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_786 (Lambda)             (None, 256, 256, 2)  0           add_189[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_95 (Multiply)          (None, 256, 256, 2)  0           lambda_786[0][0]                 \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_190 (Add)                   (None, 256, 256, 2)  0           multiply_95[0][0]                \n",
      "                                                                 input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_791 (Lambda)             (None, 256, 256, 2)  0           add_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 256, 256, 48) 912         lambda_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 256, 256, 2)  98          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_191 (Add)                   (None, 256, 256, 2)  0           conv2d_576[0][0]                 \n",
      "                                                                 lambda_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_796 (Lambda)             (None, 256, 256, 2)  0           add_191[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_96 (Multiply)          (None, 256, 256, 2)  0           lambda_796[0][0]                 \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_192 (Add)                   (None, 256, 256, 2)  0           multiply_96[0][0]                \n",
      "                                                                 input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_801 (Lambda)             (None, 256, 256, 2)  0           add_192[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 256, 256, 48) 912         lambda_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 256, 256, 2)  98          conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_193 (Add)                   (None, 256, 256, 2)  0           conv2d_582[0][0]                 \n",
      "                                                                 lambda_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_806 (Lambda)             (None, 256, 256, 2)  0           add_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_97 (Multiply)          (None, 256, 256, 2)  0           lambda_806[0][0]                 \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_194 (Add)                   (None, 256, 256, 2)  0           multiply_97[0][0]                \n",
      "                                                                 input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 256, 256, 48) 912         add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 256, 256, 2)  98          conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_195 (Add)                   (None, 256, 256, 2)  0           conv2d_588[0][0]                 \n",
      "                                                                 add_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_98 (Multiply)          (None, 256, 256, 2)  0           add_195[0][0]                    \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_196 (Add)                   (None, 256, 256, 2)  0           multiply_98[0][0]                \n",
      "                                                                 input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_811 (Lambda)             (None, 256, 256, 2)  0           add_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_816 (Lambda)             (None, 256, 256, 1)  0           lambda_811[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iiik_gaussian_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 117s 176ms/step - loss: 0.1957 - lambda_811_loss: 0.2329 - lambda_816_loss: 0.1957 - val_loss: 0.1554 - val_lambda_811_loss: 0.2058 - val_lambda_816_loss: 0.1554\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1412 - lambda_811_loss: 0.1689 - lambda_816_loss: 0.1412 - val_loss: 0.1349 - val_lambda_811_loss: 0.1637 - val_lambda_816_loss: 0.1349\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1241 - lambda_811_loss: 0.1481 - lambda_816_loss: 0.1241 - val_loss: 0.1205 - val_lambda_811_loss: 0.1398 - val_lambda_816_loss: 0.1205\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1161 - lambda_811_loss: 0.1380 - lambda_816_loss: 0.1161 - val_loss: 0.1373 - val_lambda_811_loss: 0.1536 - val_lambda_816_loss: 0.1373\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1098 - lambda_811_loss: 0.1293 - lambda_816_loss: 0.1098 - val_loss: 0.1103 - val_lambda_811_loss: 0.1274 - val_lambda_816_loss: 0.1103\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1087 - lambda_811_loss: 0.1289 - lambda_816_loss: 0.1087 - val_loss: 0.1123 - val_lambda_811_loss: 0.1293 - val_lambda_816_loss: 0.1123\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1057 - lambda_811_loss: 0.1240 - lambda_816_loss: 0.1057 - val_loss: 0.1112 - val_lambda_811_loss: 0.1287 - val_lambda_816_loss: 0.1112\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1017 - lambda_811_loss: 0.1191 - lambda_816_loss: 0.1017 - val_loss: 0.1111 - val_lambda_811_loss: 0.1311 - val_lambda_816_loss: 0.1111\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1007 - lambda_811_loss: 0.1183 - lambda_816_loss: 0.1007 - val_loss: 0.1119 - val_lambda_811_loss: 0.1310 - val_lambda_816_loss: 0.1119\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1020 - lambda_811_loss: 0.1210 - lambda_816_loss: 0.1020 - val_loss: 0.1039 - val_lambda_811_loss: 0.1233 - val_lambda_816_loss: 0.1039\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0983 - lambda_811_loss: 0.1154 - lambda_816_loss: 0.0983 - val_loss: 0.1158 - val_lambda_811_loss: 0.1481 - val_lambda_816_loss: 0.1158\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0984 - lambda_811_loss: 0.1154 - lambda_816_loss: 0.0984 - val_loss: 0.1363 - val_lambda_811_loss: 0.1494 - val_lambda_816_loss: 0.1363\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0952 - lambda_811_loss: 0.1108 - lambda_816_loss: 0.0952 - val_loss: 0.1015 - val_lambda_811_loss: 0.1161 - val_lambda_816_loss: 0.1015\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0944 - lambda_811_loss: 0.1099 - lambda_816_loss: 0.0944 - val_loss: 0.1085 - val_lambda_811_loss: 0.1238 - val_lambda_816_loss: 0.1085\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0942 - lambda_811_loss: 0.1099 - lambda_816_loss: 0.0942 - val_loss: 0.0975 - val_lambda_811_loss: 0.1102 - val_lambda_816_loss: 0.0975\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0935 - lambda_811_loss: 0.1088 - lambda_816_loss: 0.0935 - val_loss: 0.1019 - val_lambda_811_loss: 0.1161 - val_lambda_816_loss: 0.1019\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0927 - lambda_811_loss: 0.1078 - lambda_816_loss: 0.0927 - val_loss: 0.0967 - val_lambda_811_loss: 0.1091 - val_lambda_816_loss: 0.0967\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0914 - lambda_811_loss: 0.1058 - lambda_816_loss: 0.0914 - val_loss: 0.1055 - val_lambda_811_loss: 0.1228 - val_lambda_816_loss: 0.1055\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0917 - lambda_811_loss: 0.1061 - lambda_816_loss: 0.0917 - val_loss: 0.1050 - val_lambda_811_loss: 0.1168 - val_lambda_816_loss: 0.1050\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0903 - lambda_811_loss: 0.1048 - lambda_816_loss: 0.0903 - val_loss: 0.1018 - val_lambda_811_loss: 0.1152 - val_lambda_816_loss: 0.1018\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0899 - lambda_811_loss: 0.1042 - lambda_816_loss: 0.0899 - val_loss: 0.0996 - val_lambda_811_loss: 0.1137 - val_lambda_816_loss: 0.0996\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0889 - lambda_811_loss: 0.1030 - lambda_816_loss: 0.0889 - val_loss: 0.1061 - val_lambda_811_loss: 0.1192 - val_lambda_816_loss: 0.1061\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0889 - lambda_811_loss: 0.1026 - lambda_816_loss: 0.0889 - val_loss: 0.1108 - val_lambda_811_loss: 0.1243 - val_lambda_816_loss: 0.1108\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0872 - lambda_811_loss: 0.1008 - lambda_816_loss: 0.0872 - val_loss: 0.0978 - val_lambda_811_loss: 0.1110 - val_lambda_816_loss: 0.0978\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0879 - lambda_811_loss: 0.1016 - lambda_816_loss: 0.0879 - val_loss: 0.1121 - val_lambda_811_loss: 0.1254 - val_lambda_816_loss: 0.1121\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0861 - lambda_811_loss: 0.0992 - lambda_816_loss: 0.0861 - val_loss: 0.0923 - val_lambda_811_loss: 0.1082 - val_lambda_816_loss: 0.0923\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0867 - lambda_811_loss: 0.1002 - lambda_816_loss: 0.0867 - val_loss: 0.0976 - val_lambda_811_loss: 0.1120 - val_lambda_816_loss: 0.0976\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0861 - lambda_811_loss: 0.0992 - lambda_816_loss: 0.0861 - val_loss: 0.1022 - val_lambda_811_loss: 0.1167 - val_lambda_816_loss: 0.1022\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0852 - lambda_811_loss: 0.0987 - lambda_816_loss: 0.0852 - val_loss: 0.1014 - val_lambda_811_loss: 0.1121 - val_lambda_816_loss: 0.1014\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0855 - lambda_811_loss: 0.0984 - lambda_816_loss: 0.0855 - val_loss: 0.0903 - val_lambda_811_loss: 0.1029 - val_lambda_816_loss: 0.0903\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0853 - lambda_811_loss: 0.0986 - lambda_816_loss: 0.0853 - val_loss: 0.0922 - val_lambda_811_loss: 0.1044 - val_lambda_816_loss: 0.0922\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0845 - lambda_811_loss: 0.0977 - lambda_816_loss: 0.0845 - val_loss: 0.0962 - val_lambda_811_loss: 0.1116 - val_lambda_816_loss: 0.0962\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0844 - lambda_811_loss: 0.0973 - lambda_816_loss: 0.0844 - val_loss: 0.0968 - val_lambda_811_loss: 0.1090 - val_lambda_816_loss: 0.0968\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0840 - lambda_811_loss: 0.0967 - lambda_816_loss: 0.0840 - val_loss: 0.0908 - val_lambda_811_loss: 0.1038 - val_lambda_816_loss: 0.0908\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0838 - lambda_811_loss: 0.0967 - lambda_816_loss: 0.0838 - val_loss: 0.0983 - val_lambda_811_loss: 0.1127 - val_lambda_816_loss: 0.0983\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0839 - lambda_811_loss: 0.0967 - lambda_816_loss: 0.0839 - val_loss: 0.0916 - val_lambda_811_loss: 0.1057 - val_lambda_816_loss: 0.0916\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0838 - lambda_811_loss: 0.0967 - lambda_816_loss: 0.0838 - val_loss: 0.0944 - val_lambda_811_loss: 0.1099 - val_lambda_816_loss: 0.0944\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0872 - lambda_811_loss: 0.1022 - lambda_816_loss: 0.0872 - val_loss: 0.0997 - val_lambda_811_loss: 0.1115 - val_lambda_816_loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0841 - lambda_811_loss: 0.0966 - lambda_816_loss: 0.0841 - val_loss: 0.0904 - val_lambda_811_loss: 0.1033 - val_lambda_816_loss: 0.0904\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0820 - lambda_811_loss: 0.0943 - lambda_816_loss: 0.0820 - val_loss: 0.0928 - val_lambda_811_loss: 0.1066 - val_lambda_816_loss: 0.0928\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0823 - lambda_811_loss: 0.0945 - lambda_816_loss: 0.0823 - val_loss: 0.0905 - val_lambda_811_loss: 0.1018 - val_lambda_816_loss: 0.0905\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0828 - lambda_811_loss: 0.0953 - lambda_816_loss: 0.0828 - val_loss: 0.0919 - val_lambda_811_loss: 0.1052 - val_lambda_816_loss: 0.0919\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 106s 159ms/step - loss: 0.0829 - lambda_811_loss: 0.0954 - lambda_816_loss: 0.0829 - val_loss: 0.0971 - val_lambda_811_loss: 0.1111 - val_lambda_816_loss: 0.0971\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0819 - lambda_811_loss: 0.0942 - lambda_816_loss: 0.0819 - val_loss: 0.0932 - val_lambda_811_loss: 0.1100 - val_lambda_816_loss: 0.0932\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0814 - lambda_811_loss: 0.0935 - lambda_816_loss: 0.0814 - val_loss: 0.0939 - val_lambda_811_loss: 0.1057 - val_lambda_816_loss: 0.0939\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0809 - lambda_811_loss: 0.0926 - lambda_816_loss: 0.0809 - val_loss: 0.0919 - val_lambda_811_loss: 0.1063 - val_lambda_816_loss: 0.0919\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0816 - lambda_811_loss: 0.0943 - lambda_816_loss: 0.0816 - val_loss: 0.0925 - val_lambda_811_loss: 0.1061 - val_lambda_816_loss: 0.0925\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0810 - lambda_811_loss: 0.0935 - lambda_816_loss: 0.0810 - val_loss: 0.0921 - val_lambda_811_loss: 0.1039 - val_lambda_816_loss: 0.0921\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0802 - lambda_811_loss: 0.0923 - lambda_816_loss: 0.0802 - val_loss: 0.1005 - val_lambda_811_loss: 0.1140 - val_lambda_816_loss: 0.1005\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.0814 - lambda_811_loss: 0.0937 - lambda_816_loss: 0.0814 - val_loss: 0.0899 - val_lambda_811_loss: 0.1048 - val_lambda_816_loss: 0.0899\n",
      "Undersampling: 0.75\n",
      "Mask type: bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 256, 256, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_821 (Lambda)             (None, 256, 256, 2)  0           input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 256, 256, 48) 912         lambda_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 256, 256, 2)  98          conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_197 (Add)                   (None, 256, 256, 2)  0           conv2d_594[0][0]                 \n",
      "                                                                 lambda_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_826 (Lambda)             (None, 256, 256, 2)  0           add_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_99 (Multiply)          (None, 256, 256, 2)  0           lambda_826[0][0]                 \n",
      "                                                                 input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_198 (Add)                   (None, 256, 256, 2)  0           multiply_99[0][0]                \n",
      "                                                                 input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_831 (Lambda)             (None, 256, 256, 2)  0           add_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 256, 256, 48) 912         lambda_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 256, 256, 2)  98          conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_199 (Add)                   (None, 256, 256, 2)  0           conv2d_600[0][0]                 \n",
      "                                                                 lambda_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_836 (Lambda)             (None, 256, 256, 2)  0           add_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_100 (Multiply)         (None, 256, 256, 2)  0           lambda_836[0][0]                 \n",
      "                                                                 input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_200 (Add)                   (None, 256, 256, 2)  0           multiply_100[0][0]               \n",
      "                                                                 input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_841 (Lambda)             (None, 256, 256, 2)  0           add_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 256, 256, 48) 912         lambda_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 256, 256, 2)  98          conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_201 (Add)                   (None, 256, 256, 2)  0           conv2d_606[0][0]                 \n",
      "                                                                 lambda_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_846 (Lambda)             (None, 256, 256, 2)  0           add_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_101 (Multiply)         (None, 256, 256, 2)  0           lambda_846[0][0]                 \n",
      "                                                                 input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_202 (Add)                   (None, 256, 256, 2)  0           multiply_101[0][0]               \n",
      "                                                                 input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_851 (Lambda)             (None, 256, 256, 2)  0           add_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 256, 256, 48) 912         lambda_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 256, 256, 2)  98          conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_203 (Add)                   (None, 256, 256, 2)  0           conv2d_612[0][0]                 \n",
      "                                                                 lambda_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_856 (Lambda)             (None, 256, 256, 2)  0           add_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_102 (Multiply)         (None, 256, 256, 2)  0           lambda_856[0][0]                 \n",
      "                                                                 input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_204 (Add)                   (None, 256, 256, 2)  0           multiply_102[0][0]               \n",
      "                                                                 input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_861 (Lambda)             (None, 256, 256, 2)  0           add_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_866 (Lambda)             (None, 256, 256, 1)  0           lambda_861[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iiii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 119s 179ms/step - loss: 0.1761 - lambda_861_loss: 0.1992 - lambda_866_loss: 0.1761 - val_loss: 0.1149 - val_lambda_861_loss: 0.1409 - val_lambda_866_loss: 0.1149\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1146 - lambda_861_loss: 0.1364 - lambda_866_loss: 0.1146 - val_loss: 0.1274 - val_lambda_861_loss: 0.1394 - val_lambda_866_loss: 0.1274\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 108s 161ms/step - loss: 0.1059 - lambda_861_loss: 0.1296 - lambda_866_loss: 0.1059 - val_loss: 0.0900 - val_lambda_861_loss: 0.1041 - val_lambda_866_loss: 0.0900\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 108s 161ms/step - loss: 0.0824 - lambda_861_loss: 0.0956 - lambda_866_loss: 0.0824 - val_loss: 0.0841 - val_lambda_861_loss: 0.0944 - val_lambda_866_loss: 0.0841\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0780 - lambda_861_loss: 0.0909 - lambda_866_loss: 0.0780 - val_loss: 0.0793 - val_lambda_861_loss: 0.0946 - val_lambda_866_loss: 0.0793\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0773 - lambda_861_loss: 0.0919 - lambda_866_loss: 0.0773 - val_loss: 0.0800 - val_lambda_861_loss: 0.0925 - val_lambda_866_loss: 0.0800\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 108s 161ms/step - loss: 0.0742 - lambda_861_loss: 0.0866 - lambda_866_loss: 0.0742 - val_loss: 0.0782 - val_lambda_861_loss: 0.0959 - val_lambda_866_loss: 0.0782\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0703 - lambda_861_loss: 0.0824 - lambda_866_loss: 0.0703 - val_loss: 0.0765 - val_lambda_861_loss: 0.0935 - val_lambda_866_loss: 0.0765\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0695 - lambda_861_loss: 0.0813 - lambda_866_loss: 0.0695 - val_loss: 0.0758 - val_lambda_861_loss: 0.0835 - val_lambda_866_loss: 0.0758\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0686 - lambda_861_loss: 0.0798 - lambda_866_loss: 0.0686 - val_loss: 0.0720 - val_lambda_861_loss: 0.0859 - val_lambda_866_loss: 0.0720\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0651 - lambda_861_loss: 0.0755 - lambda_866_loss: 0.0651 - val_loss: 0.0696 - val_lambda_861_loss: 0.0789 - val_lambda_866_loss: 0.0696\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0677 - lambda_861_loss: 0.0793 - lambda_866_loss: 0.0677 - val_loss: 0.0812 - val_lambda_861_loss: 0.1139 - val_lambda_866_loss: 0.0812\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0662 - lambda_861_loss: 0.0770 - lambda_866_loss: 0.0662 - val_loss: 0.0700 - val_lambda_861_loss: 0.0791 - val_lambda_866_loss: 0.0700\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0619 - lambda_861_loss: 0.0709 - lambda_866_loss: 0.0619 - val_loss: 0.0676 - val_lambda_861_loss: 0.0763 - val_lambda_866_loss: 0.0676\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0620 - lambda_861_loss: 0.0714 - lambda_866_loss: 0.0620 - val_loss: 0.0735 - val_lambda_861_loss: 0.0824 - val_lambda_866_loss: 0.0735\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0611 - lambda_861_loss: 0.0703 - lambda_866_loss: 0.0611 - val_loss: 0.0677 - val_lambda_861_loss: 0.0798 - val_lambda_866_loss: 0.0677\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0612 - lambda_861_loss: 0.0704 - lambda_866_loss: 0.0612 - val_loss: 0.0687 - val_lambda_861_loss: 0.0821 - val_lambda_866_loss: 0.0687\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0589 - lambda_861_loss: 0.0672 - lambda_866_loss: 0.0589 - val_loss: 0.0654 - val_lambda_861_loss: 0.0721 - val_lambda_866_loss: 0.0654\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.0580 - lambda_861_loss: 0.0659 - lambda_866_loss: 0.0580 - val_loss: 0.0674 - val_lambda_861_loss: 0.0753 - val_lambda_866_loss: 0.0674\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 108s 161ms/step - loss: 0.0591 - lambda_861_loss: 0.0674 - lambda_866_loss: 0.0591 - val_loss: 0.0661 - val_lambda_861_loss: 0.0730 - val_lambda_866_loss: 0.0661\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0578 - lambda_861_loss: 0.0659 - lambda_866_loss: 0.0578 - val_loss: 0.0680 - val_lambda_861_loss: 0.0746 - val_lambda_866_loss: 0.0680\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0560 - lambda_861_loss: 0.0635 - lambda_866_loss: 0.0560 - val_loss: 0.0629 - val_lambda_861_loss: 0.0707 - val_lambda_866_loss: 0.0629\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0586 - lambda_861_loss: 0.0672 - lambda_866_loss: 0.0586 - val_loss: 0.0658 - val_lambda_861_loss: 0.0741 - val_lambda_866_loss: 0.0658\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0566 - lambda_861_loss: 0.0644 - lambda_866_loss: 0.0566 - val_loss: 0.0656 - val_lambda_861_loss: 0.0722 - val_lambda_866_loss: 0.0656\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0560 - lambda_861_loss: 0.0636 - lambda_866_loss: 0.0560 - val_loss: 0.0663 - val_lambda_861_loss: 0.0754 - val_lambda_866_loss: 0.0663\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0552 - lambda_861_loss: 0.0629 - lambda_866_loss: 0.0552 - val_loss: 0.0687 - val_lambda_861_loss: 0.0774 - val_lambda_866_loss: 0.0687\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0543 - lambda_861_loss: 0.0614 - lambda_866_loss: 0.0543 - val_loss: 0.0630 - val_lambda_861_loss: 0.0697 - val_lambda_866_loss: 0.0630\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0549 - lambda_861_loss: 0.0624 - lambda_866_loss: 0.0549 - val_loss: 0.0642 - val_lambda_861_loss: 0.0736 - val_lambda_866_loss: 0.0642\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0550 - lambda_861_loss: 0.0621 - lambda_866_loss: 0.0550 - val_loss: 0.0631 - val_lambda_861_loss: 0.0700 - val_lambda_866_loss: 0.0631\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0536 - lambda_861_loss: 0.0606 - lambda_866_loss: 0.0536 - val_loss: 0.0651 - val_lambda_861_loss: 0.0749 - val_lambda_866_loss: 0.0651\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0534 - lambda_861_loss: 0.0603 - lambda_866_loss: 0.0534 - val_loss: 0.0644 - val_lambda_861_loss: 0.0757 - val_lambda_866_loss: 0.0644\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0536 - lambda_861_loss: 0.0605 - lambda_866_loss: 0.0536 - val_loss: 0.0648 - val_lambda_861_loss: 0.0728 - val_lambda_866_loss: 0.0648\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0536 - lambda_861_loss: 0.0606 - lambda_866_loss: 0.0536 - val_loss: 0.0723 - val_lambda_861_loss: 0.0805 - val_lambda_866_loss: 0.0723\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0528 - lambda_861_loss: 0.0594 - lambda_866_loss: 0.0528 - val_loss: 0.0870 - val_lambda_861_loss: 0.0969 - val_lambda_866_loss: 0.0870\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0531 - lambda_861_loss: 0.0600 - lambda_866_loss: 0.0531 - val_loss: 0.0620 - val_lambda_861_loss: 0.0684 - val_lambda_866_loss: 0.0620\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0533 - lambda_861_loss: 0.0605 - lambda_866_loss: 0.0533 - val_loss: 0.0645 - val_lambda_861_loss: 0.0714 - val_lambda_866_loss: 0.0645\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0531 - lambda_861_loss: 0.0596 - lambda_866_loss: 0.0531 - val_loss: 0.0647 - val_lambda_861_loss: 0.0718 - val_lambda_866_loss: 0.0647\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0520 - lambda_861_loss: 0.0584 - lambda_866_loss: 0.0520 - val_loss: 0.0608 - val_lambda_861_loss: 0.0675 - val_lambda_866_loss: 0.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0521 - lambda_861_loss: 0.0588 - lambda_866_loss: 0.0521 - val_loss: 0.0633 - val_lambda_861_loss: 0.0710 - val_lambda_866_loss: 0.0633\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0527 - lambda_861_loss: 0.0594 - lambda_866_loss: 0.0527 - val_loss: 0.0601 - val_lambda_861_loss: 0.0660 - val_lambda_866_loss: 0.0601\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0515 - lambda_861_loss: 0.0578 - lambda_866_loss: 0.0515 - val_loss: 0.0638 - val_lambda_861_loss: 0.0703 - val_lambda_866_loss: 0.0638\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0532 - lambda_861_loss: 0.0599 - lambda_866_loss: 0.0532 - val_loss: 0.0630 - val_lambda_861_loss: 0.0699 - val_lambda_866_loss: 0.0630\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0523 - lambda_861_loss: 0.0587 - lambda_866_loss: 0.0523 - val_loss: 0.0654 - val_lambda_861_loss: 0.0744 - val_lambda_866_loss: 0.0654\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0508 - lambda_861_loss: 0.0571 - lambda_866_loss: 0.0508 - val_loss: 0.0627 - val_lambda_861_loss: 0.0698 - val_lambda_866_loss: 0.0627\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0518 - lambda_861_loss: 0.0582 - lambda_866_loss: 0.0518 - val_loss: 0.0617 - val_lambda_861_loss: 0.0681 - val_lambda_866_loss: 0.0617\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0517 - lambda_861_loss: 0.0584 - lambda_866_loss: 0.0517 - val_loss: 0.0624 - val_lambda_861_loss: 0.0687 - val_lambda_866_loss: 0.0624\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0511 - lambda_861_loss: 0.0572 - lambda_866_loss: 0.0511 - val_loss: 0.0610 - val_lambda_861_loss: 0.0671 - val_lambda_866_loss: 0.0610\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0508 - lambda_861_loss: 0.0571 - lambda_866_loss: 0.0508 - val_loss: 0.0606 - val_lambda_861_loss: 0.0667 - val_lambda_866_loss: 0.0606\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0510 - lambda_861_loss: 0.0572 - lambda_866_loss: 0.0510 - val_loss: 0.0631 - val_lambda_861_loss: 0.0705 - val_lambda_866_loss: 0.0631\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0505 - lambda_861_loss: 0.0565 - lambda_866_loss: 0.0505 - val_loss: 0.0685 - val_lambda_861_loss: 0.0750 - val_lambda_866_loss: 0.0685\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_871 (Lambda)             (None, 256, 256, 2)  0           input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 256, 256, 48) 912         lambda_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 256, 256, 2)  98          conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_205 (Add)                   (None, 256, 256, 2)  0           conv2d_618[0][0]                 \n",
      "                                                                 lambda_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_876 (Lambda)             (None, 256, 256, 2)  0           add_205[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_64 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_103 (Multiply)         (None, 256, 256, 2)  0           lambda_876[0][0]                 \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_206 (Add)                   (None, 256, 256, 2)  0           multiply_103[0][0]               \n",
      "                                                                 input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_881 (Lambda)             (None, 256, 256, 2)  0           add_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 256, 256, 48) 912         lambda_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 256, 256, 2)  98          conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_207 (Add)                   (None, 256, 256, 2)  0           conv2d_624[0][0]                 \n",
      "                                                                 lambda_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_886 (Lambda)             (None, 256, 256, 2)  0           add_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_104 (Multiply)         (None, 256, 256, 2)  0           lambda_886[0][0]                 \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_208 (Add)                   (None, 256, 256, 2)  0           multiply_104[0][0]               \n",
      "                                                                 input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_891 (Lambda)             (None, 256, 256, 2)  0           add_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 256, 256, 48) 912         lambda_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 256, 256, 2)  98          conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_209 (Add)                   (None, 256, 256, 2)  0           conv2d_630[0][0]                 \n",
      "                                                                 lambda_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_896 (Lambda)             (None, 256, 256, 2)  0           add_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_105 (Multiply)         (None, 256, 256, 2)  0           lambda_896[0][0]                 \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_210 (Add)                   (None, 256, 256, 2)  0           multiply_105[0][0]               \n",
      "                                                                 input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_901 (Lambda)             (None, 256, 256, 2)  0           add_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_906 (Lambda)             (None, 256, 256, 1)  0           lambda_901[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 95s 143ms/step - loss: 0.1814 - lambda_901_loss: 0.2016 - lambda_906_loss: 0.1814 - val_loss: 0.1268 - val_lambda_901_loss: 0.1526 - val_lambda_906_loss: 0.1268\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1189 - lambda_901_loss: 0.1376 - lambda_906_loss: 0.1189 - val_loss: 0.1054 - val_lambda_901_loss: 0.1255 - val_lambda_906_loss: 0.1054\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.1024 - lambda_901_loss: 0.1191 - lambda_906_loss: 0.1024 - val_loss: 0.1021 - val_lambda_901_loss: 0.1162 - val_lambda_906_loss: 0.1021\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0960 - lambda_901_loss: 0.1127 - lambda_906_loss: 0.0960 - val_loss: 0.0969 - val_lambda_901_loss: 0.1101 - val_lambda_906_loss: 0.0969\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0892 - lambda_901_loss: 0.1049 - lambda_906_loss: 0.0892 - val_loss: 0.0905 - val_lambda_901_loss: 0.1068 - val_lambda_906_loss: 0.0905\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0889 - lambda_901_loss: 0.1049 - lambda_906_loss: 0.0889 - val_loss: 0.0889 - val_lambda_901_loss: 0.1008 - val_lambda_906_loss: 0.0889\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0861 - lambda_901_loss: 0.1021 - lambda_906_loss: 0.0861 - val_loss: 0.0888 - val_lambda_901_loss: 0.1033 - val_lambda_906_loss: 0.0888\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0831 - lambda_901_loss: 0.0988 - lambda_906_loss: 0.0831 - val_loss: 0.0867 - val_lambda_901_loss: 0.1066 - val_lambda_906_loss: 0.0867\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0812 - lambda_901_loss: 0.0969 - lambda_906_loss: 0.0812 - val_loss: 0.0879 - val_lambda_901_loss: 0.1065 - val_lambda_906_loss: 0.0879\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0828 - lambda_901_loss: 0.0987 - lambda_906_loss: 0.0828 - val_loss: 0.0887 - val_lambda_901_loss: 0.1017 - val_lambda_906_loss: 0.0887\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0803 - lambda_901_loss: 0.0961 - lambda_906_loss: 0.0803 - val_loss: 0.0874 - val_lambda_901_loss: 0.1052 - val_lambda_906_loss: 0.0874\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0784 - lambda_901_loss: 0.0936 - lambda_906_loss: 0.0784 - val_loss: 0.0848 - val_lambda_901_loss: 0.1027 - val_lambda_906_loss: 0.0848\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0781 - lambda_901_loss: 0.0935 - lambda_906_loss: 0.0781 - val_loss: 0.0859 - val_lambda_901_loss: 0.1033 - val_lambda_906_loss: 0.0859\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0765 - lambda_901_loss: 0.0919 - lambda_906_loss: 0.0765 - val_loss: 0.0853 - val_lambda_901_loss: 0.1088 - val_lambda_906_loss: 0.0853\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0774 - lambda_901_loss: 0.0926 - lambda_906_loss: 0.0774 - val_loss: 0.0865 - val_lambda_901_loss: 0.1042 - val_lambda_906_loss: 0.0865\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0750 - lambda_901_loss: 0.0899 - lambda_906_loss: 0.0750 - val_loss: 0.0880 - val_lambda_901_loss: 0.0999 - val_lambda_906_loss: 0.0880\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0760 - lambda_901_loss: 0.0912 - lambda_906_loss: 0.0760 - val_loss: 0.0812 - val_lambda_901_loss: 0.1014 - val_lambda_906_loss: 0.0812\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0740 - lambda_901_loss: 0.0888 - lambda_906_loss: 0.0740 - val_loss: 0.0833 - val_lambda_901_loss: 0.0979 - val_lambda_906_loss: 0.0833\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0739 - lambda_901_loss: 0.0886 - lambda_906_loss: 0.0739 - val_loss: 0.0818 - val_lambda_901_loss: 0.0984 - val_lambda_906_loss: 0.0818\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0757 - lambda_901_loss: 0.0906 - lambda_906_loss: 0.0757 - val_loss: 0.0805 - val_lambda_901_loss: 0.0980 - val_lambda_906_loss: 0.0805\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 86s 128ms/step - loss: 0.0749 - lambda_901_loss: 0.0900 - lambda_906_loss: 0.0749 - val_loss: 0.0821 - val_lambda_901_loss: 0.0975 - val_lambda_906_loss: 0.0821\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0727 - lambda_901_loss: 0.0873 - lambda_906_loss: 0.0727 - val_loss: 0.0767 - val_lambda_901_loss: 0.0903 - val_lambda_906_loss: 0.0767\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0767 - lambda_901_loss: 0.0924 - lambda_906_loss: 0.0767 - val_loss: 0.0841 - val_lambda_901_loss: 0.0986 - val_lambda_906_loss: 0.0841\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0737 - lambda_901_loss: 0.0889 - lambda_906_loss: 0.0737 - val_loss: 0.0813 - val_lambda_901_loss: 0.1010 - val_lambda_906_loss: 0.0813\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0721 - lambda_901_loss: 0.0870 - lambda_906_loss: 0.0721 - val_loss: 0.0873 - val_lambda_901_loss: 0.1057 - val_lambda_906_loss: 0.0873\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0718 - lambda_901_loss: 0.0866 - lambda_906_loss: 0.0718 - val_loss: 0.0860 - val_lambda_901_loss: 0.1021 - val_lambda_906_loss: 0.0860\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0713 - lambda_901_loss: 0.0859 - lambda_906_loss: 0.0713 - val_loss: 0.0809 - val_lambda_901_loss: 0.0982 - val_lambda_906_loss: 0.0809\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0700 - lambda_901_loss: 0.0843 - lambda_906_loss: 0.0700 - val_loss: 0.0815 - val_lambda_901_loss: 0.0964 - val_lambda_906_loss: 0.0815\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0699 - lambda_901_loss: 0.0841 - lambda_906_loss: 0.0699 - val_loss: 0.0799 - val_lambda_901_loss: 0.0953 - val_lambda_906_loss: 0.0799\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0715 - lambda_901_loss: 0.0861 - lambda_906_loss: 0.0715 - val_loss: 0.0777 - val_lambda_901_loss: 0.0921 - val_lambda_906_loss: 0.0777\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0700 - lambda_901_loss: 0.0845 - lambda_906_loss: 0.0700 - val_loss: 0.0817 - val_lambda_901_loss: 0.0991 - val_lambda_906_loss: 0.0817\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0699 - lambda_901_loss: 0.0843 - lambda_906_loss: 0.0699 - val_loss: 0.0860 - val_lambda_901_loss: 0.1028 - val_lambda_906_loss: 0.0860\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0691 - lambda_901_loss: 0.0834 - lambda_906_loss: 0.0691 - val_loss: 0.0782 - val_lambda_901_loss: 0.0925 - val_lambda_906_loss: 0.0782\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0691 - lambda_901_loss: 0.0833 - lambda_906_loss: 0.0691 - val_loss: 0.0820 - val_lambda_901_loss: 0.0991 - val_lambda_906_loss: 0.0820\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0688 - lambda_901_loss: 0.0830 - lambda_906_loss: 0.0688 - val_loss: 0.0752 - val_lambda_901_loss: 0.0923 - val_lambda_906_loss: 0.0752\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0691 - lambda_901_loss: 0.0834 - lambda_906_loss: 0.0691 - val_loss: 0.0757 - val_lambda_901_loss: 0.0887 - val_lambda_906_loss: 0.0757\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0680 - lambda_901_loss: 0.0823 - lambda_906_loss: 0.0680 - val_loss: 0.0771 - val_lambda_901_loss: 0.0949 - val_lambda_906_loss: 0.0771\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0694 - lambda_901_loss: 0.0837 - lambda_906_loss: 0.0694 - val_loss: 0.0754 - val_lambda_901_loss: 0.0932 - val_lambda_906_loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0696 - lambda_901_loss: 0.0839 - lambda_906_loss: 0.0696 - val_loss: 0.0786 - val_lambda_901_loss: 0.0923 - val_lambda_906_loss: 0.0786\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0681 - lambda_901_loss: 0.0822 - lambda_906_loss: 0.0681 - val_loss: 0.0780 - val_lambda_901_loss: 0.0944 - val_lambda_906_loss: 0.0780\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0676 - lambda_901_loss: 0.0819 - lambda_906_loss: 0.0676 - val_loss: 0.0867 - val_lambda_901_loss: 0.1017 - val_lambda_906_loss: 0.0867\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0678 - lambda_901_loss: 0.0821 - lambda_906_loss: 0.0678 - val_loss: 0.0816 - val_lambda_901_loss: 0.0947 - val_lambda_906_loss: 0.0816\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0686 - lambda_901_loss: 0.0830 - lambda_906_loss: 0.0686 - val_loss: 0.0777 - val_lambda_901_loss: 0.0902 - val_lambda_906_loss: 0.0777\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0661 - lambda_901_loss: 0.0801 - lambda_906_loss: 0.0661 - val_loss: 0.0741 - val_lambda_901_loss: 0.0871 - val_lambda_906_loss: 0.0741\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0669 - lambda_901_loss: 0.0810 - lambda_906_loss: 0.0669 - val_loss: 0.0775 - val_lambda_901_loss: 0.0927 - val_lambda_906_loss: 0.0775\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0669 - lambda_901_loss: 0.0809 - lambda_906_loss: 0.0669 - val_loss: 0.0752 - val_lambda_901_loss: 0.0904 - val_lambda_906_loss: 0.0752\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0663 - lambda_901_loss: 0.0802 - lambda_906_loss: 0.0663 - val_loss: 0.0761 - val_lambda_901_loss: 0.0900 - val_lambda_906_loss: 0.0761\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0663 - lambda_901_loss: 0.0802 - lambda_906_loss: 0.0663 - val_loss: 0.0924 - val_lambda_901_loss: 0.1083 - val_lambda_906_loss: 0.0924\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0673 - lambda_901_loss: 0.0814 - lambda_906_loss: 0.0673 - val_loss: 0.0730 - val_lambda_901_loss: 0.0873 - val_lambda_906_loss: 0.0730\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0659 - lambda_901_loss: 0.0800 - lambda_906_loss: 0.0659 - val_loss: 0.0760 - val_lambda_901_loss: 0.0929 - val_lambda_906_loss: 0.0760\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 256, 256, 48) 912         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 256, 256, 2)  98          conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_211 (Add)                   (None, 256, 256, 2)  0           conv2d_636[0][0]                 \n",
      "                                                                 input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_106 (Multiply)         (None, 256, 256, 2)  0           add_211[0][0]                    \n",
      "                                                                 input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_212 (Add)                   (None, 256, 256, 2)  0           multiply_106[0][0]               \n",
      "                                                                 input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_911 (Lambda)             (None, 256, 256, 2)  0           add_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_916 (Lambda)             (None, 256, 256, 1)  0           lambda_911[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 84,146\n",
      "Trainable params: 84,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_k_gaussian_25.hdf5\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 72s 108ms/step - loss: 0.3681 - lambda_911_loss: 0.4416 - lambda_916_loss: 0.3681 - val_loss: 0.3323 - val_lambda_911_loss: 0.4012 - val_lambda_916_loss: 0.3323\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.3156 - lambda_911_loss: 0.3843 - lambda_916_loss: 0.3156 - val_loss: 0.2973 - val_lambda_911_loss: 0.3622 - val_lambda_916_loss: 0.2973\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2961 - lambda_911_loss: 0.3634 - lambda_916_loss: 0.2961 - val_loss: 0.2969 - val_lambda_911_loss: 0.3641 - val_lambda_916_loss: 0.2969\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2869 - lambda_911_loss: 0.3537 - lambda_916_loss: 0.2869 - val_loss: 0.2784 - val_lambda_911_loss: 0.3486 - val_lambda_916_loss: 0.2784\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2778 - lambda_911_loss: 0.3437 - lambda_916_loss: 0.2778 - val_loss: 0.2681 - val_lambda_911_loss: 0.3364 - val_lambda_916_loss: 0.2681\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2769 - lambda_911_loss: 0.3427 - lambda_916_loss: 0.2769 - val_loss: 0.2763 - val_lambda_911_loss: 0.3390 - val_lambda_916_loss: 0.2763\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2688 - lambda_911_loss: 0.3335 - lambda_916_loss: 0.2688 - val_loss: 0.2643 - val_lambda_911_loss: 0.3303 - val_lambda_916_loss: 0.2643\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2663 - lambda_911_loss: 0.3306 - lambda_916_loss: 0.2663 - val_loss: 0.2565 - val_lambda_911_loss: 0.3285 - val_lambda_916_loss: 0.2565\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2635 - lambda_911_loss: 0.3266 - lambda_916_loss: 0.2635 - val_loss: 0.2573 - val_lambda_911_loss: 0.3203 - val_lambda_916_loss: 0.2573\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2615 - lambda_911_loss: 0.3253 - lambda_916_loss: 0.2615 - val_loss: 0.2604 - val_lambda_911_loss: 0.3269 - val_lambda_916_loss: 0.2604\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2583 - lambda_911_loss: 0.3208 - lambda_916_loss: 0.2583 - val_loss: 0.2516 - val_lambda_911_loss: 0.3176 - val_lambda_916_loss: 0.2516\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2587 - lambda_911_loss: 0.3218 - lambda_916_loss: 0.2587 - val_loss: 0.2696 - val_lambda_911_loss: 0.3351 - val_lambda_916_loss: 0.2696\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2552 - lambda_911_loss: 0.3182 - lambda_916_loss: 0.2552 - val_loss: 0.2506 - val_lambda_911_loss: 0.3163 - val_lambda_916_loss: 0.2506\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2548 - lambda_911_loss: 0.3173 - lambda_916_loss: 0.2548 - val_loss: 0.2526 - val_lambda_911_loss: 0.3142 - val_lambda_916_loss: 0.2526\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2533 - lambda_911_loss: 0.3157 - lambda_916_loss: 0.2533 - val_loss: 0.2478 - val_lambda_911_loss: 0.3161 - val_lambda_916_loss: 0.2478\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2508 - lambda_911_loss: 0.3131 - lambda_916_loss: 0.2508 - val_loss: 0.2482 - val_lambda_911_loss: 0.3103 - val_lambda_916_loss: 0.2482\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2524 - lambda_911_loss: 0.3143 - lambda_916_loss: 0.2524 - val_loss: 0.2421 - val_lambda_911_loss: 0.3068 - val_lambda_916_loss: 0.2421\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2493 - lambda_911_loss: 0.3117 - lambda_916_loss: 0.2493 - val_loss: 0.2451 - val_lambda_911_loss: 0.3101 - val_lambda_916_loss: 0.2451\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2474 - lambda_911_loss: 0.3092 - lambda_916_loss: 0.2474 - val_loss: 0.2456 - val_lambda_911_loss: 0.3061 - val_lambda_916_loss: 0.2456\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2468 - lambda_911_loss: 0.3085 - lambda_916_loss: 0.2468 - val_loss: 0.2454 - val_lambda_911_loss: 0.3052 - val_lambda_916_loss: 0.2454\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2459 - lambda_911_loss: 0.3076 - lambda_916_loss: 0.2459 - val_loss: 0.2414 - val_lambda_911_loss: 0.3002 - val_lambda_916_loss: 0.2414\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2465 - lambda_911_loss: 0.3085 - lambda_916_loss: 0.2465 - val_loss: 0.2442 - val_lambda_911_loss: 0.3079 - val_lambda_916_loss: 0.2442\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2434 - lambda_911_loss: 0.3046 - lambda_916_loss: 0.2434 - val_loss: 0.2413 - val_lambda_911_loss: 0.3024 - val_lambda_916_loss: 0.2413\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2442 - lambda_911_loss: 0.3058 - lambda_916_loss: 0.2442 - val_loss: 0.2388 - val_lambda_911_loss: 0.3009 - val_lambda_916_loss: 0.2388\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2438 - lambda_911_loss: 0.3054 - lambda_916_loss: 0.2438 - val_loss: 0.2412 - val_lambda_911_loss: 0.2994 - val_lambda_916_loss: 0.2412\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2420 - lambda_911_loss: 0.3033 - lambda_916_loss: 0.2420 - val_loss: 0.2375 - val_lambda_911_loss: 0.2964 - val_lambda_916_loss: 0.2375\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2421 - lambda_911_loss: 0.3033 - lambda_916_loss: 0.2421 - val_loss: 0.2373 - val_lambda_911_loss: 0.2999 - val_lambda_916_loss: 0.2373\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 61s 92ms/step - loss: 0.2420 - lambda_911_loss: 0.3027 - lambda_916_loss: 0.2420 - val_loss: 0.2356 - val_lambda_911_loss: 0.2983 - val_lambda_916_loss: 0.2356\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2403 - lambda_911_loss: 0.3015 - lambda_916_loss: 0.2403 - val_loss: 0.2360 - val_lambda_911_loss: 0.2959 - val_lambda_916_loss: 0.2360\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2398 - lambda_911_loss: 0.3009 - lambda_916_loss: 0.2398 - val_loss: 0.2422 - val_lambda_911_loss: 0.3114 - val_lambda_916_loss: 0.2422\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2401 - lambda_911_loss: 0.3012 - lambda_916_loss: 0.2401 - val_loss: 0.2324 - val_lambda_911_loss: 0.2944 - val_lambda_916_loss: 0.2324\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2389 - lambda_911_loss: 0.3000 - lambda_916_loss: 0.2389 - val_loss: 0.2339 - val_lambda_911_loss: 0.2990 - val_lambda_916_loss: 0.2339\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2389 - lambda_911_loss: 0.2999 - lambda_916_loss: 0.2389 - val_loss: 0.2362 - val_lambda_911_loss: 0.2960 - val_lambda_916_loss: 0.2362\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2379 - lambda_911_loss: 0.2991 - lambda_916_loss: 0.2379 - val_loss: 0.2397 - val_lambda_911_loss: 0.3020 - val_lambda_916_loss: 0.2397\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.2383 - lambda_911_loss: 0.2992 - lambda_916_loss: 0.2383 - val_loss: 0.2338 - val_lambda_911_loss: 0.2955 - val_lambda_916_loss: 0.2338\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2366 - lambda_911_loss: 0.2973 - lambda_916_loss: 0.2366 - val_loss: 0.2335 - val_lambda_911_loss: 0.2912 - val_lambda_916_loss: 0.2335\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.2374 - lambda_911_loss: 0.2983 - lambda_916_loss: 0.2374 - val_loss: 0.2317 - val_lambda_911_loss: 0.2959 - val_lambda_916_loss: 0.2317\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2347 - lambda_911_loss: 0.2950 - lambda_916_loss: 0.2347 - val_loss: 0.2358 - val_lambda_911_loss: 0.2976 - val_lambda_916_loss: 0.2358\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2369 - lambda_911_loss: 0.2979 - lambda_916_loss: 0.2369 - val_loss: 0.2306 - val_lambda_911_loss: 0.2912 - val_lambda_916_loss: 0.2306\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2333 - lambda_911_loss: 0.2939 - lambda_916_loss: 0.2333 - val_loss: 0.2300 - val_lambda_911_loss: 0.2953 - val_lambda_916_loss: 0.2300\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2361 - lambda_911_loss: 0.2967 - lambda_916_loss: 0.2361 - val_loss: 0.2303 - val_lambda_911_loss: 0.2876 - val_lambda_916_loss: 0.2303\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2336 - lambda_911_loss: 0.2941 - lambda_916_loss: 0.2336 - val_loss: 0.2331 - val_lambda_911_loss: 0.2951 - val_lambda_916_loss: 0.2331\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2356 - lambda_911_loss: 0.2957 - lambda_916_loss: 0.2356 - val_loss: 0.2336 - val_lambda_911_loss: 0.2975 - val_lambda_916_loss: 0.2336\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2336 - lambda_911_loss: 0.2939 - lambda_916_loss: 0.2336 - val_loss: 0.2342 - val_lambda_911_loss: 0.2983 - val_lambda_916_loss: 0.2342\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2329 - lambda_911_loss: 0.2937 - lambda_916_loss: 0.2329 - val_loss: 0.2311 - val_lambda_911_loss: 0.2878 - val_lambda_916_loss: 0.2311\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2336 - lambda_911_loss: 0.2938 - lambda_916_loss: 0.2336 - val_loss: 0.2308 - val_lambda_911_loss: 0.2904 - val_lambda_916_loss: 0.2308\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2322 - lambda_911_loss: 0.2926 - lambda_916_loss: 0.2322 - val_loss: 0.2284 - val_lambda_911_loss: 0.2889 - val_lambda_916_loss: 0.2284\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2320 - lambda_911_loss: 0.2922 - lambda_916_loss: 0.2320 - val_loss: 0.2312 - val_lambda_911_loss: 0.2961 - val_lambda_916_loss: 0.2312\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2326 - lambda_911_loss: 0.2927 - lambda_916_loss: 0.2326 - val_loss: 0.2325 - val_lambda_911_loss: 0.2969 - val_lambda_916_loss: 0.2325\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2319 - lambda_911_loss: 0.2915 - lambda_916_loss: 0.2319 - val_loss: 0.2292 - val_lambda_911_loss: 0.2933 - val_lambda_916_loss: 0.2292\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_921 (Lambda)             (None, 256, 256, 2)  0           input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 256, 256, 48) 912         lambda_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 256, 256, 2)  98          conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_213 (Add)                   (None, 256, 256, 2)  0           conv2d_642[0][0]                 \n",
      "                                                                 lambda_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_926 (Lambda)             (None, 256, 256, 2)  0           add_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_107 (Multiply)         (None, 256, 256, 2)  0           lambda_926[0][0]                 \n",
      "                                                                 input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_214 (Add)                   (None, 256, 256, 2)  0           multiply_107[0][0]               \n",
      "                                                                 input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_931 (Lambda)             (None, 256, 256, 2)  0           add_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_936 (Lambda)             (None, 256, 256, 1)  0           lambda_931[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 84,146\n",
      "Trainable params: 84,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_i_gaussian_25.hdf5\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 73s 109ms/step - loss: 0.2754 - lambda_931_loss: 0.3029 - lambda_936_loss: 0.2754 - val_loss: 0.2455 - val_lambda_931_loss: 0.2773 - val_lambda_936_loss: 0.2455\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2397 - lambda_931_loss: 0.2669 - lambda_936_loss: 0.2397 - val_loss: 0.2386 - val_lambda_931_loss: 0.2659 - val_lambda_936_loss: 0.2386\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.2303 - lambda_931_loss: 0.2580 - lambda_936_loss: 0.2303 - val_loss: 0.2412 - val_lambda_931_loss: 0.2744 - val_lambda_936_loss: 0.2412\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2214 - lambda_931_loss: 0.2490 - lambda_936_loss: 0.2214 - val_loss: 0.2236 - val_lambda_931_loss: 0.2504 - val_lambda_936_loss: 0.2236\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2171 - lambda_931_loss: 0.2448 - lambda_936_loss: 0.2171 - val_loss: 0.2322 - val_lambda_931_loss: 0.2603 - val_lambda_936_loss: 0.2322\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2147 - lambda_931_loss: 0.2428 - lambda_936_loss: 0.2147 - val_loss: 0.2249 - val_lambda_931_loss: 0.2462 - val_lambda_936_loss: 0.2249\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2100 - lambda_931_loss: 0.2381 - lambda_936_loss: 0.2100 - val_loss: 0.2158 - val_lambda_931_loss: 0.2385 - val_lambda_936_loss: 0.2158\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2106 - lambda_931_loss: 0.2386 - lambda_936_loss: 0.2106 - val_loss: 0.2200 - val_lambda_931_loss: 0.2477 - val_lambda_936_loss: 0.2200\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2090 - lambda_931_loss: 0.2372 - lambda_936_loss: 0.2090 - val_loss: 0.2066 - val_lambda_931_loss: 0.2345 - val_lambda_936_loss: 0.2066\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.2062 - lambda_931_loss: 0.2347 - lambda_936_loss: 0.2062 - val_loss: 0.2122 - val_lambda_931_loss: 0.2342 - val_lambda_936_loss: 0.2122\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2055 - lambda_931_loss: 0.2338 - lambda_936_loss: 0.2055 - val_loss: 0.2029 - val_lambda_931_loss: 0.2291 - val_lambda_936_loss: 0.2029\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2025 - lambda_931_loss: 0.2302 - lambda_936_loss: 0.2025 - val_loss: 0.2270 - val_lambda_931_loss: 0.2530 - val_lambda_936_loss: 0.2270\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.2032 - lambda_931_loss: 0.2314 - lambda_936_loss: 0.2032 - val_loss: 0.2158 - val_lambda_931_loss: 0.2388 - val_lambda_936_loss: 0.2158\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.2046 - lambda_931_loss: 0.2329 - lambda_936_loss: 0.2046 - val_loss: 0.2081 - val_lambda_931_loss: 0.2356 - val_lambda_936_loss: 0.2081\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2020 - lambda_931_loss: 0.2300 - lambda_936_loss: 0.2020 - val_loss: 0.2122 - val_lambda_931_loss: 0.2388 - val_lambda_936_loss: 0.2122\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.2012 - lambda_931_loss: 0.2291 - lambda_936_loss: 0.2012 - val_loss: 0.2010 - val_lambda_931_loss: 0.2279 - val_lambda_936_loss: 0.2010\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 62s 94ms/step - loss: 0.2018 - lambda_931_loss: 0.2299 - lambda_936_loss: 0.2018 - val_loss: 0.2171 - val_lambda_931_loss: 0.2431 - val_lambda_936_loss: 0.2171\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1996 - lambda_931_loss: 0.2277 - lambda_936_loss: 0.1996 - val_loss: 0.2187 - val_lambda_931_loss: 0.2407 - val_lambda_936_loss: 0.2187\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1991 - lambda_931_loss: 0.2273 - lambda_936_loss: 0.1991 - val_loss: 0.2079 - val_lambda_931_loss: 0.2403 - val_lambda_936_loss: 0.2079\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1980 - lambda_931_loss: 0.2260 - lambda_936_loss: 0.1980 - val_loss: 0.2245 - val_lambda_931_loss: 0.2467 - val_lambda_936_loss: 0.2245\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1995 - lambda_931_loss: 0.2273 - lambda_936_loss: 0.1995 - val_loss: 0.2074 - val_lambda_931_loss: 0.2380 - val_lambda_936_loss: 0.2074\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1969 - lambda_931_loss: 0.2249 - lambda_936_loss: 0.1969 - val_loss: 0.1992 - val_lambda_931_loss: 0.2227 - val_lambda_936_loss: 0.1992\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 62s 92ms/step - loss: 0.1975 - lambda_931_loss: 0.2256 - lambda_936_loss: 0.1975 - val_loss: 0.2170 - val_lambda_931_loss: 0.2390 - val_lambda_936_loss: 0.2170\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1976 - lambda_931_loss: 0.2255 - lambda_936_loss: 0.1976 - val_loss: 0.1986 - val_lambda_931_loss: 0.2270 - val_lambda_936_loss: 0.1986\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1974 - lambda_931_loss: 0.2255 - lambda_936_loss: 0.1974 - val_loss: 0.2142 - val_lambda_931_loss: 0.2423 - val_lambda_936_loss: 0.2142\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1932 - lambda_931_loss: 0.2212 - lambda_936_loss: 0.1932 - val_loss: 0.2175 - val_lambda_931_loss: 0.2490 - val_lambda_936_loss: 0.2175\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1969 - lambda_931_loss: 0.2252 - lambda_936_loss: 0.1969 - val_loss: 0.2300 - val_lambda_931_loss: 0.2563 - val_lambda_936_loss: 0.2300\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1956 - lambda_931_loss: 0.2236 - lambda_936_loss: 0.1956 - val_loss: 0.2060 - val_lambda_931_loss: 0.2295 - val_lambda_936_loss: 0.2060\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1954 - lambda_931_loss: 0.2240 - lambda_936_loss: 0.1954 - val_loss: 0.2070 - val_lambda_931_loss: 0.2327 - val_lambda_936_loss: 0.2070\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1950 - lambda_931_loss: 0.2232 - lambda_936_loss: 0.1950 - val_loss: 0.2184 - val_lambda_931_loss: 0.2448 - val_lambda_936_loss: 0.2184\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1937 - lambda_931_loss: 0.2214 - lambda_936_loss: 0.1937 - val_loss: 0.2142 - val_lambda_931_loss: 0.2408 - val_lambda_936_loss: 0.2142\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1922 - lambda_931_loss: 0.2198 - lambda_936_loss: 0.1922 - val_loss: 0.2195 - val_lambda_931_loss: 0.2402 - val_lambda_936_loss: 0.2195\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1940 - lambda_931_loss: 0.2220 - lambda_936_loss: 0.1940 - val_loss: 0.2273 - val_lambda_931_loss: 0.2522 - val_lambda_936_loss: 0.2273\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1925 - lambda_931_loss: 0.2203 - lambda_936_loss: 0.1925 - val_loss: 0.2082 - val_lambda_931_loss: 0.2307 - val_lambda_936_loss: 0.2082\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1943 - lambda_931_loss: 0.2223 - lambda_936_loss: 0.1943 - val_loss: 0.2185 - val_lambda_931_loss: 0.2404 - val_lambda_936_loss: 0.2185\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1941 - lambda_931_loss: 0.2219 - lambda_936_loss: 0.1941 - val_loss: 0.2043 - val_lambda_931_loss: 0.2304 - val_lambda_936_loss: 0.2043\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1925 - lambda_931_loss: 0.2203 - lambda_936_loss: 0.1925 - val_loss: 0.2143 - val_lambda_931_loss: 0.2377 - val_lambda_936_loss: 0.2143\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1913 - lambda_931_loss: 0.2192 - lambda_936_loss: 0.1913 - val_loss: 0.2224 - val_lambda_931_loss: 0.2487 - val_lambda_936_loss: 0.2224\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 63s 94ms/step - loss: 0.1915 - lambda_931_loss: 0.2194 - lambda_936_loss: 0.1915 - val_loss: 0.2117 - val_lambda_931_loss: 0.2354 - val_lambda_936_loss: 0.2117\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1909 - lambda_931_loss: 0.2185 - lambda_936_loss: 0.1909 - val_loss: 0.2015 - val_lambda_931_loss: 0.2277 - val_lambda_936_loss: 0.2015\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1900 - lambda_931_loss: 0.2179 - lambda_936_loss: 0.1900 - val_loss: 0.2091 - val_lambda_931_loss: 0.2405 - val_lambda_936_loss: 0.2091\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1887 - lambda_931_loss: 0.2165 - lambda_936_loss: 0.1887 - val_loss: 0.2082 - val_lambda_931_loss: 0.2342 - val_lambda_936_loss: 0.2082\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1890 - lambda_931_loss: 0.2167 - lambda_936_loss: 0.1890 - val_loss: 0.2110 - val_lambda_931_loss: 0.2367 - val_lambda_936_loss: 0.2110\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 62s 93ms/step - loss: 0.1896 - lambda_931_loss: 0.2173 - lambda_936_loss: 0.1896 - val_loss: 0.2235 - val_lambda_931_loss: 0.2502 - val_lambda_936_loss: 0.2235\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 256, 256, 48) 912         input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 256, 256, 2)  98          conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_215 (Add)                   (None, 256, 256, 2)  0           conv2d_648[0][0]                 \n",
      "                                                                 input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_108 (Multiply)         (None, 256, 256, 2)  0           add_215[0][0]                    \n",
      "                                                                 input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_216 (Add)                   (None, 256, 256, 2)  0           multiply_108[0][0]               \n",
      "                                                                 input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 256, 256, 48) 912         add_216[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 256, 256, 2)  98          conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_217 (Add)                   (None, 256, 256, 2)  0           conv2d_654[0][0]                 \n",
      "                                                                 add_216[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_109 (Multiply)         (None, 256, 256, 2)  0           add_217[0][0]                    \n",
      "                                                                 input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_218 (Add)                   (None, 256, 256, 2)  0           multiply_109[0][0]               \n",
      "                                                                 input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_941 (Lambda)             (None, 256, 256, 2)  0           add_218[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_946 (Lambda)             (None, 256, 256, 1)  0           lambda_941[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kk_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 76s 114ms/step - loss: 0.3485 - lambda_941_loss: 0.4202 - lambda_946_loss: 0.3485 - val_loss: 0.3013 - val_lambda_941_loss: 0.3666 - val_lambda_946_loss: 0.3013\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2902 - lambda_941_loss: 0.3567 - lambda_946_loss: 0.2902 - val_loss: 0.2672 - val_lambda_941_loss: 0.3338 - val_lambda_946_loss: 0.2672\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2737 - lambda_941_loss: 0.3388 - lambda_946_loss: 0.2737 - val_loss: 0.2692 - val_lambda_941_loss: 0.3374 - val_lambda_946_loss: 0.2692\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2611 - lambda_941_loss: 0.3251 - lambda_946_loss: 0.2611 - val_loss: 0.2712 - val_lambda_941_loss: 0.3403 - val_lambda_946_loss: 0.2712\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2566 - lambda_941_loss: 0.3203 - lambda_946_loss: 0.2566 - val_loss: 0.2426 - val_lambda_941_loss: 0.3066 - val_lambda_946_loss: 0.2426\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2513 - lambda_941_loss: 0.3136 - lambda_946_loss: 0.2513 - val_loss: 0.2442 - val_lambda_941_loss: 0.3032 - val_lambda_946_loss: 0.2442\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2462 - lambda_941_loss: 0.3080 - lambda_946_loss: 0.2462 - val_loss: 0.2520 - val_lambda_941_loss: 0.3206 - val_lambda_946_loss: 0.2520\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2424 - lambda_941_loss: 0.3037 - lambda_946_loss: 0.2424 - val_loss: 0.2414 - val_lambda_941_loss: 0.3067 - val_lambda_946_loss: 0.2414\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2407 - lambda_941_loss: 0.3019 - lambda_946_loss: 0.2407 - val_loss: 0.2337 - val_lambda_941_loss: 0.2956 - val_lambda_946_loss: 0.2337\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2366 - lambda_941_loss: 0.2972 - lambda_946_loss: 0.2366 - val_loss: 0.2315 - val_lambda_941_loss: 0.2886 - val_lambda_946_loss: 0.2315\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2321 - lambda_941_loss: 0.2924 - lambda_946_loss: 0.2321 - val_loss: 0.2332 - val_lambda_941_loss: 0.2935 - val_lambda_946_loss: 0.2332\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2345 - lambda_941_loss: 0.2946 - lambda_946_loss: 0.2345 - val_loss: 0.2239 - val_lambda_941_loss: 0.2847 - val_lambda_946_loss: 0.2239\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2315 - lambda_941_loss: 0.2914 - lambda_946_loss: 0.2315 - val_loss: 0.2256 - val_lambda_941_loss: 0.2900 - val_lambda_946_loss: 0.2256\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2321 - lambda_941_loss: 0.2922 - lambda_946_loss: 0.2321 - val_loss: 0.2257 - val_lambda_941_loss: 0.2868 - val_lambda_946_loss: 0.2257\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2267 - lambda_941_loss: 0.2865 - lambda_946_loss: 0.2267 - val_loss: 0.2342 - val_lambda_941_loss: 0.2989 - val_lambda_946_loss: 0.2342\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.2250 - lambda_941_loss: 0.2846 - lambda_946_loss: 0.2250 - val_loss: 0.2178 - val_lambda_941_loss: 0.2808 - val_lambda_946_loss: 0.2178\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.2258 - lambda_941_loss: 0.2857 - lambda_946_loss: 0.2258 - val_loss: 0.2216 - val_lambda_941_loss: 0.2791 - val_lambda_946_loss: 0.2216\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 67s 100ms/step - loss: 0.2245 - lambda_941_loss: 0.2835 - lambda_946_loss: 0.2245 - val_loss: 0.2171 - val_lambda_941_loss: 0.2769 - val_lambda_946_loss: 0.2171\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.2235 - lambda_941_loss: 0.2823 - lambda_946_loss: 0.2235 - val_loss: 0.2183 - val_lambda_941_loss: 0.2750 - val_lambda_946_loss: 0.2183\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2210 - lambda_941_loss: 0.2793 - lambda_946_loss: 0.2210 - val_loss: 0.2142 - val_lambda_941_loss: 0.2714 - val_lambda_946_loss: 0.2142\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2203 - lambda_941_loss: 0.2792 - lambda_946_loss: 0.2203 - val_loss: 0.2197 - val_lambda_941_loss: 0.2808 - val_lambda_946_loss: 0.2197\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2205 - lambda_941_loss: 0.2792 - lambda_946_loss: 0.2205 - val_loss: 0.2173 - val_lambda_941_loss: 0.2773 - val_lambda_946_loss: 0.2173\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2198 - lambda_941_loss: 0.2783 - lambda_946_loss: 0.2198 - val_loss: 0.2131 - val_lambda_941_loss: 0.2714 - val_lambda_946_loss: 0.2131\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2194 - lambda_941_loss: 0.2783 - lambda_946_loss: 0.2194 - val_loss: 0.2165 - val_lambda_941_loss: 0.2737 - val_lambda_946_loss: 0.2165\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2190 - lambda_941_loss: 0.2773 - lambda_946_loss: 0.2190 - val_loss: 0.2146 - val_lambda_941_loss: 0.2725 - val_lambda_946_loss: 0.2146\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2182 - lambda_941_loss: 0.2770 - lambda_946_loss: 0.2182 - val_loss: 0.2126 - val_lambda_941_loss: 0.2731 - val_lambda_946_loss: 0.2126\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2177 - lambda_941_loss: 0.2762 - lambda_946_loss: 0.2177 - val_loss: 0.2088 - val_lambda_941_loss: 0.2648 - val_lambda_946_loss: 0.2088\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2151 - lambda_941_loss: 0.2733 - lambda_946_loss: 0.2151 - val_loss: 0.2148 - val_lambda_941_loss: 0.2737 - val_lambda_946_loss: 0.2148\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2148 - lambda_941_loss: 0.2731 - lambda_946_loss: 0.2148 - val_loss: 0.2133 - val_lambda_941_loss: 0.2732 - val_lambda_946_loss: 0.2133\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2140 - lambda_941_loss: 0.2717 - lambda_946_loss: 0.2140 - val_loss: 0.2093 - val_lambda_941_loss: 0.2694 - val_lambda_946_loss: 0.2093\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2127 - lambda_941_loss: 0.2705 - lambda_946_loss: 0.2127 - val_loss: 0.2087 - val_lambda_941_loss: 0.2651 - val_lambda_946_loss: 0.2087\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2125 - lambda_941_loss: 0.2698 - lambda_946_loss: 0.2125 - val_loss: 0.2053 - val_lambda_941_loss: 0.2630 - val_lambda_946_loss: 0.2053\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2133 - lambda_941_loss: 0.2715 - lambda_946_loss: 0.2133 - val_loss: 0.2070 - val_lambda_941_loss: 0.2655 - val_lambda_946_loss: 0.2070\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2125 - lambda_941_loss: 0.2699 - lambda_946_loss: 0.2125 - val_loss: 0.2214 - val_lambda_941_loss: 0.2794 - val_lambda_946_loss: 0.2214\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2128 - lambda_941_loss: 0.2704 - lambda_946_loss: 0.2128 - val_loss: 0.2061 - val_lambda_941_loss: 0.2643 - val_lambda_946_loss: 0.2061\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2106 - lambda_941_loss: 0.2681 - lambda_946_loss: 0.2106 - val_loss: 0.2109 - val_lambda_941_loss: 0.2672 - val_lambda_946_loss: 0.2109\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2099 - lambda_941_loss: 0.2677 - lambda_946_loss: 0.2099 - val_loss: 0.2083 - val_lambda_941_loss: 0.2644 - val_lambda_946_loss: 0.2083\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2108 - lambda_941_loss: 0.2681 - lambda_946_loss: 0.2108 - val_loss: 0.2088 - val_lambda_941_loss: 0.2666 - val_lambda_946_loss: 0.2088\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2067 - lambda_941_loss: 0.2640 - lambda_946_loss: 0.2067 - val_loss: 0.2027 - val_lambda_941_loss: 0.2574 - val_lambda_946_loss: 0.2027\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.2103 - lambda_941_loss: 0.2675 - lambda_946_loss: 0.2103 - val_loss: 0.2058 - val_lambda_941_loss: 0.2622 - val_lambda_946_loss: 0.2058\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2083 - lambda_941_loss: 0.2661 - lambda_946_loss: 0.2083 - val_loss: 0.2012 - val_lambda_941_loss: 0.2573 - val_lambda_946_loss: 0.2012\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2080 - lambda_941_loss: 0.2654 - lambda_946_loss: 0.2080 - val_loss: 0.2059 - val_lambda_941_loss: 0.2632 - val_lambda_946_loss: 0.2059\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2087 - lambda_941_loss: 0.2658 - lambda_946_loss: 0.2087 - val_loss: 0.2093 - val_lambda_941_loss: 0.2688 - val_lambda_946_loss: 0.2093\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.2091 - lambda_941_loss: 0.2667 - lambda_946_loss: 0.2091 - val_loss: 0.2065 - val_lambda_941_loss: 0.2618 - val_lambda_946_loss: 0.2065\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2070 - lambda_941_loss: 0.2643 - lambda_946_loss: 0.2070 - val_loss: 0.2021 - val_lambda_941_loss: 0.2585 - val_lambda_946_loss: 0.2021\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.2074 - lambda_941_loss: 0.2639 - lambda_946_loss: 0.2074 - val_loss: 0.2028 - val_lambda_941_loss: 0.2600 - val_lambda_946_loss: 0.2028\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2059 - lambda_941_loss: 0.2626 - lambda_946_loss: 0.2059 - val_loss: 0.2010 - val_lambda_941_loss: 0.2547 - val_lambda_946_loss: 0.2010\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.2050 - lambda_941_loss: 0.2618 - lambda_946_loss: 0.2050 - val_loss: 0.2048 - val_lambda_941_loss: 0.2616 - val_lambda_946_loss: 0.2048\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2046 - lambda_941_loss: 0.2616 - lambda_946_loss: 0.2046 - val_loss: 0.2025 - val_lambda_941_loss: 0.2622 - val_lambda_946_loss: 0.2025\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.2061 - lambda_941_loss: 0.2628 - lambda_946_loss: 0.2061 - val_loss: 0.2060 - val_lambda_941_loss: 0.2649 - val_lambda_946_loss: 0.2060\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_951 (Lambda)             (None, 256, 256, 2)  0           input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 256, 256, 48) 912         lambda_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 256, 256, 2)  98          conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_219 (Add)                   (None, 256, 256, 2)  0           conv2d_660[0][0]                 \n",
      "                                                                 lambda_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_956 (Lambda)             (None, 256, 256, 2)  0           add_219[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_110 (Multiply)         (None, 256, 256, 2)  0           lambda_956[0][0]                 \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_220 (Add)                   (None, 256, 256, 2)  0           multiply_110[0][0]               \n",
      "                                                                 input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_961 (Lambda)             (None, 256, 256, 2)  0           add_220[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 256, 256, 48) 912         lambda_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 256, 256, 2)  98          conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_221 (Add)                   (None, 256, 256, 2)  0           conv2d_666[0][0]                 \n",
      "                                                                 lambda_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_966 (Lambda)             (None, 256, 256, 2)  0           add_221[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_111 (Multiply)         (None, 256, 256, 2)  0           lambda_966[0][0]                 \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_222 (Add)                   (None, 256, 256, 2)  0           multiply_111[0][0]               \n",
      "                                                                 input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_971 (Lambda)             (None, 256, 256, 2)  0           add_222[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_976 (Lambda)             (None, 256, 256, 1)  0           lambda_971[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 75s 113ms/step - loss: 0.2027 - lambda_971_loss: 0.2305 - lambda_976_loss: 0.2027 - val_loss: 0.1788 - val_lambda_971_loss: 0.2090 - val_lambda_976_loss: 0.1788\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1512 - lambda_971_loss: 0.1754 - lambda_976_loss: 0.1512 - val_loss: 0.1580 - val_lambda_971_loss: 0.1775 - val_lambda_976_loss: 0.1580\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1366 - lambda_971_loss: 0.1614 - lambda_976_loss: 0.1366 - val_loss: 0.1333 - val_lambda_971_loss: 0.1523 - val_lambda_976_loss: 0.1333\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1282 - lambda_971_loss: 0.1545 - lambda_976_loss: 0.1282 - val_loss: 0.1309 - val_lambda_971_loss: 0.1625 - val_lambda_976_loss: 0.1309\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1257 - lambda_971_loss: 0.1517 - lambda_976_loss: 0.1257 - val_loss: 0.1325 - val_lambda_971_loss: 0.1645 - val_lambda_976_loss: 0.1325\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1223 - lambda_971_loss: 0.1484 - lambda_976_loss: 0.1223 - val_loss: 0.1327 - val_lambda_971_loss: 0.1716 - val_lambda_976_loss: 0.1327\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1197 - lambda_971_loss: 0.1454 - lambda_976_loss: 0.1197 - val_loss: 0.1254 - val_lambda_971_loss: 0.1550 - val_lambda_976_loss: 0.1254\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1182 - lambda_971_loss: 0.1437 - lambda_976_loss: 0.1182 - val_loss: 0.1282 - val_lambda_971_loss: 0.1558 - val_lambda_976_loss: 0.1282\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1164 - lambda_971_loss: 0.1419 - lambda_976_loss: 0.1164 - val_loss: 0.1177 - val_lambda_971_loss: 0.1504 - val_lambda_976_loss: 0.1177\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1158 - lambda_971_loss: 0.1411 - lambda_976_loss: 0.1158 - val_loss: 0.1346 - val_lambda_971_loss: 0.1641 - val_lambda_976_loss: 0.1346\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1139 - lambda_971_loss: 0.1393 - lambda_976_loss: 0.1139 - val_loss: 0.1381 - val_lambda_971_loss: 0.1598 - val_lambda_976_loss: 0.1381\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.1129 - lambda_971_loss: 0.1379 - lambda_976_loss: 0.1129 - val_loss: 0.1286 - val_lambda_971_loss: 0.1612 - val_lambda_976_loss: 0.1286\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1109 - lambda_971_loss: 0.1359 - lambda_976_loss: 0.1109 - val_loss: 0.1167 - val_lambda_971_loss: 0.1461 - val_lambda_976_loss: 0.1167\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1106 - lambda_971_loss: 0.1355 - lambda_976_loss: 0.1106 - val_loss: 0.1169 - val_lambda_971_loss: 0.1431 - val_lambda_976_loss: 0.1169\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1110 - lambda_971_loss: 0.1364 - lambda_976_loss: 0.1110 - val_loss: 0.1178 - val_lambda_971_loss: 0.1479 - val_lambda_976_loss: 0.1178\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1094 - lambda_971_loss: 0.1342 - lambda_976_loss: 0.1094 - val_loss: 0.1163 - val_lambda_971_loss: 0.1457 - val_lambda_976_loss: 0.1163\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1085 - lambda_971_loss: 0.1330 - lambda_976_loss: 0.1085 - val_loss: 0.1226 - val_lambda_971_loss: 0.1517 - val_lambda_976_loss: 0.1226\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1077 - lambda_971_loss: 0.1322 - lambda_976_loss: 0.1077 - val_loss: 0.1166 - val_lambda_971_loss: 0.1458 - val_lambda_976_loss: 0.1166\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1073 - lambda_971_loss: 0.1319 - lambda_976_loss: 0.1073 - val_loss: 0.1122 - val_lambda_971_loss: 0.1359 - val_lambda_976_loss: 0.1122\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1072 - lambda_971_loss: 0.1316 - lambda_976_loss: 0.1072 - val_loss: 0.1175 - val_lambda_971_loss: 0.1456 - val_lambda_976_loss: 0.1175\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1058 - lambda_971_loss: 0.1301 - lambda_976_loss: 0.1058 - val_loss: 0.1284 - val_lambda_971_loss: 0.1615 - val_lambda_976_loss: 0.1284\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1062 - lambda_971_loss: 0.1300 - lambda_976_loss: 0.1062 - val_loss: 0.1099 - val_lambda_971_loss: 0.1379 - val_lambda_976_loss: 0.1099\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1052 - lambda_971_loss: 0.1293 - lambda_976_loss: 0.1052 - val_loss: 0.1138 - val_lambda_971_loss: 0.1459 - val_lambda_976_loss: 0.1138\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1044 - lambda_971_loss: 0.1281 - lambda_976_loss: 0.1044 - val_loss: 0.1175 - val_lambda_971_loss: 0.1437 - val_lambda_976_loss: 0.1175\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1040 - lambda_971_loss: 0.1277 - lambda_976_loss: 0.1040 - val_loss: 0.1151 - val_lambda_971_loss: 0.1460 - val_lambda_976_loss: 0.1151\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1036 - lambda_971_loss: 0.1272 - lambda_976_loss: 0.1036 - val_loss: 0.1156 - val_lambda_971_loss: 0.1472 - val_lambda_976_loss: 0.1156\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1034 - lambda_971_loss: 0.1271 - lambda_976_loss: 0.1034 - val_loss: 0.1073 - val_lambda_971_loss: 0.1377 - val_lambda_976_loss: 0.1073\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1027 - lambda_971_loss: 0.1262 - lambda_976_loss: 0.1027 - val_loss: 0.1083 - val_lambda_971_loss: 0.1361 - val_lambda_976_loss: 0.1083\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1020 - lambda_971_loss: 0.1252 - lambda_976_loss: 0.1020 - val_loss: 0.1099 - val_lambda_971_loss: 0.1384 - val_lambda_976_loss: 0.1099\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1027 - lambda_971_loss: 0.1261 - lambda_976_loss: 0.1027 - val_loss: 0.1135 - val_lambda_971_loss: 0.1382 - val_lambda_976_loss: 0.1135\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1029 - lambda_971_loss: 0.1265 - lambda_976_loss: 0.1029 - val_loss: 0.1101 - val_lambda_971_loss: 0.1383 - val_lambda_976_loss: 0.1101\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1014 - lambda_971_loss: 0.1246 - lambda_976_loss: 0.1014 - val_loss: 0.1161 - val_lambda_971_loss: 0.1494 - val_lambda_976_loss: 0.1161\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 63s 95ms/step - loss: 0.1036 - lambda_971_loss: 0.1265 - lambda_976_loss: 0.1036 - val_loss: 0.1172 - val_lambda_971_loss: 0.1396 - val_lambda_976_loss: 0.1172\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1010 - lambda_971_loss: 0.1240 - lambda_976_loss: 0.1010 - val_loss: 0.1108 - val_lambda_971_loss: 0.1357 - val_lambda_976_loss: 0.1108\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1010 - lambda_971_loss: 0.1243 - lambda_976_loss: 0.1010 - val_loss: 0.1096 - val_lambda_971_loss: 0.1395 - val_lambda_976_loss: 0.1096\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1009 - lambda_971_loss: 0.1238 - lambda_976_loss: 0.1009 - val_loss: 0.1173 - val_lambda_971_loss: 0.1453 - val_lambda_976_loss: 0.1173\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1014 - lambda_971_loss: 0.1244 - lambda_976_loss: 0.1014 - val_loss: 0.1164 - val_lambda_971_loss: 0.1532 - val_lambda_976_loss: 0.1164\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1001 - lambda_971_loss: 0.1227 - lambda_976_loss: 0.1001 - val_loss: 0.1082 - val_lambda_971_loss: 0.1343 - val_lambda_976_loss: 0.1082\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1001 - lambda_971_loss: 0.1225 - lambda_976_loss: 0.1001 - val_loss: 0.1121 - val_lambda_971_loss: 0.1396 - val_lambda_976_loss: 0.1121\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.0999 - lambda_971_loss: 0.1224 - lambda_976_loss: 0.0999 - val_loss: 0.1141 - val_lambda_971_loss: 0.1427 - val_lambda_976_loss: 0.1141\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1008 - lambda_971_loss: 0.1238 - lambda_976_loss: 0.1008 - val_loss: 0.1076 - val_lambda_971_loss: 0.1366 - val_lambda_976_loss: 0.1076\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.0995 - lambda_971_loss: 0.1218 - lambda_976_loss: 0.0995 - val_loss: 0.1093 - val_lambda_971_loss: 0.1346 - val_lambda_976_loss: 0.1093\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1008 - lambda_971_loss: 0.1234 - lambda_976_loss: 0.1008 - val_loss: 0.1070 - val_lambda_971_loss: 0.1294 - val_lambda_976_loss: 0.1070\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.0985 - lambda_971_loss: 0.1210 - lambda_976_loss: 0.0985 - val_loss: 0.1085 - val_lambda_971_loss: 0.1356 - val_lambda_976_loss: 0.1085\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.0988 - lambda_971_loss: 0.1210 - lambda_976_loss: 0.0988 - val_loss: 0.1217 - val_lambda_971_loss: 0.1503 - val_lambda_976_loss: 0.1217\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.0989 - lambda_971_loss: 0.1213 - lambda_976_loss: 0.0989 - val_loss: 0.1069 - val_lambda_971_loss: 0.1424 - val_lambda_976_loss: 0.1069\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.0987 - lambda_971_loss: 0.1209 - lambda_976_loss: 0.0987 - val_loss: 0.1070 - val_lambda_971_loss: 0.1340 - val_lambda_976_loss: 0.1070\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.0985 - lambda_971_loss: 0.1207 - lambda_976_loss: 0.0985 - val_loss: 0.1065 - val_lambda_971_loss: 0.1276 - val_lambda_976_loss: 0.1065\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.0984 - lambda_971_loss: 0.1204 - lambda_976_loss: 0.0984 - val_loss: 0.1047 - val_lambda_971_loss: 0.1303 - val_lambda_976_loss: 0.1047\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.0984 - lambda_971_loss: 0.1205 - lambda_976_loss: 0.0984 - val_loss: 0.1164 - val_lambda_971_loss: 0.1516 - val_lambda_976_loss: 0.1164\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_981 (Lambda)             (None, 256, 256, 2)  0           input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 256, 256, 48) 912         lambda_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 256, 256, 2)  98          conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_223 (Add)                   (None, 256, 256, 2)  0           conv2d_672[0][0]                 \n",
      "                                                                 lambda_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_986 (Lambda)             (None, 256, 256, 2)  0           add_223[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_112 (Multiply)         (None, 256, 256, 2)  0           lambda_986[0][0]                 \n",
      "                                                                 input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_224 (Add)                   (None, 256, 256, 2)  0           multiply_112[0][0]               \n",
      "                                                                 input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 256, 256, 48) 912         add_224[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 256, 256, 2)  98          conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_225 (Add)                   (None, 256, 256, 2)  0           conv2d_678[0][0]                 \n",
      "                                                                 add_224[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_113 (Multiply)         (None, 256, 256, 2)  0           add_225[0][0]                    \n",
      "                                                                 input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_226 (Add)                   (None, 256, 256, 2)  0           multiply_113[0][0]               \n",
      "                                                                 input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_991 (Lambda)             (None, 256, 256, 2)  0           add_226[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_996 (Lambda)             (None, 256, 256, 1)  0           lambda_991[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 76s 113ms/step - loss: 0.2259 - lambda_991_loss: 0.2694 - lambda_996_loss: 0.2259 - val_loss: 0.2054 - val_lambda_991_loss: 0.2452 - val_lambda_996_loss: 0.2054\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1766 - lambda_991_loss: 0.2147 - lambda_996_loss: 0.1766 - val_loss: 0.1688 - val_lambda_991_loss: 0.2088 - val_lambda_996_loss: 0.1688\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1681 - lambda_991_loss: 0.2066 - lambda_996_loss: 0.1681 - val_loss: 0.1577 - val_lambda_991_loss: 0.1952 - val_lambda_996_loss: 0.1577\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1588 - lambda_991_loss: 0.1951 - lambda_996_loss: 0.1588 - val_loss: 0.1586 - val_lambda_991_loss: 0.1876 - val_lambda_996_loss: 0.1586\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1554 - lambda_991_loss: 0.1920 - lambda_996_loss: 0.1554 - val_loss: 0.1629 - val_lambda_991_loss: 0.1971 - val_lambda_996_loss: 0.1629\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1521 - lambda_991_loss: 0.1877 - lambda_996_loss: 0.1521 - val_loss: 0.1508 - val_lambda_991_loss: 0.1828 - val_lambda_996_loss: 0.1508\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1487 - lambda_991_loss: 0.1844 - lambda_996_loss: 0.1487 - val_loss: 0.1431 - val_lambda_991_loss: 0.1775 - val_lambda_996_loss: 0.1431\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1455 - lambda_991_loss: 0.1803 - lambda_996_loss: 0.1455 - val_loss: 0.1436 - val_lambda_991_loss: 0.1766 - val_lambda_996_loss: 0.1436\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1446 - lambda_991_loss: 0.1797 - lambda_996_loss: 0.1446 - val_loss: 0.1446 - val_lambda_991_loss: 0.1765 - val_lambda_996_loss: 0.1446\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1434 - lambda_991_loss: 0.1783 - lambda_996_loss: 0.1434 - val_loss: 0.1456 - val_lambda_991_loss: 0.1807 - val_lambda_996_loss: 0.1456\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1411 - lambda_991_loss: 0.1759 - lambda_996_loss: 0.1411 - val_loss: 0.1407 - val_lambda_991_loss: 0.1698 - val_lambda_996_loss: 0.1407\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1400 - lambda_991_loss: 0.1748 - lambda_996_loss: 0.1400 - val_loss: 0.1445 - val_lambda_991_loss: 0.1782 - val_lambda_996_loss: 0.1445\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1391 - lambda_991_loss: 0.1737 - lambda_996_loss: 0.1391 - val_loss: 0.1413 - val_lambda_991_loss: 0.1740 - val_lambda_996_loss: 0.1413\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1368 - lambda_991_loss: 0.1711 - lambda_996_loss: 0.1368 - val_loss: 0.1359 - val_lambda_991_loss: 0.1639 - val_lambda_996_loss: 0.1359\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1360 - lambda_991_loss: 0.1698 - lambda_996_loss: 0.1360 - val_loss: 0.1427 - val_lambda_991_loss: 0.1728 - val_lambda_996_loss: 0.1427\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1352 - lambda_991_loss: 0.1690 - lambda_996_loss: 0.1352 - val_loss: 0.1396 - val_lambda_991_loss: 0.1710 - val_lambda_996_loss: 0.1396\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 64s 95ms/step - loss: 0.1339 - lambda_991_loss: 0.1677 - lambda_996_loss: 0.1339 - val_loss: 0.1381 - val_lambda_991_loss: 0.1668 - val_lambda_996_loss: 0.1381\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1343 - lambda_991_loss: 0.1680 - lambda_996_loss: 0.1343 - val_loss: 0.1346 - val_lambda_991_loss: 0.1648 - val_lambda_996_loss: 0.1346\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1329 - lambda_991_loss: 0.1661 - lambda_996_loss: 0.1329 - val_loss: 0.1364 - val_lambda_991_loss: 0.1683 - val_lambda_996_loss: 0.1364\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1321 - lambda_991_loss: 0.1658 - lambda_996_loss: 0.1321 - val_loss: 0.1406 - val_lambda_991_loss: 0.1697 - val_lambda_996_loss: 0.1406\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1308 - lambda_991_loss: 0.1641 - lambda_996_loss: 0.1308 - val_loss: 0.1467 - val_lambda_991_loss: 0.1784 - val_lambda_996_loss: 0.1467\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1310 - lambda_991_loss: 0.1643 - lambda_996_loss: 0.1310 - val_loss: 0.1315 - val_lambda_991_loss: 0.1628 - val_lambda_996_loss: 0.1315\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1297 - lambda_991_loss: 0.1625 - lambda_996_loss: 0.1297 - val_loss: 0.1377 - val_lambda_991_loss: 0.1661 - val_lambda_996_loss: 0.1377\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1299 - lambda_991_loss: 0.1628 - lambda_996_loss: 0.1299 - val_loss: 0.1276 - val_lambda_991_loss: 0.1565 - val_lambda_996_loss: 0.1276\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1296 - lambda_991_loss: 0.1625 - lambda_996_loss: 0.1296 - val_loss: 0.1391 - val_lambda_991_loss: 0.1726 - val_lambda_996_loss: 0.1391\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1279 - lambda_991_loss: 0.1608 - lambda_996_loss: 0.1279 - val_loss: 0.1351 - val_lambda_991_loss: 0.1631 - val_lambda_996_loss: 0.1351\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.1273 - lambda_991_loss: 0.1599 - lambda_996_loss: 0.1273 - val_loss: 0.1471 - val_lambda_991_loss: 0.1752 - val_lambda_996_loss: 0.1471\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1284 - lambda_991_loss: 0.1616 - lambda_996_loss: 0.1284 - val_loss: 0.1293 - val_lambda_991_loss: 0.1626 - val_lambda_996_loss: 0.1293\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1272 - lambda_991_loss: 0.1598 - lambda_996_loss: 0.1272 - val_loss: 0.1308 - val_lambda_991_loss: 0.1571 - val_lambda_996_loss: 0.1308\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1264 - lambda_991_loss: 0.1586 - lambda_996_loss: 0.1264 - val_loss: 0.1301 - val_lambda_991_loss: 0.1593 - val_lambda_996_loss: 0.1301\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1270 - lambda_991_loss: 0.1597 - lambda_996_loss: 0.1270 - val_loss: 0.1357 - val_lambda_991_loss: 0.1643 - val_lambda_996_loss: 0.1357\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1263 - lambda_991_loss: 0.1586 - lambda_996_loss: 0.1263 - val_loss: 0.1323 - val_lambda_991_loss: 0.1619 - val_lambda_996_loss: 0.1323\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1262 - lambda_991_loss: 0.1587 - lambda_996_loss: 0.1262 - val_loss: 0.1265 - val_lambda_991_loss: 0.1545 - val_lambda_996_loss: 0.1265\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1244 - lambda_991_loss: 0.1565 - lambda_996_loss: 0.1244 - val_loss: 0.1333 - val_lambda_991_loss: 0.1585 - val_lambda_996_loss: 0.1333\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1246 - lambda_991_loss: 0.1567 - lambda_996_loss: 0.1246 - val_loss: 0.1255 - val_lambda_991_loss: 0.1584 - val_lambda_996_loss: 0.1255\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1245 - lambda_991_loss: 0.1566 - lambda_996_loss: 0.1245 - val_loss: 0.1297 - val_lambda_991_loss: 0.1593 - val_lambda_996_loss: 0.1297\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1239 - lambda_991_loss: 0.1558 - lambda_996_loss: 0.1239 - val_loss: 0.1268 - val_lambda_991_loss: 0.1562 - val_lambda_996_loss: 0.1268\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1236 - lambda_991_loss: 0.1556 - lambda_996_loss: 0.1236 - val_loss: 0.1340 - val_lambda_991_loss: 0.1642 - val_lambda_996_loss: 0.1340\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1239 - lambda_991_loss: 0.1565 - lambda_996_loss: 0.1239 - val_loss: 0.1342 - val_lambda_991_loss: 0.1612 - val_lambda_996_loss: 0.1342\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1233 - lambda_991_loss: 0.1552 - lambda_996_loss: 0.1233 - val_loss: 0.1288 - val_lambda_991_loss: 0.1570 - val_lambda_996_loss: 0.1288\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1222 - lambda_991_loss: 0.1539 - lambda_996_loss: 0.1222 - val_loss: 0.1291 - val_lambda_991_loss: 0.1572 - val_lambda_996_loss: 0.1291\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1233 - lambda_991_loss: 0.1558 - lambda_996_loss: 0.1233 - val_loss: 0.1321 - val_lambda_991_loss: 0.1620 - val_lambda_996_loss: 0.1321\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 66s 98ms/step - loss: 0.1224 - lambda_991_loss: 0.1544 - lambda_996_loss: 0.1224 - val_loss: 0.1266 - val_lambda_991_loss: 0.1558 - val_lambda_996_loss: 0.1266\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1218 - lambda_991_loss: 0.1534 - lambda_996_loss: 0.1218 - val_loss: 0.1345 - val_lambda_991_loss: 0.1642 - val_lambda_996_loss: 0.1345\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1210 - lambda_991_loss: 0.1525 - lambda_996_loss: 0.1210 - val_loss: 0.1269 - val_lambda_991_loss: 0.1534 - val_lambda_996_loss: 0.1269\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1217 - lambda_991_loss: 0.1533 - lambda_996_loss: 0.1217 - val_loss: 0.1293 - val_lambda_991_loss: 0.1581 - val_lambda_996_loss: 0.1293\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1216 - lambda_991_loss: 0.1534 - lambda_996_loss: 0.1216 - val_loss: 0.1255 - val_lambda_991_loss: 0.1552 - val_lambda_996_loss: 0.1255\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1200 - lambda_991_loss: 0.1512 - lambda_996_loss: 0.1200 - val_loss: 0.1249 - val_lambda_991_loss: 0.1562 - val_lambda_996_loss: 0.1249\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1213 - lambda_991_loss: 0.1531 - lambda_996_loss: 0.1213 - val_loss: 0.1272 - val_lambda_991_loss: 0.1575 - val_lambda_996_loss: 0.1272\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1206 - lambda_991_loss: 0.1523 - lambda_996_loss: 0.1206 - val_loss: 0.1211 - val_lambda_991_loss: 0.1530 - val_lambda_996_loss: 0.1211\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 256, 256, 48) 912         input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_682 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_682[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 256, 256, 2)  98          conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_227 (Add)                   (None, 256, 256, 2)  0           conv2d_684[0][0]                 \n",
      "                                                                 input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_114 (Multiply)         (None, 256, 256, 2)  0           add_227[0][0]                    \n",
      "                                                                 input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_228 (Add)                   (None, 256, 256, 2)  0           multiply_114[0][0]               \n",
      "                                                                 input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1001 (Lambda)            (None, 256, 256, 2)  0           add_228[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 256, 256, 48) 912         lambda_1001[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 256, 256, 2)  98          conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_229 (Add)                   (None, 256, 256, 2)  0           conv2d_690[0][0]                 \n",
      "                                                                 lambda_1001[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1006 (Lambda)            (None, 256, 256, 2)  0           add_229[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_115 (Multiply)         (None, 256, 256, 2)  0           lambda_1006[0][0]                \n",
      "                                                                 input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_230 (Add)                   (None, 256, 256, 2)  0           multiply_115[0][0]               \n",
      "                                                                 input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1011 (Lambda)            (None, 256, 256, 2)  0           add_230[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1016 (Lambda)            (None, 256, 256, 1)  0           lambda_1011[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 168,292\n",
      "Trainable params: 168,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ki_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 76s 114ms/step - loss: 0.2302 - lambda_1011_loss: 0.2638 - lambda_1016_loss: 0.2302 - val_loss: 0.1906 - val_lambda_1011_loss: 0.2221 - val_lambda_1016_loss: 0.1906\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1732 - lambda_1011_loss: 0.2039 - lambda_1016_loss: 0.1732 - val_loss: 0.1635 - val_lambda_1011_loss: 0.2076 - val_lambda_1016_loss: 0.1635\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1570 - lambda_1011_loss: 0.1868 - lambda_1016_loss: 0.1570 - val_loss: 0.1509 - val_lambda_1011_loss: 0.1788 - val_lambda_1016_loss: 0.1509\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1478 - lambda_1011_loss: 0.1775 - lambda_1016_loss: 0.1478 - val_loss: 0.1402 - val_lambda_1011_loss: 0.1732 - val_lambda_1016_loss: 0.1402\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1435 - lambda_1011_loss: 0.1729 - lambda_1016_loss: 0.1435 - val_loss: 0.1401 - val_lambda_1011_loss: 0.1666 - val_lambda_1016_loss: 0.1401\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1374 - lambda_1011_loss: 0.1654 - lambda_1016_loss: 0.1374 - val_loss: 0.1387 - val_lambda_1011_loss: 0.1620 - val_lambda_1016_loss: 0.1387\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1358 - lambda_1011_loss: 0.1638 - lambda_1016_loss: 0.1358 - val_loss: 0.1332 - val_lambda_1011_loss: 0.1586 - val_lambda_1016_loss: 0.1332\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1338 - lambda_1011_loss: 0.1621 - lambda_1016_loss: 0.1338 - val_loss: 0.1274 - val_lambda_1011_loss: 0.1530 - val_lambda_1016_loss: 0.1274\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1316 - lambda_1011_loss: 0.1592 - lambda_1016_loss: 0.1316 - val_loss: 0.1277 - val_lambda_1011_loss: 0.1533 - val_lambda_1016_loss: 0.1277\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1313 - lambda_1011_loss: 0.1592 - lambda_1016_loss: 0.1313 - val_loss: 0.1285 - val_lambda_1011_loss: 0.1593 - val_lambda_1016_loss: 0.1285\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1275 - lambda_1011_loss: 0.1540 - lambda_1016_loss: 0.1275 - val_loss: 0.1257 - val_lambda_1011_loss: 0.1607 - val_lambda_1016_loss: 0.1257\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1264 - lambda_1011_loss: 0.1527 - lambda_1016_loss: 0.1264 - val_loss: 0.1216 - val_lambda_1011_loss: 0.1515 - val_lambda_1016_loss: 0.1216\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1266 - lambda_1011_loss: 0.1535 - lambda_1016_loss: 0.1266 - val_loss: 0.1224 - val_lambda_1011_loss: 0.1533 - val_lambda_1016_loss: 0.1224\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 66s 99ms/step - loss: 0.1250 - lambda_1011_loss: 0.1516 - lambda_1016_loss: 0.1250 - val_loss: 0.1208 - val_lambda_1011_loss: 0.1503 - val_lambda_1016_loss: 0.1208\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1227 - lambda_1011_loss: 0.1482 - lambda_1016_loss: 0.1227 - val_loss: 0.1240 - val_lambda_1011_loss: 0.1513 - val_lambda_1016_loss: 0.1240\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1227 - lambda_1011_loss: 0.1483 - lambda_1016_loss: 0.1227 - val_loss: 0.1184 - val_lambda_1011_loss: 0.1440 - val_lambda_1016_loss: 0.1184\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1212 - lambda_1011_loss: 0.1463 - lambda_1016_loss: 0.1212 - val_loss: 0.1181 - val_lambda_1011_loss: 0.1438 - val_lambda_1016_loss: 0.1181\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1215 - lambda_1011_loss: 0.1468 - lambda_1016_loss: 0.1215 - val_loss: 0.1221 - val_lambda_1011_loss: 0.1494 - val_lambda_1016_loss: 0.1221\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1207 - lambda_1011_loss: 0.1458 - lambda_1016_loss: 0.1207 - val_loss: 0.1181 - val_lambda_1011_loss: 0.1387 - val_lambda_1016_loss: 0.1181\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1207 - lambda_1011_loss: 0.1461 - lambda_1016_loss: 0.1207 - val_loss: 0.1218 - val_lambda_1011_loss: 0.1486 - val_lambda_1016_loss: 0.1218\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1188 - lambda_1011_loss: 0.1441 - lambda_1016_loss: 0.1188 - val_loss: 0.1188 - val_lambda_1011_loss: 0.1430 - val_lambda_1016_loss: 0.1188\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1181 - lambda_1011_loss: 0.1425 - lambda_1016_loss: 0.1181 - val_loss: 0.1192 - val_lambda_1011_loss: 0.1494 - val_lambda_1016_loss: 0.1192\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1176 - lambda_1011_loss: 0.1421 - lambda_1016_loss: 0.1176 - val_loss: 0.1156 - val_lambda_1011_loss: 0.1404 - val_lambda_1016_loss: 0.1156\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1190 - lambda_1011_loss: 0.1443 - lambda_1016_loss: 0.1190 - val_loss: 0.1159 - val_lambda_1011_loss: 0.1462 - val_lambda_1016_loss: 0.1159\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1168 - lambda_1011_loss: 0.1412 - lambda_1016_loss: 0.1168 - val_loss: 0.1163 - val_lambda_1011_loss: 0.1489 - val_lambda_1016_loss: 0.1163\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1154 - lambda_1011_loss: 0.1391 - lambda_1016_loss: 0.1154 - val_loss: 0.1214 - val_lambda_1011_loss: 0.1432 - val_lambda_1016_loss: 0.1214\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1162 - lambda_1011_loss: 0.1401 - lambda_1016_loss: 0.1162 - val_loss: 0.1188 - val_lambda_1011_loss: 0.1412 - val_lambda_1016_loss: 0.1188\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1153 - lambda_1011_loss: 0.1393 - lambda_1016_loss: 0.1153 - val_loss: 0.1140 - val_lambda_1011_loss: 0.1395 - val_lambda_1016_loss: 0.1140\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1149 - lambda_1011_loss: 0.1388 - lambda_1016_loss: 0.1149 - val_loss: 0.1147 - val_lambda_1011_loss: 0.1392 - val_lambda_1016_loss: 0.1147\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1144 - lambda_1011_loss: 0.1380 - lambda_1016_loss: 0.1144 - val_loss: 0.1158 - val_lambda_1011_loss: 0.1432 - val_lambda_1016_loss: 0.1158\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1149 - lambda_1011_loss: 0.1390 - lambda_1016_loss: 0.1149 - val_loss: 0.1152 - val_lambda_1011_loss: 0.1409 - val_lambda_1016_loss: 0.1152\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1141 - lambda_1011_loss: 0.1376 - lambda_1016_loss: 0.1141 - val_loss: 0.1174 - val_lambda_1011_loss: 0.1384 - val_lambda_1016_loss: 0.1174\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1135 - lambda_1011_loss: 0.1372 - lambda_1016_loss: 0.1135 - val_loss: 0.1142 - val_lambda_1011_loss: 0.1407 - val_lambda_1016_loss: 0.1142\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1132 - lambda_1011_loss: 0.1366 - lambda_1016_loss: 0.1132 - val_loss: 0.1130 - val_lambda_1011_loss: 0.1424 - val_lambda_1016_loss: 0.1130\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1129 - lambda_1011_loss: 0.1363 - lambda_1016_loss: 0.1129 - val_loss: 0.1131 - val_lambda_1011_loss: 0.1393 - val_lambda_1016_loss: 0.1131\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1129 - lambda_1011_loss: 0.1360 - lambda_1016_loss: 0.1129 - val_loss: 0.1136 - val_lambda_1011_loss: 0.1441 - val_lambda_1016_loss: 0.1136\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1122 - lambda_1011_loss: 0.1358 - lambda_1016_loss: 0.1122 - val_loss: 0.1157 - val_lambda_1011_loss: 0.1408 - val_lambda_1016_loss: 0.1157\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1124 - lambda_1011_loss: 0.1357 - lambda_1016_loss: 0.1124 - val_loss: 0.1192 - val_lambda_1011_loss: 0.1456 - val_lambda_1016_loss: 0.1192\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1119 - lambda_1011_loss: 0.1352 - lambda_1016_loss: 0.1119 - val_loss: 0.1173 - val_lambda_1011_loss: 0.1452 - val_lambda_1016_loss: 0.1173\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1130 - lambda_1011_loss: 0.1361 - lambda_1016_loss: 0.1130 - val_loss: 0.1118 - val_lambda_1011_loss: 0.1409 - val_lambda_1016_loss: 0.1118\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1120 - lambda_1011_loss: 0.1353 - lambda_1016_loss: 0.1120 - val_loss: 0.1136 - val_lambda_1011_loss: 0.1380 - val_lambda_1016_loss: 0.1136\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1124 - lambda_1011_loss: 0.1357 - lambda_1016_loss: 0.1124 - val_loss: 0.1110 - val_lambda_1011_loss: 0.1335 - val_lambda_1016_loss: 0.1110\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1106 - lambda_1011_loss: 0.1333 - lambda_1016_loss: 0.1106 - val_loss: 0.1105 - val_lambda_1011_loss: 0.1370 - val_lambda_1016_loss: 0.1105\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1123 - lambda_1011_loss: 0.1357 - lambda_1016_loss: 0.1123 - val_loss: 0.1139 - val_lambda_1011_loss: 0.1408 - val_lambda_1016_loss: 0.1139\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1101 - lambda_1011_loss: 0.1330 - lambda_1016_loss: 0.1101 - val_loss: 0.1165 - val_lambda_1011_loss: 0.1424 - val_lambda_1016_loss: 0.1165\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 65s 97ms/step - loss: 0.1101 - lambda_1011_loss: 0.1329 - lambda_1016_loss: 0.1101 - val_loss: 0.1127 - val_lambda_1011_loss: 0.1337 - val_lambda_1016_loss: 0.1127\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 64s 96ms/step - loss: 0.1093 - lambda_1011_loss: 0.1318 - lambda_1016_loss: 0.1093 - val_loss: 0.1119 - val_lambda_1011_loss: 0.1380 - val_lambda_1016_loss: 0.1119\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 65s 98ms/step - loss: 0.1089 - lambda_1011_loss: 0.1310 - lambda_1016_loss: 0.1089 - val_loss: 0.1113 - val_lambda_1011_loss: 0.1333 - val_lambda_1016_loss: 0.1113\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1099 - lambda_1011_loss: 0.1323 - lambda_1016_loss: 0.1099 - val_loss: 0.1100 - val_lambda_1011_loss: 0.1366 - val_lambda_1016_loss: 0.1100\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 64s 97ms/step - loss: 0.1094 - lambda_1011_loss: 0.1316 - lambda_1016_loss: 0.1094 - val_loss: 0.1137 - val_lambda_1011_loss: 0.1357 - val_lambda_1016_loss: 0.1137\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 256, 256, 48) 912         input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 256, 256, 2)  98          conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_231 (Add)                   (None, 256, 256, 2)  0           conv2d_696[0][0]                 \n",
      "                                                                 input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_116 (Multiply)         (None, 256, 256, 2)  0           add_231[0][0]                    \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_232 (Add)                   (None, 256, 256, 2)  0           multiply_116[0][0]               \n",
      "                                                                 input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 256, 256, 48) 912         add_232[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_701 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 256, 256, 2)  98          conv2d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_233 (Add)                   (None, 256, 256, 2)  0           conv2d_702[0][0]                 \n",
      "                                                                 add_232[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_117 (Multiply)         (None, 256, 256, 2)  0           add_233[0][0]                    \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_234 (Add)                   (None, 256, 256, 2)  0           multiply_117[0][0]               \n",
      "                                                                 input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 256, 256, 48) 912         add_234[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 256, 256, 2)  98          conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_235 (Add)                   (None, 256, 256, 2)  0           conv2d_708[0][0]                 \n",
      "                                                                 add_234[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_118 (Multiply)         (None, 256, 256, 2)  0           add_235[0][0]                    \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_236 (Add)                   (None, 256, 256, 2)  0           multiply_118[0][0]               \n",
      "                                                                 input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1021 (Lambda)            (None, 256, 256, 2)  0           add_236[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1026 (Lambda)            (None, 256, 256, 1)  0           lambda_1021[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkk_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 95s 142ms/step - loss: 0.3403 - lambda_1021_loss: 0.4118 - lambda_1026_loss: 0.3403 - val_loss: 0.2820 - val_lambda_1021_loss: 0.3518 - val_lambda_1026_loss: 0.2820\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2816 - lambda_1021_loss: 0.3472 - lambda_1026_loss: 0.2816 - val_loss: 0.2840 - val_lambda_1021_loss: 0.3512 - val_lambda_1026_loss: 0.2840\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2630 - lambda_1021_loss: 0.3263 - lambda_1026_loss: 0.2630 - val_loss: 0.2431 - val_lambda_1021_loss: 0.3079 - val_lambda_1026_loss: 0.2431\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2522 - lambda_1021_loss: 0.3142 - lambda_1026_loss: 0.2522 - val_loss: 0.2465 - val_lambda_1021_loss: 0.3088 - val_lambda_1026_loss: 0.2465\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2478 - lambda_1021_loss: 0.3088 - lambda_1026_loss: 0.2478 - val_loss: 0.2360 - val_lambda_1021_loss: 0.2980 - val_lambda_1026_loss: 0.2360\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2399 - lambda_1021_loss: 0.3002 - lambda_1026_loss: 0.2399 - val_loss: 0.2322 - val_lambda_1021_loss: 0.2952 - val_lambda_1026_loss: 0.2322\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2352 - lambda_1021_loss: 0.2950 - lambda_1026_loss: 0.2352 - val_loss: 0.2316 - val_lambda_1021_loss: 0.2891 - val_lambda_1026_loss: 0.2316\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2349 - lambda_1021_loss: 0.2951 - lambda_1026_loss: 0.2349 - val_loss: 0.2241 - val_lambda_1021_loss: 0.2876 - val_lambda_1026_loss: 0.2241\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2310 - lambda_1021_loss: 0.2906 - lambda_1026_loss: 0.2310 - val_loss: 0.2197 - val_lambda_1021_loss: 0.2776 - val_lambda_1026_loss: 0.2197\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2263 - lambda_1021_loss: 0.2848 - lambda_1026_loss: 0.2263 - val_loss: 0.2305 - val_lambda_1021_loss: 0.2915 - val_lambda_1026_loss: 0.2305\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2250 - lambda_1021_loss: 0.2835 - lambda_1026_loss: 0.2250 - val_loss: 0.2313 - val_lambda_1021_loss: 0.2851 - val_lambda_1026_loss: 0.2313\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.2265 - lambda_1021_loss: 0.2851 - lambda_1026_loss: 0.2265 - val_loss: 0.2171 - val_lambda_1021_loss: 0.2748 - val_lambda_1026_loss: 0.2171\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.2228 - lambda_1021_loss: 0.2806 - lambda_1026_loss: 0.2228 - val_loss: 0.2153 - val_lambda_1021_loss: 0.2783 - val_lambda_1026_loss: 0.2153\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.2207 - lambda_1021_loss: 0.2787 - lambda_1026_loss: 0.2207 - val_loss: 0.2155 - val_lambda_1021_loss: 0.2712 - val_lambda_1026_loss: 0.2155\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2188 - lambda_1021_loss: 0.2763 - lambda_1026_loss: 0.2188 - val_loss: 0.2129 - val_lambda_1021_loss: 0.2686 - val_lambda_1026_loss: 0.2129\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2170 - lambda_1021_loss: 0.2747 - lambda_1026_loss: 0.2170 - val_loss: 0.2123 - val_lambda_1021_loss: 0.2723 - val_lambda_1026_loss: 0.2123\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2190 - lambda_1021_loss: 0.2768 - lambda_1026_loss: 0.2190 - val_loss: 0.2123 - val_lambda_1021_loss: 0.2706 - val_lambda_1026_loss: 0.2123\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2143 - lambda_1021_loss: 0.2710 - lambda_1026_loss: 0.2143 - val_loss: 0.2228 - val_lambda_1021_loss: 0.2864 - val_lambda_1026_loss: 0.2228\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2141 - lambda_1021_loss: 0.2714 - lambda_1026_loss: 0.2141 - val_loss: 0.2121 - val_lambda_1021_loss: 0.2718 - val_lambda_1026_loss: 0.2121\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2126 - lambda_1021_loss: 0.2689 - lambda_1026_loss: 0.2126 - val_loss: 0.2090 - val_lambda_1021_loss: 0.2684 - val_lambda_1026_loss: 0.2090\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2136 - lambda_1021_loss: 0.2705 - lambda_1026_loss: 0.2136 - val_loss: 0.2086 - val_lambda_1021_loss: 0.2672 - val_lambda_1026_loss: 0.2086\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2110 - lambda_1021_loss: 0.2677 - lambda_1026_loss: 0.2110 - val_loss: 0.2048 - val_lambda_1021_loss: 0.2611 - val_lambda_1026_loss: 0.2048\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2113 - lambda_1021_loss: 0.2677 - lambda_1026_loss: 0.2113 - val_loss: 0.2072 - val_lambda_1021_loss: 0.2676 - val_lambda_1026_loss: 0.2072\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2077 - lambda_1021_loss: 0.2643 - lambda_1026_loss: 0.2077 - val_loss: 0.2024 - val_lambda_1021_loss: 0.2602 - val_lambda_1026_loss: 0.2024\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2074 - lambda_1021_loss: 0.2638 - lambda_1026_loss: 0.2074 - val_loss: 0.2034 - val_lambda_1021_loss: 0.2613 - val_lambda_1026_loss: 0.2034\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2081 - lambda_1021_loss: 0.2644 - lambda_1026_loss: 0.2081 - val_loss: 0.2028 - val_lambda_1021_loss: 0.2588 - val_lambda_1026_loss: 0.2028\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2085 - lambda_1021_loss: 0.2647 - lambda_1026_loss: 0.2085 - val_loss: 0.2020 - val_lambda_1021_loss: 0.2588 - val_lambda_1026_loss: 0.2020\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.2065 - lambda_1021_loss: 0.2627 - lambda_1026_loss: 0.2065 - val_loss: 0.2040 - val_lambda_1021_loss: 0.2617 - val_lambda_1026_loss: 0.2040\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.2066 - lambda_1021_loss: 0.2621 - lambda_1026_loss: 0.2066 - val_loss: 0.2000 - val_lambda_1021_loss: 0.2589 - val_lambda_1026_loss: 0.2000\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2050 - lambda_1021_loss: 0.2609 - lambda_1026_loss: 0.2050 - val_loss: 0.2031 - val_lambda_1021_loss: 0.2610 - val_lambda_1026_loss: 0.2031\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2052 - lambda_1021_loss: 0.2608 - lambda_1026_loss: 0.2052 - val_loss: 0.2014 - val_lambda_1021_loss: 0.2575 - val_lambda_1026_loss: 0.2014\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2029 - lambda_1021_loss: 0.2588 - lambda_1026_loss: 0.2029 - val_loss: 0.2052 - val_lambda_1021_loss: 0.2620 - val_lambda_1026_loss: 0.2052\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2049 - lambda_1021_loss: 0.2606 - lambda_1026_loss: 0.2049 - val_loss: 0.2056 - val_lambda_1021_loss: 0.2619 - val_lambda_1026_loss: 0.2056\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2036 - lambda_1021_loss: 0.2594 - lambda_1026_loss: 0.2036 - val_loss: 0.1970 - val_lambda_1021_loss: 0.2477 - val_lambda_1026_loss: 0.1970\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2015 - lambda_1021_loss: 0.2570 - lambda_1026_loss: 0.2015 - val_loss: 0.1999 - val_lambda_1021_loss: 0.2517 - val_lambda_1026_loss: 0.1999\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2033 - lambda_1021_loss: 0.2590 - lambda_1026_loss: 0.2033 - val_loss: 0.1949 - val_lambda_1021_loss: 0.2489 - val_lambda_1026_loss: 0.1949\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2012 - lambda_1021_loss: 0.2563 - lambda_1026_loss: 0.2012 - val_loss: 0.1989 - val_lambda_1021_loss: 0.2554 - val_lambda_1026_loss: 0.1989\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1997 - lambda_1021_loss: 0.2549 - lambda_1026_loss: 0.1997 - val_loss: 0.1955 - val_lambda_1021_loss: 0.2493 - val_lambda_1026_loss: 0.1955\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.2000 - lambda_1021_loss: 0.2546 - lambda_1026_loss: 0.2000 - val_loss: 0.1945 - val_lambda_1021_loss: 0.2479 - val_lambda_1026_loss: 0.1945\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1980 - lambda_1021_loss: 0.2531 - lambda_1026_loss: 0.1980 - val_loss: 0.1979 - val_lambda_1021_loss: 0.2529 - val_lambda_1026_loss: 0.1979\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 82s 124ms/step - loss: 0.1978 - lambda_1021_loss: 0.2527 - lambda_1026_loss: 0.1978 - val_loss: 0.1982 - val_lambda_1021_loss: 0.2547 - val_lambda_1026_loss: 0.1982\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 82s 123ms/step - loss: 0.1987 - lambda_1021_loss: 0.2535 - lambda_1026_loss: 0.1987 - val_loss: 0.1921 - val_lambda_1021_loss: 0.2457 - val_lambda_1026_loss: 0.1921\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1983 - lambda_1021_loss: 0.2533 - lambda_1026_loss: 0.1983 - val_loss: 0.1912 - val_lambda_1021_loss: 0.2445 - val_lambda_1026_loss: 0.1912\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1977 - lambda_1021_loss: 0.2522 - lambda_1026_loss: 0.1977 - val_loss: 0.2000 - val_lambda_1021_loss: 0.2542 - val_lambda_1026_loss: 0.2000\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1974 - lambda_1021_loss: 0.2519 - lambda_1026_loss: 0.1974 - val_loss: 0.1958 - val_lambda_1021_loss: 0.2516 - val_lambda_1026_loss: 0.1958\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1970 - lambda_1021_loss: 0.2517 - lambda_1026_loss: 0.1970 - val_loss: 0.1919 - val_lambda_1021_loss: 0.2501 - val_lambda_1026_loss: 0.1919\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1960 - lambda_1021_loss: 0.2507 - lambda_1026_loss: 0.1960 - val_loss: 0.1921 - val_lambda_1021_loss: 0.2454 - val_lambda_1026_loss: 0.1921\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1953 - lambda_1021_loss: 0.2496 - lambda_1026_loss: 0.1953 - val_loss: 0.1901 - val_lambda_1021_loss: 0.2449 - val_lambda_1026_loss: 0.1901\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1942 - lambda_1021_loss: 0.2484 - lambda_1026_loss: 0.1942 - val_loss: 0.1956 - val_lambda_1021_loss: 0.2468 - val_lambda_1026_loss: 0.1956\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 83s 124ms/step - loss: 0.1953 - lambda_1021_loss: 0.2497 - lambda_1026_loss: 0.1953 - val_loss: 0.1931 - val_lambda_1021_loss: 0.2469 - val_lambda_1026_loss: 0.1931\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 256, 256, 48) 912         input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 256, 256, 2)  98          conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_237 (Add)                   (None, 256, 256, 2)  0           conv2d_714[0][0]                 \n",
      "                                                                 input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_119 (Multiply)         (None, 256, 256, 2)  0           add_237[0][0]                    \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_238 (Add)                   (None, 256, 256, 2)  0           multiply_119[0][0]               \n",
      "                                                                 input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1031 (Lambda)            (None, 256, 256, 2)  0           add_238[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 256, 256, 48) 912         lambda_1031[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_720 (Conv2D)             (None, 256, 256, 2)  98          conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_239 (Add)                   (None, 256, 256, 2)  0           conv2d_720[0][0]                 \n",
      "                                                                 lambda_1031[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1036 (Lambda)            (None, 256, 256, 2)  0           add_239[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_120 (Multiply)         (None, 256, 256, 2)  0           lambda_1036[0][0]                \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_240 (Add)                   (None, 256, 256, 2)  0           multiply_120[0][0]               \n",
      "                                                                 input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1041 (Lambda)            (None, 256, 256, 2)  0           add_240[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_721 (Conv2D)             (None, 256, 256, 48) 912         lambda_1041[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_722 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_723 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_722[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_724 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_723[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_725 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_724[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_726 (Conv2D)             (None, 256, 256, 2)  98          conv2d_725[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_241 (Add)                   (None, 256, 256, 2)  0           conv2d_726[0][0]                 \n",
      "                                                                 lambda_1041[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1046 (Lambda)            (None, 256, 256, 2)  0           add_241[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_121 (Multiply)         (None, 256, 256, 2)  0           lambda_1046[0][0]                \n",
      "                                                                 input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_242 (Add)                   (None, 256, 256, 2)  0           multiply_121[0][0]               \n",
      "                                                                 input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1051 (Lambda)            (None, 256, 256, 2)  0           add_242[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1056 (Lambda)            (None, 256, 256, 1)  0           lambda_1051[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 96s 144ms/step - loss: 0.1711 - lambda_1051_loss: 0.1973 - lambda_1056_loss: 0.1711 - val_loss: 0.1258 - val_lambda_1051_loss: 0.1435 - val_lambda_1056_loss: 0.1258\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1219 - lambda_1051_loss: 0.1447 - lambda_1056_loss: 0.1219 - val_loss: 0.1263 - val_lambda_1051_loss: 0.1419 - val_lambda_1056_loss: 0.1263\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1137 - lambda_1051_loss: 0.1340 - lambda_1056_loss: 0.1137 - val_loss: 0.1227 - val_lambda_1051_loss: 0.1407 - val_lambda_1056_loss: 0.1227\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1043 - lambda_1051_loss: 0.1232 - lambda_1056_loss: 0.1043 - val_loss: 0.1070 - val_lambda_1051_loss: 0.1252 - val_lambda_1056_loss: 0.1070\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1016 - lambda_1051_loss: 0.1201 - lambda_1056_loss: 0.1016 - val_loss: 0.1015 - val_lambda_1051_loss: 0.1280 - val_lambda_1056_loss: 0.1015\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1035 - lambda_1051_loss: 0.1220 - lambda_1056_loss: 0.1035 - val_loss: 0.0961 - val_lambda_1051_loss: 0.1109 - val_lambda_1056_loss: 0.0961\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0954 - lambda_1051_loss: 0.1121 - lambda_1056_loss: 0.0954 - val_loss: 0.0962 - val_lambda_1051_loss: 0.1143 - val_lambda_1056_loss: 0.0962\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0947 - lambda_1051_loss: 0.1113 - lambda_1056_loss: 0.0947 - val_loss: 0.0958 - val_lambda_1051_loss: 0.1162 - val_lambda_1056_loss: 0.0958\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0927 - lambda_1051_loss: 0.1092 - lambda_1056_loss: 0.0927 - val_loss: 0.0985 - val_lambda_1051_loss: 0.1197 - val_lambda_1056_loss: 0.0985\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0907 - lambda_1051_loss: 0.1070 - lambda_1056_loss: 0.0907 - val_loss: 0.0927 - val_lambda_1051_loss: 0.1085 - val_lambda_1056_loss: 0.0927\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0897 - lambda_1051_loss: 0.1057 - lambda_1056_loss: 0.0897 - val_loss: 0.0954 - val_lambda_1051_loss: 0.1131 - val_lambda_1056_loss: 0.0954\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0891 - lambda_1051_loss: 0.1051 - lambda_1056_loss: 0.0891 - val_loss: 0.0963 - val_lambda_1051_loss: 0.1130 - val_lambda_1056_loss: 0.0963\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0877 - lambda_1051_loss: 0.1035 - lambda_1056_loss: 0.0877 - val_loss: 0.0953 - val_lambda_1051_loss: 0.1223 - val_lambda_1056_loss: 0.0953\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0871 - lambda_1051_loss: 0.1025 - lambda_1056_loss: 0.0871 - val_loss: 0.0939 - val_lambda_1051_loss: 0.1131 - val_lambda_1056_loss: 0.0939\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0867 - lambda_1051_loss: 0.1024 - lambda_1056_loss: 0.0867 - val_loss: 0.0987 - val_lambda_1051_loss: 0.1194 - val_lambda_1056_loss: 0.0987\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0840 - lambda_1051_loss: 0.0988 - lambda_1056_loss: 0.0840 - val_loss: 0.0955 - val_lambda_1051_loss: 0.1146 - val_lambda_1056_loss: 0.0955\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0837 - lambda_1051_loss: 0.0988 - lambda_1056_loss: 0.0837 - val_loss: 0.0935 - val_lambda_1051_loss: 0.1116 - val_lambda_1056_loss: 0.0935\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0838 - lambda_1051_loss: 0.0990 - lambda_1056_loss: 0.0838 - val_loss: 0.0868 - val_lambda_1051_loss: 0.1028 - val_lambda_1056_loss: 0.0868\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0831 - lambda_1051_loss: 0.0986 - lambda_1056_loss: 0.0831 - val_loss: 0.0929 - val_lambda_1051_loss: 0.1061 - val_lambda_1056_loss: 0.0929\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0812 - lambda_1051_loss: 0.0973 - lambda_1056_loss: 0.0812 - val_loss: 0.0946 - val_lambda_1051_loss: 0.1203 - val_lambda_1056_loss: 0.0946\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0803 - lambda_1051_loss: 0.0963 - lambda_1056_loss: 0.0803 - val_loss: 0.0885 - val_lambda_1051_loss: 0.1051 - val_lambda_1056_loss: 0.0885\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0792 - lambda_1051_loss: 0.0944 - lambda_1056_loss: 0.0792 - val_loss: 0.0838 - val_lambda_1051_loss: 0.1005 - val_lambda_1056_loss: 0.0838\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0784 - lambda_1051_loss: 0.0936 - lambda_1056_loss: 0.0784 - val_loss: 0.0833 - val_lambda_1051_loss: 0.0984 - val_lambda_1056_loss: 0.0833\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0781 - lambda_1051_loss: 0.0931 - lambda_1056_loss: 0.0781 - val_loss: 0.0819 - val_lambda_1051_loss: 0.0958 - val_lambda_1056_loss: 0.0819\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0766 - lambda_1051_loss: 0.0908 - lambda_1056_loss: 0.0766 - val_loss: 0.0822 - val_lambda_1051_loss: 0.0989 - val_lambda_1056_loss: 0.0822\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0764 - lambda_1051_loss: 0.0909 - lambda_1056_loss: 0.0764 - val_loss: 0.0805 - val_lambda_1051_loss: 0.0959 - val_lambda_1056_loss: 0.0805\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0754 - lambda_1051_loss: 0.0892 - lambda_1056_loss: 0.0754 - val_loss: 0.0837 - val_lambda_1051_loss: 0.0981 - val_lambda_1056_loss: 0.0837\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0738 - lambda_1051_loss: 0.0874 - lambda_1056_loss: 0.0738 - val_loss: 0.0818 - val_lambda_1051_loss: 0.0943 - val_lambda_1056_loss: 0.0818\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0746 - lambda_1051_loss: 0.0893 - lambda_1056_loss: 0.0746 - val_loss: 0.0835 - val_lambda_1051_loss: 0.0986 - val_lambda_1056_loss: 0.0835\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0745 - lambda_1051_loss: 0.0881 - lambda_1056_loss: 0.0745 - val_loss: 0.0803 - val_lambda_1051_loss: 0.0932 - val_lambda_1056_loss: 0.0803\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0752 - lambda_1051_loss: 0.0891 - lambda_1056_loss: 0.0752 - val_loss: 0.0803 - val_lambda_1051_loss: 0.0943 - val_lambda_1056_loss: 0.0803\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0724 - lambda_1051_loss: 0.0860 - lambda_1056_loss: 0.0724 - val_loss: 0.0767 - val_lambda_1051_loss: 0.0932 - val_lambda_1056_loss: 0.0767\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0733 - lambda_1051_loss: 0.0871 - lambda_1056_loss: 0.0733 - val_loss: 0.0781 - val_lambda_1051_loss: 0.1017 - val_lambda_1056_loss: 0.0781\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0739 - lambda_1051_loss: 0.0880 - lambda_1056_loss: 0.0739 - val_loss: 0.0780 - val_lambda_1051_loss: 0.0892 - val_lambda_1056_loss: 0.0780\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0729 - lambda_1051_loss: 0.0872 - lambda_1056_loss: 0.0729 - val_loss: 0.0826 - val_lambda_1051_loss: 0.0995 - val_lambda_1056_loss: 0.0826\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0722 - lambda_1051_loss: 0.0854 - lambda_1056_loss: 0.0722 - val_loss: 0.0764 - val_lambda_1051_loss: 0.1037 - val_lambda_1056_loss: 0.0764\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0723 - lambda_1051_loss: 0.0865 - lambda_1056_loss: 0.0723 - val_loss: 0.0804 - val_lambda_1051_loss: 0.0915 - val_lambda_1056_loss: 0.0804\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0709 - lambda_1051_loss: 0.0837 - lambda_1056_loss: 0.0709 - val_loss: 0.0799 - val_lambda_1051_loss: 0.0953 - val_lambda_1056_loss: 0.0799\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0712 - lambda_1051_loss: 0.0844 - lambda_1056_loss: 0.0712 - val_loss: 0.0765 - val_lambda_1051_loss: 0.0856 - val_lambda_1056_loss: 0.0765\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0707 - lambda_1051_loss: 0.0838 - lambda_1056_loss: 0.0707 - val_loss: 0.0775 - val_lambda_1051_loss: 0.0944 - val_lambda_1056_loss: 0.0775\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0704 - lambda_1051_loss: 0.0835 - lambda_1056_loss: 0.0704 - val_loss: 0.0782 - val_lambda_1051_loss: 0.0918 - val_lambda_1056_loss: 0.0782\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0704 - lambda_1051_loss: 0.0832 - lambda_1056_loss: 0.0704 - val_loss: 0.0768 - val_lambda_1051_loss: 0.0887 - val_lambda_1056_loss: 0.0768\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0700 - lambda_1051_loss: 0.0829 - lambda_1056_loss: 0.0700 - val_loss: 0.0770 - val_lambda_1051_loss: 0.0896 - val_lambda_1056_loss: 0.0770\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0702 - lambda_1051_loss: 0.0831 - lambda_1056_loss: 0.0702 - val_loss: 0.0796 - val_lambda_1051_loss: 0.1051 - val_lambda_1056_loss: 0.0796\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0699 - lambda_1051_loss: 0.0826 - lambda_1056_loss: 0.0699 - val_loss: 0.0799 - val_lambda_1051_loss: 0.0911 - val_lambda_1056_loss: 0.0799\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0693 - lambda_1051_loss: 0.0815 - lambda_1056_loss: 0.0693 - val_loss: 0.0767 - val_lambda_1051_loss: 0.0889 - val_lambda_1056_loss: 0.0767\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0697 - lambda_1051_loss: 0.0821 - lambda_1056_loss: 0.0697 - val_loss: 0.0753 - val_lambda_1051_loss: 0.0929 - val_lambda_1056_loss: 0.0753\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0700 - lambda_1051_loss: 0.0827 - lambda_1056_loss: 0.0700 - val_loss: 0.0802 - val_lambda_1051_loss: 0.0999 - val_lambda_1056_loss: 0.0802\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0688 - lambda_1051_loss: 0.0811 - lambda_1056_loss: 0.0688 - val_loss: 0.0761 - val_lambda_1051_loss: 0.0886 - val_lambda_1056_loss: 0.0761\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0685 - lambda_1051_loss: 0.0806 - lambda_1056_loss: 0.0685 - val_loss: 0.0784 - val_lambda_1051_loss: 0.0969 - val_lambda_1056_loss: 0.0784\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_81 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_727 (Conv2D)             (None, 256, 256, 48) 912         input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_728 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_727[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_729 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_728[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_730 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_729[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_731 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_730[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_732 (Conv2D)             (None, 256, 256, 2)  98          conv2d_731[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_243 (Add)                   (None, 256, 256, 2)  0           conv2d_732[0][0]                 \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_122 (Multiply)         (None, 256, 256, 2)  0           add_243[0][0]                    \n",
      "                                                                 input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_244 (Add)                   (None, 256, 256, 2)  0           multiply_122[0][0]               \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1061 (Lambda)            (None, 256, 256, 2)  0           add_244[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_733 (Conv2D)             (None, 256, 256, 48) 912         lambda_1061[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_734 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_733[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_735 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_734[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_736 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_735[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_737 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_736[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_738 (Conv2D)             (None, 256, 256, 2)  98          conv2d_737[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_245 (Add)                   (None, 256, 256, 2)  0           conv2d_738[0][0]                 \n",
      "                                                                 lambda_1061[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1066 (Lambda)            (None, 256, 256, 2)  0           add_245[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_123 (Multiply)         (None, 256, 256, 2)  0           lambda_1066[0][0]                \n",
      "                                                                 input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_246 (Add)                   (None, 256, 256, 2)  0           multiply_123[0][0]               \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_739 (Conv2D)             (None, 256, 256, 48) 912         add_246[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_740 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_739[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_741 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_740[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_742 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_743 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_742[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_744 (Conv2D)             (None, 256, 256, 2)  98          conv2d_743[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_247 (Add)                   (None, 256, 256, 2)  0           conv2d_744[0][0]                 \n",
      "                                                                 add_246[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_124 (Multiply)         (None, 256, 256, 2)  0           add_247[0][0]                    \n",
      "                                                                 input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_248 (Add)                   (None, 256, 256, 2)  0           multiply_124[0][0]               \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1071 (Lambda)            (None, 256, 256, 2)  0           add_248[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1076 (Lambda)            (None, 256, 256, 1)  0           lambda_1071[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 96s 144ms/step - loss: 0.2189 - lambda_1071_loss: 0.2588 - lambda_1076_loss: 0.2189 - val_loss: 0.1864 - val_lambda_1071_loss: 0.2275 - val_lambda_1076_loss: 0.1864\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1660 - lambda_1071_loss: 0.1999 - lambda_1076_loss: 0.1660 - val_loss: 0.1484 - val_lambda_1071_loss: 0.1776 - val_lambda_1076_loss: 0.1484\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1478 - lambda_1071_loss: 0.1805 - lambda_1076_loss: 0.1478 - val_loss: 0.1418 - val_lambda_1071_loss: 0.1786 - val_lambda_1076_loss: 0.1418\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1415 - lambda_1071_loss: 0.1729 - lambda_1076_loss: 0.1415 - val_loss: 0.1346 - val_lambda_1071_loss: 0.1705 - val_lambda_1076_loss: 0.1346\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1337 - lambda_1071_loss: 0.1633 - lambda_1076_loss: 0.1337 - val_loss: 0.1295 - val_lambda_1071_loss: 0.1587 - val_lambda_1076_loss: 0.1295\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1315 - lambda_1071_loss: 0.1607 - lambda_1076_loss: 0.1315 - val_loss: 0.1257 - val_lambda_1071_loss: 0.1597 - val_lambda_1076_loss: 0.1257\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1274 - lambda_1071_loss: 0.1560 - lambda_1076_loss: 0.1274 - val_loss: 0.1295 - val_lambda_1071_loss: 0.1593 - val_lambda_1076_loss: 0.1295\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1241 - lambda_1071_loss: 0.1516 - lambda_1076_loss: 0.1241 - val_loss: 0.1216 - val_lambda_1071_loss: 0.1475 - val_lambda_1076_loss: 0.1216\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1212 - lambda_1071_loss: 0.1482 - lambda_1076_loss: 0.1212 - val_loss: 0.1198 - val_lambda_1071_loss: 0.1533 - val_lambda_1076_loss: 0.1198\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1211 - lambda_1071_loss: 0.1484 - lambda_1076_loss: 0.1211 - val_loss: 0.1245 - val_lambda_1071_loss: 0.1455 - val_lambda_1076_loss: 0.1245\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1180 - lambda_1071_loss: 0.1442 - lambda_1076_loss: 0.1180 - val_loss: 0.1301 - val_lambda_1071_loss: 0.1584 - val_lambda_1076_loss: 0.1301\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1170 - lambda_1071_loss: 0.1435 - lambda_1076_loss: 0.1170 - val_loss: 0.1180 - val_lambda_1071_loss: 0.1426 - val_lambda_1076_loss: 0.1180\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1167 - lambda_1071_loss: 0.1432 - lambda_1076_loss: 0.1167 - val_loss: 0.1257 - val_lambda_1071_loss: 0.1523 - val_lambda_1076_loss: 0.1257\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1154 - lambda_1071_loss: 0.1412 - lambda_1076_loss: 0.1154 - val_loss: 0.1149 - val_lambda_1071_loss: 0.1382 - val_lambda_1076_loss: 0.1149\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1136 - lambda_1071_loss: 0.1390 - lambda_1076_loss: 0.1136 - val_loss: 0.1125 - val_lambda_1071_loss: 0.1359 - val_lambda_1076_loss: 0.1125\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1123 - lambda_1071_loss: 0.1376 - lambda_1076_loss: 0.1123 - val_loss: 0.1168 - val_lambda_1071_loss: 0.1407 - val_lambda_1076_loss: 0.1168\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1109 - lambda_1071_loss: 0.1358 - lambda_1076_loss: 0.1109 - val_loss: 0.1088 - val_lambda_1071_loss: 0.1328 - val_lambda_1076_loss: 0.1088\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1110 - lambda_1071_loss: 0.1359 - lambda_1076_loss: 0.1110 - val_loss: 0.1118 - val_lambda_1071_loss: 0.1366 - val_lambda_1076_loss: 0.1118\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1102 - lambda_1071_loss: 0.1349 - lambda_1076_loss: 0.1102 - val_loss: 0.1123 - val_lambda_1071_loss: 0.1373 - val_lambda_1076_loss: 0.1123\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1095 - lambda_1071_loss: 0.1341 - lambda_1076_loss: 0.1095 - val_loss: 0.1154 - val_lambda_1071_loss: 0.1384 - val_lambda_1076_loss: 0.1154\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1090 - lambda_1071_loss: 0.1332 - lambda_1076_loss: 0.1090 - val_loss: 0.1118 - val_lambda_1071_loss: 0.1441 - val_lambda_1076_loss: 0.1118\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1078 - lambda_1071_loss: 0.1320 - lambda_1076_loss: 0.1078 - val_loss: 0.1088 - val_lambda_1071_loss: 0.1387 - val_lambda_1076_loss: 0.1088\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1065 - lambda_1071_loss: 0.1304 - lambda_1076_loss: 0.1065 - val_loss: 0.1170 - val_lambda_1071_loss: 0.1358 - val_lambda_1076_loss: 0.1170\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1071 - lambda_1071_loss: 0.1306 - lambda_1076_loss: 0.1071 - val_loss: 0.1079 - val_lambda_1071_loss: 0.1316 - val_lambda_1076_loss: 0.1079\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1062 - lambda_1071_loss: 0.1300 - lambda_1076_loss: 0.1062 - val_loss: 0.1055 - val_lambda_1071_loss: 0.1280 - val_lambda_1076_loss: 0.1055\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1050 - lambda_1071_loss: 0.1284 - lambda_1076_loss: 0.1050 - val_loss: 0.1121 - val_lambda_1071_loss: 0.1340 - val_lambda_1076_loss: 0.1121\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1046 - lambda_1071_loss: 0.1275 - lambda_1076_loss: 0.1046 - val_loss: 0.1152 - val_lambda_1071_loss: 0.1380 - val_lambda_1076_loss: 0.1152\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1046 - lambda_1071_loss: 0.1275 - lambda_1076_loss: 0.1046 - val_loss: 0.1164 - val_lambda_1071_loss: 0.1393 - val_lambda_1076_loss: 0.1164\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1050 - lambda_1071_loss: 0.1286 - lambda_1076_loss: 0.1050 - val_loss: 0.1048 - val_lambda_1071_loss: 0.1266 - val_lambda_1076_loss: 0.1048\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1032 - lambda_1071_loss: 0.1260 - lambda_1076_loss: 0.1032 - val_loss: 0.1144 - val_lambda_1071_loss: 0.1364 - val_lambda_1076_loss: 0.1144\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1031 - lambda_1071_loss: 0.1259 - lambda_1076_loss: 0.1031 - val_loss: 0.1089 - val_lambda_1071_loss: 0.1306 - val_lambda_1076_loss: 0.1089\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1036 - lambda_1071_loss: 0.1268 - lambda_1076_loss: 0.1036 - val_loss: 0.1139 - val_lambda_1071_loss: 0.1384 - val_lambda_1076_loss: 0.1139\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1028 - lambda_1071_loss: 0.1258 - lambda_1076_loss: 0.1028 - val_loss: 0.1078 - val_lambda_1071_loss: 0.1301 - val_lambda_1076_loss: 0.1078\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1026 - lambda_1071_loss: 0.1254 - lambda_1076_loss: 0.1026 - val_loss: 0.1078 - val_lambda_1071_loss: 0.1287 - val_lambda_1076_loss: 0.1078\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1020 - lambda_1071_loss: 0.1246 - lambda_1076_loss: 0.1020 - val_loss: 0.1077 - val_lambda_1071_loss: 0.1265 - val_lambda_1076_loss: 0.1077\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1011 - lambda_1071_loss: 0.1233 - lambda_1076_loss: 0.1011 - val_loss: 0.1049 - val_lambda_1071_loss: 0.1234 - val_lambda_1076_loss: 0.1049\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1009 - lambda_1071_loss: 0.1231 - lambda_1076_loss: 0.1009 - val_loss: 0.1069 - val_lambda_1071_loss: 0.1285 - val_lambda_1076_loss: 0.1069\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1011 - lambda_1071_loss: 0.1232 - lambda_1076_loss: 0.1011 - val_loss: 0.1073 - val_lambda_1071_loss: 0.1288 - val_lambda_1076_loss: 0.1073\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1008 - lambda_1071_loss: 0.1230 - lambda_1076_loss: 0.1008 - val_loss: 0.1025 - val_lambda_1071_loss: 0.1248 - val_lambda_1076_loss: 0.1025\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1004 - lambda_1071_loss: 0.1227 - lambda_1076_loss: 0.1004 - val_loss: 0.1043 - val_lambda_1071_loss: 0.1282 - val_lambda_1076_loss: 0.1043\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0998 - lambda_1071_loss: 0.1216 - lambda_1076_loss: 0.0998 - val_loss: 0.1045 - val_lambda_1071_loss: 0.1268 - val_lambda_1076_loss: 0.1045\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1004 - lambda_1071_loss: 0.1225 - lambda_1076_loss: 0.1004 - val_loss: 0.1061 - val_lambda_1071_loss: 0.1254 - val_lambda_1076_loss: 0.1061\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0989 - lambda_1071_loss: 0.1206 - lambda_1076_loss: 0.0989 - val_loss: 0.1041 - val_lambda_1071_loss: 0.1249 - val_lambda_1076_loss: 0.1041\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0999 - lambda_1071_loss: 0.1216 - lambda_1076_loss: 0.0999 - val_loss: 0.1040 - val_lambda_1071_loss: 0.1234 - val_lambda_1076_loss: 0.1040\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.0992 - lambda_1071_loss: 0.1210 - lambda_1076_loss: 0.0992 - val_loss: 0.1046 - val_lambda_1071_loss: 0.1277 - val_lambda_1076_loss: 0.1046\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.0989 - lambda_1071_loss: 0.1205 - lambda_1076_loss: 0.0989 - val_loss: 0.1002 - val_lambda_1071_loss: 0.1202 - val_lambda_1076_loss: 0.1002\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.0980 - lambda_1071_loss: 0.1193 - lambda_1076_loss: 0.0980 - val_loss: 0.0989 - val_lambda_1071_loss: 0.1193 - val_lambda_1076_loss: 0.0989\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.0986 - lambda_1071_loss: 0.1201 - lambda_1076_loss: 0.0986 - val_loss: 0.1105 - val_lambda_1071_loss: 0.1329 - val_lambda_1076_loss: 0.1105\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.0985 - lambda_1071_loss: 0.1202 - lambda_1076_loss: 0.0985 - val_loss: 0.1002 - val_lambda_1071_loss: 0.1199 - val_lambda_1076_loss: 0.1002\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.0979 - lambda_1071_loss: 0.1191 - lambda_1076_loss: 0.0979 - val_loss: 0.1010 - val_lambda_1071_loss: 0.1233 - val_lambda_1076_loss: 0.1010\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_83 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_745 (Conv2D)             (None, 256, 256, 48) 912         input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_746 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_745[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_747 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_748 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_747[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_749 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_750 (Conv2D)             (None, 256, 256, 2)  98          conv2d_749[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_249 (Add)                   (None, 256, 256, 2)  0           conv2d_750[0][0]                 \n",
      "                                                                 input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_125 (Multiply)         (None, 256, 256, 2)  0           add_249[0][0]                    \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_250 (Add)                   (None, 256, 256, 2)  0           multiply_125[0][0]               \n",
      "                                                                 input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_751 (Conv2D)             (None, 256, 256, 48) 912         add_250[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_752 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_753 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_752[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_754 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_753[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_755 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_754[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_756 (Conv2D)             (None, 256, 256, 2)  98          conv2d_755[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_251 (Add)                   (None, 256, 256, 2)  0           conv2d_756[0][0]                 \n",
      "                                                                 add_250[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_126 (Multiply)         (None, 256, 256, 2)  0           add_251[0][0]                    \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_252 (Add)                   (None, 256, 256, 2)  0           multiply_126[0][0]               \n",
      "                                                                 input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1081 (Lambda)            (None, 256, 256, 2)  0           add_252[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)             (None, 256, 256, 48) 912         lambda_1081[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_757[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_758[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_760 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_759[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_761 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_760[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_762 (Conv2D)             (None, 256, 256, 2)  98          conv2d_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_253 (Add)                   (None, 256, 256, 2)  0           conv2d_762[0][0]                 \n",
      "                                                                 lambda_1081[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1086 (Lambda)            (None, 256, 256, 2)  0           add_253[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_127 (Multiply)         (None, 256, 256, 2)  0           lambda_1086[0][0]                \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_254 (Add)                   (None, 256, 256, 2)  0           multiply_127[0][0]               \n",
      "                                                                 input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1091 (Lambda)            (None, 256, 256, 2)  0           add_254[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1096 (Lambda)            (None, 256, 256, 1)  0           lambda_1091[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kki_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 97s 145ms/step - loss: 0.2243 - lambda_1091_loss: 0.2576 - lambda_1096_loss: 0.2243 - val_loss: 0.1748 - val_lambda_1091_loss: 0.2123 - val_lambda_1096_loss: 0.1748\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1654 - lambda_1091_loss: 0.1954 - lambda_1096_loss: 0.1654 - val_loss: 0.1660 - val_lambda_1091_loss: 0.2005 - val_lambda_1096_loss: 0.1660\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1515 - lambda_1091_loss: 0.1795 - lambda_1096_loss: 0.1515 - val_loss: 0.1599 - val_lambda_1091_loss: 0.2004 - val_lambda_1096_loss: 0.1599\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1421 - lambda_1091_loss: 0.1692 - lambda_1096_loss: 0.1421 - val_loss: 0.1470 - val_lambda_1091_loss: 0.1693 - val_lambda_1096_loss: 0.1470\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1375 - lambda_1091_loss: 0.1642 - lambda_1096_loss: 0.1375 - val_loss: 0.1465 - val_lambda_1091_loss: 0.1740 - val_lambda_1096_loss: 0.1465\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1340 - lambda_1091_loss: 0.1599 - lambda_1096_loss: 0.1340 - val_loss: 0.1304 - val_lambda_1091_loss: 0.1709 - val_lambda_1096_loss: 0.1304\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1313 - lambda_1091_loss: 0.1572 - lambda_1096_loss: 0.1313 - val_loss: 0.1252 - val_lambda_1091_loss: 0.1482 - val_lambda_1096_loss: 0.1252\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1282 - lambda_1091_loss: 0.1536 - lambda_1096_loss: 0.1282 - val_loss: 0.1224 - val_lambda_1091_loss: 0.1489 - val_lambda_1096_loss: 0.1224\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1257 - lambda_1091_loss: 0.1505 - lambda_1096_loss: 0.1257 - val_loss: 0.1219 - val_lambda_1091_loss: 0.1473 - val_lambda_1096_loss: 0.1219\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1262 - lambda_1091_loss: 0.1519 - lambda_1096_loss: 0.1262 - val_loss: 0.1183 - val_lambda_1091_loss: 0.1425 - val_lambda_1096_loss: 0.1183\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1218 - lambda_1091_loss: 0.1453 - lambda_1096_loss: 0.1218 - val_loss: 0.1182 - val_lambda_1091_loss: 0.1446 - val_lambda_1096_loss: 0.1182\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1214 - lambda_1091_loss: 0.1449 - lambda_1096_loss: 0.1214 - val_loss: 0.1208 - val_lambda_1091_loss: 0.1504 - val_lambda_1096_loss: 0.1208\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1204 - lambda_1091_loss: 0.1448 - lambda_1096_loss: 0.1204 - val_loss: 0.1176 - val_lambda_1091_loss: 0.1413 - val_lambda_1096_loss: 0.1176\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1190 - lambda_1091_loss: 0.1421 - lambda_1096_loss: 0.1190 - val_loss: 0.1159 - val_lambda_1091_loss: 0.1357 - val_lambda_1096_loss: 0.1159\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1172 - lambda_1091_loss: 0.1396 - lambda_1096_loss: 0.1172 - val_loss: 0.1149 - val_lambda_1091_loss: 0.1398 - val_lambda_1096_loss: 0.1149\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1163 - lambda_1091_loss: 0.1391 - lambda_1096_loss: 0.1163 - val_loss: 0.1148 - val_lambda_1091_loss: 0.1355 - val_lambda_1096_loss: 0.1148\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1158 - lambda_1091_loss: 0.1380 - lambda_1096_loss: 0.1158 - val_loss: 0.1169 - val_lambda_1091_loss: 0.1380 - val_lambda_1096_loss: 0.1169\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1150 - lambda_1091_loss: 0.1374 - lambda_1096_loss: 0.1150 - val_loss: 0.1153 - val_lambda_1091_loss: 0.1450 - val_lambda_1096_loss: 0.1153\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1145 - lambda_1091_loss: 0.1365 - lambda_1096_loss: 0.1145 - val_loss: 0.1135 - val_lambda_1091_loss: 0.1371 - val_lambda_1096_loss: 0.1135\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1130 - lambda_1091_loss: 0.1346 - lambda_1096_loss: 0.1130 - val_loss: 0.1164 - val_lambda_1091_loss: 0.1411 - val_lambda_1096_loss: 0.1164\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1126 - lambda_1091_loss: 0.1342 - lambda_1096_loss: 0.1126 - val_loss: 0.1094 - val_lambda_1091_loss: 0.1343 - val_lambda_1096_loss: 0.1094\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1117 - lambda_1091_loss: 0.1335 - lambda_1096_loss: 0.1117 - val_loss: 0.1101 - val_lambda_1091_loss: 0.1299 - val_lambda_1096_loss: 0.1101\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1122 - lambda_1091_loss: 0.1335 - lambda_1096_loss: 0.1122 - val_loss: 0.1118 - val_lambda_1091_loss: 0.1326 - val_lambda_1096_loss: 0.1118\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1110 - lambda_1091_loss: 0.1321 - lambda_1096_loss: 0.1110 - val_loss: 0.1094 - val_lambda_1091_loss: 0.1329 - val_lambda_1096_loss: 0.1094\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1106 - lambda_1091_loss: 0.1319 - lambda_1096_loss: 0.1106 - val_loss: 0.1219 - val_lambda_1091_loss: 0.1485 - val_lambda_1096_loss: 0.1219\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1094 - lambda_1091_loss: 0.1307 - lambda_1096_loss: 0.1094 - val_loss: 0.1078 - val_lambda_1091_loss: 0.1304 - val_lambda_1096_loss: 0.1078\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1096 - lambda_1091_loss: 0.1304 - lambda_1096_loss: 0.1096 - val_loss: 0.1129 - val_lambda_1091_loss: 0.1344 - val_lambda_1096_loss: 0.1129\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1084 - lambda_1091_loss: 0.1292 - lambda_1096_loss: 0.1084 - val_loss: 0.1078 - val_lambda_1091_loss: 0.1303 - val_lambda_1096_loss: 0.1078\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1079 - lambda_1091_loss: 0.1283 - lambda_1096_loss: 0.1079 - val_loss: 0.1099 - val_lambda_1091_loss: 0.1410 - val_lambda_1096_loss: 0.1099\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1081 - lambda_1091_loss: 0.1289 - lambda_1096_loss: 0.1081 - val_loss: 0.1118 - val_lambda_1091_loss: 0.1326 - val_lambda_1096_loss: 0.1118\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1070 - lambda_1091_loss: 0.1272 - lambda_1096_loss: 0.1070 - val_loss: 0.1167 - val_lambda_1091_loss: 0.1420 - val_lambda_1096_loss: 0.1167\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1081 - lambda_1091_loss: 0.1286 - lambda_1096_loss: 0.1081 - val_loss: 0.1086 - val_lambda_1091_loss: 0.1285 - val_lambda_1096_loss: 0.1086\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1063 - lambda_1091_loss: 0.1264 - lambda_1096_loss: 0.1063 - val_loss: 0.1053 - val_lambda_1091_loss: 0.1218 - val_lambda_1096_loss: 0.1053\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1059 - lambda_1091_loss: 0.1256 - lambda_1096_loss: 0.1059 - val_loss: 0.1058 - val_lambda_1091_loss: 0.1274 - val_lambda_1096_loss: 0.1058\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1056 - lambda_1091_loss: 0.1254 - lambda_1096_loss: 0.1056 - val_loss: 0.1079 - val_lambda_1091_loss: 0.1267 - val_lambda_1096_loss: 0.1079\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1063 - lambda_1091_loss: 0.1264 - lambda_1096_loss: 0.1063 - val_loss: 0.1079 - val_lambda_1091_loss: 0.1286 - val_lambda_1096_loss: 0.1079\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1057 - lambda_1091_loss: 0.1256 - lambda_1096_loss: 0.1057 - val_loss: 0.1097 - val_lambda_1091_loss: 0.1291 - val_lambda_1096_loss: 0.1097\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1060 - lambda_1091_loss: 0.1259 - lambda_1096_loss: 0.1060 - val_loss: 0.1108 - val_lambda_1091_loss: 0.1399 - val_lambda_1096_loss: 0.1108\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1054 - lambda_1091_loss: 0.1251 - lambda_1096_loss: 0.1054 - val_loss: 0.1042 - val_lambda_1091_loss: 0.1205 - val_lambda_1096_loss: 0.1042\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1046 - lambda_1091_loss: 0.1244 - lambda_1096_loss: 0.1046 - val_loss: 0.1072 - val_lambda_1091_loss: 0.1289 - val_lambda_1096_loss: 0.1072\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1052 - lambda_1091_loss: 0.1251 - lambda_1096_loss: 0.1052 - val_loss: 0.1047 - val_lambda_1091_loss: 0.1275 - val_lambda_1096_loss: 0.1047\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1045 - lambda_1091_loss: 0.1238 - lambda_1096_loss: 0.1045 - val_loss: 0.1071 - val_lambda_1091_loss: 0.1268 - val_lambda_1096_loss: 0.1071\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1038 - lambda_1091_loss: 0.1231 - lambda_1096_loss: 0.1038 - val_loss: 0.1075 - val_lambda_1091_loss: 0.1281 - val_lambda_1096_loss: 0.1075\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 84s 125ms/step - loss: 0.1031 - lambda_1091_loss: 0.1222 - lambda_1096_loss: 0.1031 - val_loss: 0.1092 - val_lambda_1091_loss: 0.1351 - val_lambda_1096_loss: 0.1092\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 83s 125ms/step - loss: 0.1032 - lambda_1091_loss: 0.1222 - lambda_1096_loss: 0.1032 - val_loss: 0.1036 - val_lambda_1091_loss: 0.1269 - val_lambda_1096_loss: 0.1036\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.1027 - lambda_1091_loss: 0.1217 - lambda_1096_loss: 0.1027 - val_loss: 0.1036 - val_lambda_1091_loss: 0.1239 - val_lambda_1096_loss: 0.1036\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.1022 - lambda_1091_loss: 0.1211 - lambda_1096_loss: 0.1022 - val_loss: 0.1071 - val_lambda_1091_loss: 0.1256 - val_lambda_1096_loss: 0.1071\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.1027 - lambda_1091_loss: 0.1220 - lambda_1096_loss: 0.1027 - val_loss: 0.1087 - val_lambda_1091_loss: 0.1341 - val_lambda_1096_loss: 0.1087\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1023 - lambda_1091_loss: 0.1213 - lambda_1096_loss: 0.1023 - val_loss: 0.1012 - val_lambda_1091_loss: 0.1217 - val_lambda_1096_loss: 0.1012\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.1008 - lambda_1091_loss: 0.1195 - lambda_1096_loss: 0.1008 - val_loss: 0.1071 - val_lambda_1091_loss: 0.1275 - val_lambda_1096_loss: 0.1071\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_85 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1101 (Lambda)            (None, 256, 256, 2)  0           input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_763 (Conv2D)             (None, 256, 256, 48) 912         lambda_1101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_764 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_763[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_765 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_764[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_766 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_765[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_767 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_766[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_768 (Conv2D)             (None, 256, 256, 2)  98          conv2d_767[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_255 (Add)                   (None, 256, 256, 2)  0           conv2d_768[0][0]                 \n",
      "                                                                 lambda_1101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1106 (Lambda)            (None, 256, 256, 2)  0           add_255[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_86 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_128 (Multiply)         (None, 256, 256, 2)  0           lambda_1106[0][0]                \n",
      "                                                                 input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_256 (Add)                   (None, 256, 256, 2)  0           multiply_128[0][0]               \n",
      "                                                                 input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1111 (Lambda)            (None, 256, 256, 2)  0           add_256[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_769 (Conv2D)             (None, 256, 256, 48) 912         lambda_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_770 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_769[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_771 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_770[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_772 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_771[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_773 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_772[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_774 (Conv2D)             (None, 256, 256, 2)  98          conv2d_773[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_257 (Add)                   (None, 256, 256, 2)  0           conv2d_774[0][0]                 \n",
      "                                                                 lambda_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1116 (Lambda)            (None, 256, 256, 2)  0           add_257[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_129 (Multiply)         (None, 256, 256, 2)  0           lambda_1116[0][0]                \n",
      "                                                                 input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_258 (Add)                   (None, 256, 256, 2)  0           multiply_129[0][0]               \n",
      "                                                                 input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_775 (Conv2D)             (None, 256, 256, 48) 912         add_258[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_776 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_775[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_778[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)             (None, 256, 256, 2)  98          conv2d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_259 (Add)                   (None, 256, 256, 2)  0           conv2d_780[0][0]                 \n",
      "                                                                 add_258[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_130 (Multiply)         (None, 256, 256, 2)  0           add_259[0][0]                    \n",
      "                                                                 input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_260 (Add)                   (None, 256, 256, 2)  0           multiply_130[0][0]               \n",
      "                                                                 input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1121 (Lambda)            (None, 256, 256, 2)  0           add_260[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1126 (Lambda)            (None, 256, 256, 1)  0           lambda_1121[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 98s 147ms/step - loss: 0.1936 - lambda_1121_loss: 0.2314 - lambda_1126_loss: 0.1936 - val_loss: 0.1470 - val_lambda_1121_loss: 0.1849 - val_lambda_1126_loss: 0.1470\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1363 - lambda_1121_loss: 0.1651 - lambda_1126_loss: 0.1363 - val_loss: 0.1418 - val_lambda_1121_loss: 0.1760 - val_lambda_1126_loss: 0.1418\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1260 - lambda_1121_loss: 0.1538 - lambda_1126_loss: 0.1260 - val_loss: 0.1271 - val_lambda_1121_loss: 0.1510 - val_lambda_1126_loss: 0.1271\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1221 - lambda_1121_loss: 0.1487 - lambda_1126_loss: 0.1221 - val_loss: 0.1214 - val_lambda_1121_loss: 0.1463 - val_lambda_1126_loss: 0.1214\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1138 - lambda_1121_loss: 0.1380 - lambda_1126_loss: 0.1138 - val_loss: 0.1185 - val_lambda_1121_loss: 0.1429 - val_lambda_1126_loss: 0.1185\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1127 - lambda_1121_loss: 0.1389 - lambda_1126_loss: 0.1127 - val_loss: 0.1101 - val_lambda_1121_loss: 0.1321 - val_lambda_1126_loss: 0.1101\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1078 - lambda_1121_loss: 0.1326 - lambda_1126_loss: 0.1078 - val_loss: 0.1144 - val_lambda_1121_loss: 0.1445 - val_lambda_1126_loss: 0.1144\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1068 - lambda_1121_loss: 0.1320 - lambda_1126_loss: 0.1068 - val_loss: 0.1113 - val_lambda_1121_loss: 0.1423 - val_lambda_1126_loss: 0.1113\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1056 - lambda_1121_loss: 0.1302 - lambda_1126_loss: 0.1056 - val_loss: 0.1052 - val_lambda_1121_loss: 0.1245 - val_lambda_1126_loss: 0.1052\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1039 - lambda_1121_loss: 0.1284 - lambda_1126_loss: 0.1039 - val_loss: 0.1122 - val_lambda_1121_loss: 0.1404 - val_lambda_1126_loss: 0.1122\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1032 - lambda_1121_loss: 0.1280 - lambda_1126_loss: 0.1032 - val_loss: 0.1046 - val_lambda_1121_loss: 0.1300 - val_lambda_1126_loss: 0.1046\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1012 - lambda_1121_loss: 0.1255 - lambda_1126_loss: 0.1012 - val_loss: 0.1251 - val_lambda_1121_loss: 0.1512 - val_lambda_1126_loss: 0.1251\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1015 - lambda_1121_loss: 0.1262 - lambda_1126_loss: 0.1015 - val_loss: 0.1321 - val_lambda_1121_loss: 0.1645 - val_lambda_1126_loss: 0.1321\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0981 - lambda_1121_loss: 0.1221 - lambda_1126_loss: 0.0981 - val_loss: 0.1095 - val_lambda_1121_loss: 0.1363 - val_lambda_1126_loss: 0.1095\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1004 - lambda_1121_loss: 0.1253 - lambda_1126_loss: 0.1004 - val_loss: 0.1076 - val_lambda_1121_loss: 0.1377 - val_lambda_1126_loss: 0.1076\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0974 - lambda_1121_loss: 0.1213 - lambda_1126_loss: 0.0974 - val_loss: 0.1117 - val_lambda_1121_loss: 0.1374 - val_lambda_1126_loss: 0.1117\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0975 - lambda_1121_loss: 0.1214 - lambda_1126_loss: 0.0975 - val_loss: 0.1114 - val_lambda_1121_loss: 0.1319 - val_lambda_1126_loss: 0.1114\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0970 - lambda_1121_loss: 0.1213 - lambda_1126_loss: 0.0970 - val_loss: 0.1016 - val_lambda_1121_loss: 0.1253 - val_lambda_1126_loss: 0.1016\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0956 - lambda_1121_loss: 0.1196 - lambda_1126_loss: 0.0956 - val_loss: 0.1147 - val_lambda_1121_loss: 0.1457 - val_lambda_1126_loss: 0.1147\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0946 - lambda_1121_loss: 0.1184 - lambda_1126_loss: 0.0946 - val_loss: 0.1057 - val_lambda_1121_loss: 0.1295 - val_lambda_1126_loss: 0.1057\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0950 - lambda_1121_loss: 0.1191 - lambda_1126_loss: 0.0950 - val_loss: 0.1031 - val_lambda_1121_loss: 0.1298 - val_lambda_1126_loss: 0.1031\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0940 - lambda_1121_loss: 0.1175 - lambda_1126_loss: 0.0940 - val_loss: 0.1041 - val_lambda_1121_loss: 0.1270 - val_lambda_1126_loss: 0.1041\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0929 - lambda_1121_loss: 0.1166 - lambda_1126_loss: 0.0929 - val_loss: 0.1064 - val_lambda_1121_loss: 0.1322 - val_lambda_1126_loss: 0.1064\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0936 - lambda_1121_loss: 0.1171 - lambda_1126_loss: 0.0936 - val_loss: 0.1080 - val_lambda_1121_loss: 0.1340 - val_lambda_1126_loss: 0.1080\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0927 - lambda_1121_loss: 0.1169 - lambda_1126_loss: 0.0927 - val_loss: 0.1063 - val_lambda_1121_loss: 0.1338 - val_lambda_1126_loss: 0.1063\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0920 - lambda_1121_loss: 0.1158 - lambda_1126_loss: 0.0920 - val_loss: 0.1040 - val_lambda_1121_loss: 0.1283 - val_lambda_1126_loss: 0.1040\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0922 - lambda_1121_loss: 0.1162 - lambda_1126_loss: 0.0922 - val_loss: 0.1091 - val_lambda_1121_loss: 0.1315 - val_lambda_1126_loss: 0.1091\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0913 - lambda_1121_loss: 0.1150 - lambda_1126_loss: 0.0913 - val_loss: 0.1024 - val_lambda_1121_loss: 0.1288 - val_lambda_1126_loss: 0.1024\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0916 - lambda_1121_loss: 0.1159 - lambda_1126_loss: 0.0916 - val_loss: 0.1044 - val_lambda_1121_loss: 0.1295 - val_lambda_1126_loss: 0.1044\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0914 - lambda_1121_loss: 0.1156 - lambda_1126_loss: 0.0914 - val_loss: 0.1100 - val_lambda_1121_loss: 0.1340 - val_lambda_1126_loss: 0.1100\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0910 - lambda_1121_loss: 0.1153 - lambda_1126_loss: 0.0910 - val_loss: 0.1044 - val_lambda_1121_loss: 0.1294 - val_lambda_1126_loss: 0.1044\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0903 - lambda_1121_loss: 0.1140 - lambda_1126_loss: 0.0903 - val_loss: 0.0988 - val_lambda_1121_loss: 0.1307 - val_lambda_1126_loss: 0.0988\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0901 - lambda_1121_loss: 0.1139 - lambda_1126_loss: 0.0901 - val_loss: 0.0963 - val_lambda_1121_loss: 0.1172 - val_lambda_1126_loss: 0.0963\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0897 - lambda_1121_loss: 0.1136 - lambda_1126_loss: 0.0897 - val_loss: 0.1016 - val_lambda_1121_loss: 0.1264 - val_lambda_1126_loss: 0.1016\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0897 - lambda_1121_loss: 0.1135 - lambda_1126_loss: 0.0897 - val_loss: 0.0953 - val_lambda_1121_loss: 0.1191 - val_lambda_1126_loss: 0.0953\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0883 - lambda_1121_loss: 0.1117 - lambda_1126_loss: 0.0883 - val_loss: 0.1114 - val_lambda_1121_loss: 0.1399 - val_lambda_1126_loss: 0.1114\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0885 - lambda_1121_loss: 0.1122 - lambda_1126_loss: 0.0885 - val_loss: 0.1034 - val_lambda_1121_loss: 0.1311 - val_lambda_1126_loss: 0.1034\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0883 - lambda_1121_loss: 0.1120 - lambda_1126_loss: 0.0883 - val_loss: 0.1043 - val_lambda_1121_loss: 0.1280 - val_lambda_1126_loss: 0.1043\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0884 - lambda_1121_loss: 0.1122 - lambda_1126_loss: 0.0884 - val_loss: 0.1019 - val_lambda_1121_loss: 0.1307 - val_lambda_1126_loss: 0.1019\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0881 - lambda_1121_loss: 0.1118 - lambda_1126_loss: 0.0881 - val_loss: 0.0985 - val_lambda_1121_loss: 0.1227 - val_lambda_1126_loss: 0.0985\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0871 - lambda_1121_loss: 0.1107 - lambda_1126_loss: 0.0871 - val_loss: 0.1060 - val_lambda_1121_loss: 0.1263 - val_lambda_1126_loss: 0.1060\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0881 - lambda_1121_loss: 0.1117 - lambda_1126_loss: 0.0881 - val_loss: 0.0986 - val_lambda_1121_loss: 0.1256 - val_lambda_1126_loss: 0.0986\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0872 - lambda_1121_loss: 0.1103 - lambda_1126_loss: 0.0872 - val_loss: 0.0990 - val_lambda_1121_loss: 0.1223 - val_lambda_1126_loss: 0.0990\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0865 - lambda_1121_loss: 0.1098 - lambda_1126_loss: 0.0865 - val_loss: 0.0983 - val_lambda_1121_loss: 0.1250 - val_lambda_1126_loss: 0.0983\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0872 - lambda_1121_loss: 0.1101 - lambda_1126_loss: 0.0872 - val_loss: 0.0985 - val_lambda_1121_loss: 0.1217 - val_lambda_1126_loss: 0.0985\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0857 - lambda_1121_loss: 0.1088 - lambda_1126_loss: 0.0857 - val_loss: 0.0989 - val_lambda_1121_loss: 0.1326 - val_lambda_1126_loss: 0.0989\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0862 - lambda_1121_loss: 0.1093 - lambda_1126_loss: 0.0862 - val_loss: 0.0955 - val_lambda_1121_loss: 0.1190 - val_lambda_1126_loss: 0.0955\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0862 - lambda_1121_loss: 0.1094 - lambda_1126_loss: 0.0862 - val_loss: 0.0928 - val_lambda_1121_loss: 0.1153 - val_lambda_1126_loss: 0.0928\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0852 - lambda_1121_loss: 0.1079 - lambda_1126_loss: 0.0852 - val_loss: 0.1008 - val_lambda_1121_loss: 0.1261 - val_lambda_1126_loss: 0.1008\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0854 - lambda_1121_loss: 0.1083 - lambda_1126_loss: 0.0854 - val_loss: 0.0931 - val_lambda_1121_loss: 0.1184 - val_lambda_1126_loss: 0.0931\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_87 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1131 (Lambda)            (None, 256, 256, 2)  0           input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)             (None, 256, 256, 48) 912         lambda_1131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_783[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_784[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)             (None, 256, 256, 2)  98          conv2d_785[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_261 (Add)                   (None, 256, 256, 2)  0           conv2d_786[0][0]                 \n",
      "                                                                 lambda_1131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1136 (Lambda)            (None, 256, 256, 2)  0           add_261[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_88 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_131 (Multiply)         (None, 256, 256, 2)  0           lambda_1136[0][0]                \n",
      "                                                                 input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_262 (Add)                   (None, 256, 256, 2)  0           multiply_131[0][0]               \n",
      "                                                                 input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_787 (Conv2D)             (None, 256, 256, 48) 912         add_262[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_787[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_788[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_789[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_790[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)             (None, 256, 256, 2)  98          conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_263 (Add)                   (None, 256, 256, 2)  0           conv2d_792[0][0]                 \n",
      "                                                                 add_262[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_132 (Multiply)         (None, 256, 256, 2)  0           add_263[0][0]                    \n",
      "                                                                 input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_264 (Add)                   (None, 256, 256, 2)  0           multiply_132[0][0]               \n",
      "                                                                 input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1141 (Lambda)            (None, 256, 256, 2)  0           add_264[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_793 (Conv2D)             (None, 256, 256, 48) 912         lambda_1141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_794 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_793[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_795 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_794[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_796 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_795[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_797 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_796[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_798 (Conv2D)             (None, 256, 256, 2)  98          conv2d_797[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_265 (Add)                   (None, 256, 256, 2)  0           conv2d_798[0][0]                 \n",
      "                                                                 lambda_1141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1146 (Lambda)            (None, 256, 256, 2)  0           add_265[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_133 (Multiply)         (None, 256, 256, 2)  0           lambda_1146[0][0]                \n",
      "                                                                 input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_266 (Add)                   (None, 256, 256, 2)  0           multiply_133[0][0]               \n",
      "                                                                 input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1151 (Lambda)            (None, 256, 256, 2)  0           add_266[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1156 (Lambda)            (None, 256, 256, 1)  0           lambda_1151[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iki_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 99s 149ms/step - loss: 0.1693 - lambda_1151_loss: 0.1957 - lambda_1156_loss: 0.1693 - val_loss: 0.1233 - val_lambda_1151_loss: 0.1471 - val_lambda_1156_loss: 0.1233\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1180 - lambda_1151_loss: 0.1400 - lambda_1156_loss: 0.1180 - val_loss: 0.1100 - val_lambda_1151_loss: 0.1306 - val_lambda_1156_loss: 0.1100\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1078 - lambda_1151_loss: 0.1267 - lambda_1156_loss: 0.1078 - val_loss: 0.1151 - val_lambda_1151_loss: 0.1411 - val_lambda_1156_loss: 0.1151\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1002 - lambda_1151_loss: 0.1178 - lambda_1156_loss: 0.1002 - val_loss: 0.1012 - val_lambda_1151_loss: 0.1170 - val_lambda_1156_loss: 0.1012\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0990 - lambda_1151_loss: 0.1164 - lambda_1156_loss: 0.0990 - val_loss: 0.0963 - val_lambda_1151_loss: 0.1150 - val_lambda_1156_loss: 0.0963\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0969 - lambda_1151_loss: 0.1140 - lambda_1156_loss: 0.0969 - val_loss: 0.1006 - val_lambda_1151_loss: 0.1205 - val_lambda_1156_loss: 0.1006\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0929 - lambda_1151_loss: 0.1093 - lambda_1156_loss: 0.0929 - val_loss: 0.0952 - val_lambda_1151_loss: 0.1098 - val_lambda_1156_loss: 0.0952\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0909 - lambda_1151_loss: 0.1067 - lambda_1156_loss: 0.0909 - val_loss: 0.0920 - val_lambda_1151_loss: 0.1054 - val_lambda_1156_loss: 0.0920\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0894 - lambda_1151_loss: 0.1046 - lambda_1156_loss: 0.0894 - val_loss: 0.0965 - val_lambda_1151_loss: 0.1133 - val_lambda_1156_loss: 0.0965\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0889 - lambda_1151_loss: 0.1041 - lambda_1156_loss: 0.0889 - val_loss: 0.1027 - val_lambda_1151_loss: 0.1184 - val_lambda_1156_loss: 0.1027\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0878 - lambda_1151_loss: 0.1031 - lambda_1156_loss: 0.0878 - val_loss: 0.0987 - val_lambda_1151_loss: 0.1137 - val_lambda_1156_loss: 0.0987\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0853 - lambda_1151_loss: 0.0999 - lambda_1156_loss: 0.0853 - val_loss: 0.0879 - val_lambda_1151_loss: 0.1062 - val_lambda_1156_loss: 0.0879\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0855 - lambda_1151_loss: 0.1003 - lambda_1156_loss: 0.0855 - val_loss: 0.0893 - val_lambda_1151_loss: 0.1052 - val_lambda_1156_loss: 0.0893\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0840 - lambda_1151_loss: 0.0983 - lambda_1156_loss: 0.0840 - val_loss: 0.0888 - val_lambda_1151_loss: 0.1063 - val_lambda_1156_loss: 0.0888\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0834 - lambda_1151_loss: 0.0981 - lambda_1156_loss: 0.0834 - val_loss: 0.0921 - val_lambda_1151_loss: 0.1132 - val_lambda_1156_loss: 0.0921\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0836 - lambda_1151_loss: 0.0979 - lambda_1156_loss: 0.0836 - val_loss: 0.0946 - val_lambda_1151_loss: 0.1110 - val_lambda_1156_loss: 0.0946\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0834 - lambda_1151_loss: 0.0975 - lambda_1156_loss: 0.0834 - val_loss: 0.1049 - val_lambda_1151_loss: 0.1209 - val_lambda_1156_loss: 0.1049\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0821 - lambda_1151_loss: 0.0960 - lambda_1156_loss: 0.0821 - val_loss: 0.0908 - val_lambda_1151_loss: 0.1066 - val_lambda_1156_loss: 0.0908\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0805 - lambda_1151_loss: 0.0939 - lambda_1156_loss: 0.0805 - val_loss: 0.0948 - val_lambda_1151_loss: 0.1088 - val_lambda_1156_loss: 0.0948\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0815 - lambda_1151_loss: 0.0954 - lambda_1156_loss: 0.0815 - val_loss: 0.0916 - val_lambda_1151_loss: 0.1079 - val_lambda_1156_loss: 0.0916\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0802 - lambda_1151_loss: 0.0938 - lambda_1156_loss: 0.0802 - val_loss: 0.0875 - val_lambda_1151_loss: 0.1083 - val_lambda_1156_loss: 0.0875\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0801 - lambda_1151_loss: 0.0934 - lambda_1156_loss: 0.0801 - val_loss: 0.1085 - val_lambda_1151_loss: 0.1210 - val_lambda_1156_loss: 0.1085\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0790 - lambda_1151_loss: 0.0924 - lambda_1156_loss: 0.0790 - val_loss: 0.0907 - val_lambda_1151_loss: 0.1083 - val_lambda_1156_loss: 0.0907\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0782 - lambda_1151_loss: 0.0916 - lambda_1156_loss: 0.0782 - val_loss: 0.0837 - val_lambda_1151_loss: 0.0979 - val_lambda_1156_loss: 0.0837\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0790 - lambda_1151_loss: 0.0923 - lambda_1156_loss: 0.0790 - val_loss: 0.0879 - val_lambda_1151_loss: 0.1059 - val_lambda_1156_loss: 0.0879\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0781 - lambda_1151_loss: 0.0912 - lambda_1156_loss: 0.0781 - val_loss: 0.0881 - val_lambda_1151_loss: 0.1050 - val_lambda_1156_loss: 0.0881\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0775 - lambda_1151_loss: 0.0905 - lambda_1156_loss: 0.0775 - val_loss: 0.0843 - val_lambda_1151_loss: 0.1024 - val_lambda_1156_loss: 0.0843\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0776 - lambda_1151_loss: 0.0907 - lambda_1156_loss: 0.0776 - val_loss: 0.0878 - val_lambda_1151_loss: 0.1034 - val_lambda_1156_loss: 0.0878\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0767 - lambda_1151_loss: 0.0895 - lambda_1156_loss: 0.0767 - val_loss: 0.0865 - val_lambda_1151_loss: 0.1018 - val_lambda_1156_loss: 0.0865\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0761 - lambda_1151_loss: 0.0889 - lambda_1156_loss: 0.0761 - val_loss: 0.0833 - val_lambda_1151_loss: 0.0950 - val_lambda_1156_loss: 0.0833\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0762 - lambda_1151_loss: 0.0890 - lambda_1156_loss: 0.0762 - val_loss: 0.0814 - val_lambda_1151_loss: 0.0968 - val_lambda_1156_loss: 0.0814\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0760 - lambda_1151_loss: 0.0887 - lambda_1156_loss: 0.0760 - val_loss: 0.0874 - val_lambda_1151_loss: 0.1031 - val_lambda_1156_loss: 0.0874\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0757 - lambda_1151_loss: 0.0885 - lambda_1156_loss: 0.0757 - val_loss: 0.0861 - val_lambda_1151_loss: 0.1020 - val_lambda_1156_loss: 0.0861\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0752 - lambda_1151_loss: 0.0879 - lambda_1156_loss: 0.0752 - val_loss: 0.0862 - val_lambda_1151_loss: 0.1013 - val_lambda_1156_loss: 0.0862\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0749 - lambda_1151_loss: 0.0874 - lambda_1156_loss: 0.0749 - val_loss: 0.0844 - val_lambda_1151_loss: 0.0977 - val_lambda_1156_loss: 0.0844\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0750 - lambda_1151_loss: 0.0877 - lambda_1156_loss: 0.0750 - val_loss: 0.0804 - val_lambda_1151_loss: 0.0966 - val_lambda_1156_loss: 0.0804\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0744 - lambda_1151_loss: 0.0871 - lambda_1156_loss: 0.0744 - val_loss: 0.0839 - val_lambda_1151_loss: 0.0977 - val_lambda_1156_loss: 0.0839\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0741 - lambda_1151_loss: 0.0868 - lambda_1156_loss: 0.0741 - val_loss: 0.0874 - val_lambda_1151_loss: 0.1037 - val_lambda_1156_loss: 0.0874\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0742 - lambda_1151_loss: 0.0867 - lambda_1156_loss: 0.0742 - val_loss: 0.0868 - val_lambda_1151_loss: 0.1002 - val_lambda_1156_loss: 0.0868\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0742 - lambda_1151_loss: 0.0868 - lambda_1156_loss: 0.0742 - val_loss: 0.0849 - val_lambda_1151_loss: 0.0993 - val_lambda_1156_loss: 0.0849\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0736 - lambda_1151_loss: 0.0860 - lambda_1156_loss: 0.0736 - val_loss: 0.0890 - val_lambda_1151_loss: 0.1034 - val_lambda_1156_loss: 0.0890\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0740 - lambda_1151_loss: 0.0864 - lambda_1156_loss: 0.0740 - val_loss: 0.0857 - val_lambda_1151_loss: 0.1000 - val_lambda_1156_loss: 0.0857\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0736 - lambda_1151_loss: 0.0858 - lambda_1156_loss: 0.0736 - val_loss: 0.0864 - val_lambda_1151_loss: 0.1003 - val_lambda_1156_loss: 0.0864\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0734 - lambda_1151_loss: 0.0857 - lambda_1156_loss: 0.0734 - val_loss: 0.0805 - val_lambda_1151_loss: 0.0947 - val_lambda_1156_loss: 0.0805\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0732 - lambda_1151_loss: 0.0854 - lambda_1156_loss: 0.0732 - val_loss: 0.0865 - val_lambda_1151_loss: 0.1040 - val_lambda_1156_loss: 0.0865\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0726 - lambda_1151_loss: 0.0849 - lambda_1156_loss: 0.0726 - val_loss: 0.0903 - val_lambda_1151_loss: 0.1052 - val_lambda_1156_loss: 0.0903\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0733 - lambda_1151_loss: 0.0856 - lambda_1156_loss: 0.0733 - val_loss: 0.0853 - val_lambda_1151_loss: 0.0999 - val_lambda_1156_loss: 0.0853\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0725 - lambda_1151_loss: 0.0846 - lambda_1156_loss: 0.0725 - val_loss: 0.0852 - val_lambda_1151_loss: 0.1004 - val_lambda_1156_loss: 0.0852\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0720 - lambda_1151_loss: 0.0841 - lambda_1156_loss: 0.0720 - val_loss: 0.0827 - val_lambda_1151_loss: 0.0967 - val_lambda_1156_loss: 0.0827\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0722 - lambda_1151_loss: 0.0849 - lambda_1156_loss: 0.0722 - val_loss: 0.0814 - val_lambda_1151_loss: 0.0980 - val_lambda_1156_loss: 0.0814\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_89 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1161 (Lambda)            (None, 256, 256, 2)  0           input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_799 (Conv2D)             (None, 256, 256, 48) 912         lambda_1161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_800 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_799[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_801 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_800[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_802 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_802[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)             (None, 256, 256, 2)  98          conv2d_803[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_267 (Add)                   (None, 256, 256, 2)  0           conv2d_804[0][0]                 \n",
      "                                                                 lambda_1161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1166 (Lambda)            (None, 256, 256, 2)  0           add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_134 (Multiply)         (None, 256, 256, 2)  0           lambda_1166[0][0]                \n",
      "                                                                 input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_268 (Add)                   (None, 256, 256, 2)  0           multiply_134[0][0]               \n",
      "                                                                 input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1171 (Lambda)            (None, 256, 256, 2)  0           add_268[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)             (None, 256, 256, 48) 912         lambda_1171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_805[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_807[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_808[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)             (None, 256, 256, 2)  98          conv2d_809[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_269 (Add)                   (None, 256, 256, 2)  0           conv2d_810[0][0]                 \n",
      "                                                                 lambda_1171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1176 (Lambda)            (None, 256, 256, 2)  0           add_269[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_135 (Multiply)         (None, 256, 256, 2)  0           lambda_1176[0][0]                \n",
      "                                                                 input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_270 (Add)                   (None, 256, 256, 2)  0           multiply_135[0][0]               \n",
      "                                                                 input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)             (None, 256, 256, 48) 912         add_270[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_812[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_813[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_814[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)             (None, 256, 256, 2)  98          conv2d_815[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_271 (Add)                   (None, 256, 256, 2)  0           conv2d_816[0][0]                 \n",
      "                                                                 add_270[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_136 (Multiply)         (None, 256, 256, 2)  0           add_271[0][0]                    \n",
      "                                                                 input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_272 (Add)                   (None, 256, 256, 2)  0           multiply_136[0][0]               \n",
      "                                                                 input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1181 (Lambda)            (None, 256, 256, 2)  0           add_272[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1186 (Lambda)            (None, 256, 256, 1)  0           lambda_1181[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 252,438\n",
      "Trainable params: 252,438\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_iik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 99s 148ms/step - loss: 0.1882 - lambda_1181_loss: 0.2264 - lambda_1186_loss: 0.1882 - val_loss: 0.1419 - val_lambda_1181_loss: 0.1709 - val_lambda_1186_loss: 0.1419\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1355 - lambda_1181_loss: 0.1651 - lambda_1186_loss: 0.1355 - val_loss: 0.1261 - val_lambda_1181_loss: 0.1483 - val_lambda_1186_loss: 0.1261\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1240 - lambda_1181_loss: 0.1501 - lambda_1186_loss: 0.1240 - val_loss: 0.1242 - val_lambda_1181_loss: 0.1496 - val_lambda_1186_loss: 0.1242\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1179 - lambda_1181_loss: 0.1438 - lambda_1186_loss: 0.1179 - val_loss: 0.1154 - val_lambda_1181_loss: 0.1425 - val_lambda_1186_loss: 0.1154\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1139 - lambda_1181_loss: 0.1390 - lambda_1186_loss: 0.1139 - val_loss: 0.1117 - val_lambda_1181_loss: 0.1338 - val_lambda_1186_loss: 0.1117\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 86s 128ms/step - loss: 0.1096 - lambda_1181_loss: 0.1334 - lambda_1186_loss: 0.1096 - val_loss: 0.1129 - val_lambda_1181_loss: 0.1326 - val_lambda_1186_loss: 0.1129\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 86s 129ms/step - loss: 0.1061 - lambda_1181_loss: 0.1304 - lambda_1186_loss: 0.1061 - val_loss: 0.1231 - val_lambda_1181_loss: 0.1529 - val_lambda_1186_loss: 0.1231\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 86s 129ms/step - loss: 0.1063 - lambda_1181_loss: 0.1310 - lambda_1186_loss: 0.1063 - val_loss: 0.1258 - val_lambda_1181_loss: 0.1544 - val_lambda_1186_loss: 0.1258\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1045 - lambda_1181_loss: 0.1297 - lambda_1186_loss: 0.1045 - val_loss: 0.1075 - val_lambda_1181_loss: 0.1296 - val_lambda_1186_loss: 0.1075\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1031 - lambda_1181_loss: 0.1272 - lambda_1186_loss: 0.1031 - val_loss: 0.1125 - val_lambda_1181_loss: 0.1370 - val_lambda_1186_loss: 0.1125\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1019 - lambda_1181_loss: 0.1273 - lambda_1186_loss: 0.1019 - val_loss: 0.1288 - val_lambda_1181_loss: 0.1514 - val_lambda_1186_loss: 0.1288\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.1011 - lambda_1181_loss: 0.1256 - lambda_1186_loss: 0.1011 - val_loss: 0.1137 - val_lambda_1181_loss: 0.1369 - val_lambda_1186_loss: 0.1137\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.1006 - lambda_1181_loss: 0.1251 - lambda_1186_loss: 0.1006 - val_loss: 0.1187 - val_lambda_1181_loss: 0.1400 - val_lambda_1186_loss: 0.1187\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0990 - lambda_1181_loss: 0.1228 - lambda_1186_loss: 0.0990 - val_loss: 0.1063 - val_lambda_1181_loss: 0.1341 - val_lambda_1186_loss: 0.1063\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0979 - lambda_1181_loss: 0.1216 - lambda_1186_loss: 0.0979 - val_loss: 0.1103 - val_lambda_1181_loss: 0.1373 - val_lambda_1186_loss: 0.1103\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0971 - lambda_1181_loss: 0.1212 - lambda_1186_loss: 0.0971 - val_loss: 0.1144 - val_lambda_1181_loss: 0.1363 - val_lambda_1186_loss: 0.1144\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0969 - lambda_1181_loss: 0.1208 - lambda_1186_loss: 0.0969 - val_loss: 0.1027 - val_lambda_1181_loss: 0.1289 - val_lambda_1186_loss: 0.1027\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0955 - lambda_1181_loss: 0.1191 - lambda_1186_loss: 0.0955 - val_loss: 0.1027 - val_lambda_1181_loss: 0.1291 - val_lambda_1186_loss: 0.1027\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0957 - lambda_1181_loss: 0.1192 - lambda_1186_loss: 0.0957 - val_loss: 0.1072 - val_lambda_1181_loss: 0.1366 - val_lambda_1186_loss: 0.1072\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0952 - lambda_1181_loss: 0.1188 - lambda_1186_loss: 0.0952 - val_loss: 0.1117 - val_lambda_1181_loss: 0.1330 - val_lambda_1186_loss: 0.1117\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0933 - lambda_1181_loss: 0.1169 - lambda_1186_loss: 0.0933 - val_loss: 0.1009 - val_lambda_1181_loss: 0.1227 - val_lambda_1186_loss: 0.1009\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0941 - lambda_1181_loss: 0.1176 - lambda_1186_loss: 0.0941 - val_loss: 0.1104 - val_lambda_1181_loss: 0.1325 - val_lambda_1186_loss: 0.1104\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0934 - lambda_1181_loss: 0.1167 - lambda_1186_loss: 0.0934 - val_loss: 0.1032 - val_lambda_1181_loss: 0.1290 - val_lambda_1186_loss: 0.1032\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 85s 128ms/step - loss: 0.0928 - lambda_1181_loss: 0.1163 - lambda_1186_loss: 0.0928 - val_loss: 0.1079 - val_lambda_1181_loss: 0.1363 - val_lambda_1186_loss: 0.1079\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0926 - lambda_1181_loss: 0.1159 - lambda_1186_loss: 0.0926 - val_loss: 0.1113 - val_lambda_1181_loss: 0.1344 - val_lambda_1186_loss: 0.1113\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0916 - lambda_1181_loss: 0.1151 - lambda_1186_loss: 0.0916 - val_loss: 0.1072 - val_lambda_1181_loss: 0.1328 - val_lambda_1186_loss: 0.1072\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0920 - lambda_1181_loss: 0.1154 - lambda_1186_loss: 0.0920 - val_loss: 0.1042 - val_lambda_1181_loss: 0.1278 - val_lambda_1186_loss: 0.1042\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0914 - lambda_1181_loss: 0.1144 - lambda_1186_loss: 0.0914 - val_loss: 0.1117 - val_lambda_1181_loss: 0.1426 - val_lambda_1186_loss: 0.1117\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0910 - lambda_1181_loss: 0.1143 - lambda_1186_loss: 0.0910 - val_loss: 0.1065 - val_lambda_1181_loss: 0.1337 - val_lambda_1186_loss: 0.1065\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0909 - lambda_1181_loss: 0.1142 - lambda_1186_loss: 0.0909 - val_loss: 0.0979 - val_lambda_1181_loss: 0.1199 - val_lambda_1186_loss: 0.0979\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0902 - lambda_1181_loss: 0.1137 - lambda_1186_loss: 0.0902 - val_loss: 0.1139 - val_lambda_1181_loss: 0.1436 - val_lambda_1186_loss: 0.1139\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0893 - lambda_1181_loss: 0.1122 - lambda_1186_loss: 0.0893 - val_loss: 0.0945 - val_lambda_1181_loss: 0.1181 - val_lambda_1186_loss: 0.0945\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0900 - lambda_1181_loss: 0.1131 - lambda_1186_loss: 0.0900 - val_loss: 0.1012 - val_lambda_1181_loss: 0.1214 - val_lambda_1186_loss: 0.1012\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0889 - lambda_1181_loss: 0.1116 - lambda_1186_loss: 0.0889 - val_loss: 0.1028 - val_lambda_1181_loss: 0.1302 - val_lambda_1186_loss: 0.1028\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0887 - lambda_1181_loss: 0.1118 - lambda_1186_loss: 0.0887 - val_loss: 0.0995 - val_lambda_1181_loss: 0.1214 - val_lambda_1186_loss: 0.0995\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0882 - lambda_1181_loss: 0.1108 - lambda_1186_loss: 0.0882 - val_loss: 0.1021 - val_lambda_1181_loss: 0.1250 - val_lambda_1186_loss: 0.1021\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0880 - lambda_1181_loss: 0.1116 - lambda_1186_loss: 0.0880 - val_loss: 0.0984 - val_lambda_1181_loss: 0.1232 - val_lambda_1186_loss: 0.0984\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0874 - lambda_1181_loss: 0.1102 - lambda_1186_loss: 0.0874 - val_loss: 0.0993 - val_lambda_1181_loss: 0.1274 - val_lambda_1186_loss: 0.0993\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0884 - lambda_1181_loss: 0.1115 - lambda_1186_loss: 0.0884 - val_loss: 0.0952 - val_lambda_1181_loss: 0.1203 - val_lambda_1186_loss: 0.0952\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0875 - lambda_1181_loss: 0.1101 - lambda_1186_loss: 0.0875 - val_loss: 0.1026 - val_lambda_1181_loss: 0.1248 - val_lambda_1186_loss: 0.1026\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0869 - lambda_1181_loss: 0.1094 - lambda_1186_loss: 0.0869 - val_loss: 0.0998 - val_lambda_1181_loss: 0.1242 - val_lambda_1186_loss: 0.0998\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0872 - lambda_1181_loss: 0.1100 - lambda_1186_loss: 0.0872 - val_loss: 0.0957 - val_lambda_1181_loss: 0.1174 - val_lambda_1186_loss: 0.0957\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0875 - lambda_1181_loss: 0.1102 - lambda_1186_loss: 0.0875 - val_loss: 0.0973 - val_lambda_1181_loss: 0.1214 - val_lambda_1186_loss: 0.0973\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 84s 127ms/step - loss: 0.0873 - lambda_1181_loss: 0.1102 - lambda_1186_loss: 0.0873 - val_loss: 0.1076 - val_lambda_1181_loss: 0.1285 - val_lambda_1186_loss: 0.1076\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0865 - lambda_1181_loss: 0.1091 - lambda_1186_loss: 0.0865 - val_loss: 0.0995 - val_lambda_1181_loss: 0.1216 - val_lambda_1186_loss: 0.0995\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 84s 126ms/step - loss: 0.0864 - lambda_1181_loss: 0.1087 - lambda_1186_loss: 0.0864 - val_loss: 0.0939 - val_lambda_1181_loss: 0.1212 - val_lambda_1186_loss: 0.0939\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0866 - lambda_1181_loss: 0.1091 - lambda_1186_loss: 0.0866 - val_loss: 0.1031 - val_lambda_1181_loss: 0.1260 - val_lambda_1186_loss: 0.1031\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0859 - lambda_1181_loss: 0.1083 - lambda_1186_loss: 0.0859 - val_loss: 0.0927 - val_lambda_1181_loss: 0.1152 - val_lambda_1186_loss: 0.0927\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0857 - lambda_1181_loss: 0.1082 - lambda_1186_loss: 0.0857 - val_loss: 0.1025 - val_lambda_1181_loss: 0.1302 - val_lambda_1186_loss: 0.1025\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 85s 127ms/step - loss: 0.0858 - lambda_1181_loss: 0.1088 - lambda_1186_loss: 0.0858 - val_loss: 0.1045 - val_lambda_1181_loss: 0.1316 - val_lambda_1186_loss: 0.1045\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_91 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1191 (Lambda)            (None, 256, 256, 2)  0           input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)             (None, 256, 256, 48) 912         lambda_1191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_817[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_818[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_819[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_820[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_822 (Conv2D)             (None, 256, 256, 2)  98          conv2d_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_273 (Add)                   (None, 256, 256, 2)  0           conv2d_822[0][0]                 \n",
      "                                                                 lambda_1191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1196 (Lambda)            (None, 256, 256, 2)  0           add_273[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_92 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_137 (Multiply)         (None, 256, 256, 2)  0           lambda_1196[0][0]                \n",
      "                                                                 input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_274 (Add)                   (None, 256, 256, 2)  0           multiply_137[0][0]               \n",
      "                                                                 input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_823 (Conv2D)             (None, 256, 256, 48) 912         add_274[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_824 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_823[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_825 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_824[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_826 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_825[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_827 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_826[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_828 (Conv2D)             (None, 256, 256, 2)  98          conv2d_827[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_275 (Add)                   (None, 256, 256, 2)  0           conv2d_828[0][0]                 \n",
      "                                                                 add_274[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_138 (Multiply)         (None, 256, 256, 2)  0           add_275[0][0]                    \n",
      "                                                                 input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_276 (Add)                   (None, 256, 256, 2)  0           multiply_138[0][0]               \n",
      "                                                                 input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1201 (Lambda)            (None, 256, 256, 2)  0           add_276[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)             (None, 256, 256, 48) 912         lambda_1201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_829[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_830[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_832[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)             (None, 256, 256, 2)  98          conv2d_833[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_277 (Add)                   (None, 256, 256, 2)  0           conv2d_834[0][0]                 \n",
      "                                                                 lambda_1201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1206 (Lambda)            (None, 256, 256, 2)  0           add_277[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_139 (Multiply)         (None, 256, 256, 2)  0           lambda_1206[0][0]                \n",
      "                                                                 input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_278 (Add)                   (None, 256, 256, 2)  0           multiply_139[0][0]               \n",
      "                                                                 input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1211 (Lambda)            (None, 256, 256, 2)  0           add_278[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)             (None, 256, 256, 48) 912         lambda_1211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_835[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_836[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_837[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_839 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_838[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)             (None, 256, 256, 2)  98          conv2d_839[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_279 (Add)                   (None, 256, 256, 2)  0           conv2d_840[0][0]                 \n",
      "                                                                 lambda_1211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1216 (Lambda)            (None, 256, 256, 2)  0           add_279[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_140 (Multiply)         (None, 256, 256, 2)  0           lambda_1216[0][0]                \n",
      "                                                                 input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_280 (Add)                   (None, 256, 256, 2)  0           multiply_140[0][0]               \n",
      "                                                                 input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1221 (Lambda)            (None, 256, 256, 2)  0           add_280[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1226 (Lambda)            (None, 256, 256, 1)  0           lambda_1221[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_ikii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 124s 186ms/step - loss: 0.1466 - lambda_1221_loss: 0.1691 - lambda_1226_loss: 0.1466 - val_loss: 0.1141 - val_lambda_1221_loss: 0.1355 - val_lambda_1226_loss: 0.1141\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0960 - lambda_1221_loss: 0.1141 - lambda_1226_loss: 0.0960 - val_loss: 0.0937 - val_lambda_1221_loss: 0.1089 - val_lambda_1226_loss: 0.0937\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0851 - lambda_1221_loss: 0.0992 - lambda_1226_loss: 0.0851 - val_loss: 0.0914 - val_lambda_1221_loss: 0.1044 - val_lambda_1226_loss: 0.0914\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0803 - lambda_1221_loss: 0.0946 - lambda_1226_loss: 0.0803 - val_loss: 0.0891 - val_lambda_1221_loss: 0.1130 - val_lambda_1226_loss: 0.0891\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0754 - lambda_1221_loss: 0.0876 - lambda_1226_loss: 0.0754 - val_loss: 0.0831 - val_lambda_1221_loss: 0.0956 - val_lambda_1226_loss: 0.0831\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0726 - lambda_1221_loss: 0.0836 - lambda_1226_loss: 0.0726 - val_loss: 0.0770 - val_lambda_1221_loss: 0.0842 - val_lambda_1226_loss: 0.0770\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0709 - lambda_1221_loss: 0.0825 - lambda_1226_loss: 0.0709 - val_loss: 0.0765 - val_lambda_1221_loss: 0.0827 - val_lambda_1226_loss: 0.0765\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0691 - lambda_1221_loss: 0.0802 - lambda_1226_loss: 0.0691 - val_loss: 0.0786 - val_lambda_1221_loss: 0.0879 - val_lambda_1226_loss: 0.0786\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0681 - lambda_1221_loss: 0.0783 - lambda_1226_loss: 0.0681 - val_loss: 0.0763 - val_lambda_1221_loss: 0.0898 - val_lambda_1226_loss: 0.0763\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0648 - lambda_1221_loss: 0.0743 - lambda_1226_loss: 0.0648 - val_loss: 0.0752 - val_lambda_1221_loss: 0.0835 - val_lambda_1226_loss: 0.0752\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0649 - lambda_1221_loss: 0.0749 - lambda_1226_loss: 0.0649 - val_loss: 0.0709 - val_lambda_1221_loss: 0.0800 - val_lambda_1226_loss: 0.0709\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0631 - lambda_1221_loss: 0.0722 - lambda_1226_loss: 0.0631 - val_loss: 0.0749 - val_lambda_1221_loss: 0.0840 - val_lambda_1226_loss: 0.0749\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0631 - lambda_1221_loss: 0.0728 - lambda_1226_loss: 0.0631 - val_loss: 0.0833 - val_lambda_1221_loss: 0.0909 - val_lambda_1226_loss: 0.0833\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0618 - lambda_1221_loss: 0.0707 - lambda_1226_loss: 0.0618 - val_loss: 0.0673 - val_lambda_1221_loss: 0.0765 - val_lambda_1226_loss: 0.0673\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0611 - lambda_1221_loss: 0.0698 - lambda_1226_loss: 0.0611 - val_loss: 0.0743 - val_lambda_1221_loss: 0.0876 - val_lambda_1226_loss: 0.0743\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0612 - lambda_1221_loss: 0.0706 - lambda_1226_loss: 0.0612 - val_loss: 0.0711 - val_lambda_1221_loss: 0.0801 - val_lambda_1226_loss: 0.0711\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0594 - lambda_1221_loss: 0.0680 - lambda_1226_loss: 0.0594 - val_loss: 0.0714 - val_lambda_1221_loss: 0.0844 - val_lambda_1226_loss: 0.0714\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0601 - lambda_1221_loss: 0.0693 - lambda_1226_loss: 0.0601 - val_loss: 0.0671 - val_lambda_1221_loss: 0.0757 - val_lambda_1226_loss: 0.0671\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0595 - lambda_1221_loss: 0.0685 - lambda_1226_loss: 0.0595 - val_loss: 0.0788 - val_lambda_1221_loss: 0.0939 - val_lambda_1226_loss: 0.0788\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0600 - lambda_1221_loss: 0.0696 - lambda_1226_loss: 0.0600 - val_loss: 0.0697 - val_lambda_1221_loss: 0.0783 - val_lambda_1226_loss: 0.0697\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0579 - lambda_1221_loss: 0.0659 - lambda_1226_loss: 0.0579 - val_loss: 0.0685 - val_lambda_1221_loss: 0.0807 - val_lambda_1226_loss: 0.0685\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0578 - lambda_1221_loss: 0.0661 - lambda_1226_loss: 0.0578 - val_loss: 0.0695 - val_lambda_1221_loss: 0.0792 - val_lambda_1226_loss: 0.0695\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0577 - lambda_1221_loss: 0.0664 - lambda_1226_loss: 0.0577 - val_loss: 0.0671 - val_lambda_1221_loss: 0.0781 - val_lambda_1226_loss: 0.0671\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0574 - lambda_1221_loss: 0.0654 - lambda_1226_loss: 0.0574 - val_loss: 0.0675 - val_lambda_1221_loss: 0.0887 - val_lambda_1226_loss: 0.0675\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0569 - lambda_1221_loss: 0.0654 - lambda_1226_loss: 0.0569 - val_loss: 0.0713 - val_lambda_1221_loss: 0.0826 - val_lambda_1226_loss: 0.0713\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0572 - lambda_1221_loss: 0.0656 - lambda_1226_loss: 0.0572 - val_loss: 0.0680 - val_lambda_1221_loss: 0.0845 - val_lambda_1226_loss: 0.0680\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0557 - lambda_1221_loss: 0.0638 - lambda_1226_loss: 0.0557 - val_loss: 0.0686 - val_lambda_1221_loss: 0.0826 - val_lambda_1226_loss: 0.0686\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0569 - lambda_1221_loss: 0.0652 - lambda_1226_loss: 0.0569 - val_loss: 0.0651 - val_lambda_1221_loss: 0.0748 - val_lambda_1226_loss: 0.0651\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0561 - lambda_1221_loss: 0.0640 - lambda_1226_loss: 0.0561 - val_loss: 0.0635 - val_lambda_1221_loss: 0.0737 - val_lambda_1226_loss: 0.0635\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0555 - lambda_1221_loss: 0.0634 - lambda_1226_loss: 0.0555 - val_loss: 0.0669 - val_lambda_1221_loss: 0.0736 - val_lambda_1226_loss: 0.0669\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0563 - lambda_1221_loss: 0.0646 - lambda_1226_loss: 0.0563 - val_loss: 0.0752 - val_lambda_1221_loss: 0.0850 - val_lambda_1226_loss: 0.0752\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0551 - lambda_1221_loss: 0.0631 - lambda_1226_loss: 0.0551 - val_loss: 0.0681 - val_lambda_1221_loss: 0.0781 - val_lambda_1226_loss: 0.0681\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0553 - lambda_1221_loss: 0.0634 - lambda_1226_loss: 0.0553 - val_loss: 0.0677 - val_lambda_1221_loss: 0.0786 - val_lambda_1226_loss: 0.0677\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0546 - lambda_1221_loss: 0.0624 - lambda_1226_loss: 0.0546 - val_loss: 0.0725 - val_lambda_1221_loss: 0.0812 - val_lambda_1226_loss: 0.0725\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0546 - lambda_1221_loss: 0.0622 - lambda_1226_loss: 0.0546 - val_loss: 0.0677 - val_lambda_1221_loss: 0.0768 - val_lambda_1226_loss: 0.0677\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0551 - lambda_1221_loss: 0.0628 - lambda_1226_loss: 0.0551 - val_loss: 0.0682 - val_lambda_1221_loss: 0.0895 - val_lambda_1226_loss: 0.0682\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0542 - lambda_1221_loss: 0.0620 - lambda_1226_loss: 0.0542 - val_loss: 0.0676 - val_lambda_1221_loss: 0.0801 - val_lambda_1226_loss: 0.0676\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0545 - lambda_1221_loss: 0.0622 - lambda_1226_loss: 0.0545 - val_loss: 0.0646 - val_lambda_1221_loss: 0.0720 - val_lambda_1226_loss: 0.0646\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0540 - lambda_1221_loss: 0.0618 - lambda_1226_loss: 0.0540 - val_loss: 0.0666 - val_lambda_1221_loss: 0.0771 - val_lambda_1226_loss: 0.0666\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0541 - lambda_1221_loss: 0.0614 - lambda_1226_loss: 0.0541 - val_loss: 0.0627 - val_lambda_1221_loss: 0.0706 - val_lambda_1226_loss: 0.0627\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0536 - lambda_1221_loss: 0.0611 - lambda_1226_loss: 0.0536 - val_loss: 0.0670 - val_lambda_1221_loss: 0.0763 - val_lambda_1226_loss: 0.0670\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0532 - lambda_1221_loss: 0.0602 - lambda_1226_loss: 0.0532 - val_loss: 0.0695 - val_lambda_1221_loss: 0.0783 - val_lambda_1226_loss: 0.0695\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0538 - lambda_1221_loss: 0.0615 - lambda_1226_loss: 0.0538 - val_loss: 0.0651 - val_lambda_1221_loss: 0.0733 - val_lambda_1226_loss: 0.0651\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0530 - lambda_1221_loss: 0.0599 - lambda_1226_loss: 0.0530 - val_loss: 0.0659 - val_lambda_1221_loss: 0.0785 - val_lambda_1226_loss: 0.0659\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0533 - lambda_1221_loss: 0.0608 - lambda_1226_loss: 0.0533 - val_loss: 0.0647 - val_lambda_1221_loss: 0.0739 - val_lambda_1226_loss: 0.0647\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0528 - lambda_1221_loss: 0.0603 - lambda_1226_loss: 0.0528 - val_loss: 0.0657 - val_lambda_1221_loss: 0.0741 - val_lambda_1226_loss: 0.0657\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0522 - lambda_1221_loss: 0.0591 - lambda_1226_loss: 0.0522 - val_loss: 0.0659 - val_lambda_1221_loss: 0.0747 - val_lambda_1226_loss: 0.0659\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0531 - lambda_1221_loss: 0.0603 - lambda_1226_loss: 0.0531 - val_loss: 0.0622 - val_lambda_1221_loss: 0.0704 - val_lambda_1226_loss: 0.0622\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0521 - lambda_1221_loss: 0.0592 - lambda_1226_loss: 0.0521 - val_loss: 0.0655 - val_lambda_1221_loss: 0.0734 - val_lambda_1226_loss: 0.0655\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0527 - lambda_1221_loss: 0.0600 - lambda_1226_loss: 0.0527 - val_loss: 0.0652 - val_lambda_1221_loss: 0.0723 - val_lambda_1226_loss: 0.0652\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_93 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)             (None, 256, 256, 48) 912         input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_842[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_843[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_844[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_846 (Conv2D)             (None, 256, 256, 2)  98          conv2d_845[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_281 (Add)                   (None, 256, 256, 2)  0           conv2d_846[0][0]                 \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_94 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_141 (Multiply)         (None, 256, 256, 2)  0           add_281[0][0]                    \n",
      "                                                                 input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_282 (Add)                   (None, 256, 256, 2)  0           multiply_141[0][0]               \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_847 (Conv2D)             (None, 256, 256, 48) 912         add_282[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_848 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_847[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_849 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_848[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_850 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_849[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_851 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_850[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_852 (Conv2D)             (None, 256, 256, 2)  98          conv2d_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_283 (Add)                   (None, 256, 256, 2)  0           conv2d_852[0][0]                 \n",
      "                                                                 add_282[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_142 (Multiply)         (None, 256, 256, 2)  0           add_283[0][0]                    \n",
      "                                                                 input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_284 (Add)                   (None, 256, 256, 2)  0           multiply_142[0][0]               \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_853 (Conv2D)             (None, 256, 256, 48) 912         add_284[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_854 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_853[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_855 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_854[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_856 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_855[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_857 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_856[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_858 (Conv2D)             (None, 256, 256, 2)  98          conv2d_857[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_285 (Add)                   (None, 256, 256, 2)  0           conv2d_858[0][0]                 \n",
      "                                                                 add_284[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_143 (Multiply)         (None, 256, 256, 2)  0           add_285[0][0]                    \n",
      "                                                                 input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_286 (Add)                   (None, 256, 256, 2)  0           multiply_143[0][0]               \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_859 (Conv2D)             (None, 256, 256, 48) 912         add_286[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_860 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_859[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_861 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_860[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_862 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_861[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_863 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_862[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_864 (Conv2D)             (None, 256, 256, 2)  98          conv2d_863[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_287 (Add)                   (None, 256, 256, 2)  0           conv2d_864[0][0]                 \n",
      "                                                                 add_286[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_144 (Multiply)         (None, 256, 256, 2)  0           add_287[0][0]                    \n",
      "                                                                 input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_288 (Add)                   (None, 256, 256, 2)  0           multiply_144[0][0]               \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1231 (Lambda)            (None, 256, 256, 2)  0           add_288[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1236 (Lambda)            (None, 256, 256, 1)  0           lambda_1231[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkkk_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 122s 183ms/step - loss: 0.3316 - lambda_1231_loss: 0.4013 - lambda_1236_loss: 0.3316 - val_loss: 0.2822 - val_lambda_1231_loss: 0.3553 - val_lambda_1236_loss: 0.2822\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.2737 - lambda_1231_loss: 0.3379 - lambda_1236_loss: 0.2737 - val_loss: 0.2629 - val_lambda_1231_loss: 0.3310 - val_lambda_1236_loss: 0.2629\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2612 - lambda_1231_loss: 0.3246 - lambda_1236_loss: 0.2612 - val_loss: 0.2561 - val_lambda_1231_loss: 0.3154 - val_lambda_1236_loss: 0.2561\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 108s 161ms/step - loss: 0.2495 - lambda_1231_loss: 0.3104 - lambda_1236_loss: 0.2495 - val_loss: 0.2341 - val_lambda_1231_loss: 0.2925 - val_lambda_1236_loss: 0.2341\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2419 - lambda_1231_loss: 0.3021 - lambda_1236_loss: 0.2419 - val_loss: 0.2263 - val_lambda_1231_loss: 0.2880 - val_lambda_1236_loss: 0.2263\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2368 - lambda_1231_loss: 0.2969 - lambda_1236_loss: 0.2368 - val_loss: 0.2272 - val_lambda_1231_loss: 0.2892 - val_lambda_1236_loss: 0.2272\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2336 - lambda_1231_loss: 0.2924 - lambda_1236_loss: 0.2336 - val_loss: 0.2302 - val_lambda_1231_loss: 0.2974 - val_lambda_1236_loss: 0.2302\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2283 - lambda_1231_loss: 0.2868 - lambda_1236_loss: 0.2283 - val_loss: 0.2240 - val_lambda_1231_loss: 0.2798 - val_lambda_1236_loss: 0.2240\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2258 - lambda_1231_loss: 0.2834 - lambda_1236_loss: 0.2258 - val_loss: 0.2199 - val_lambda_1231_loss: 0.2787 - val_lambda_1236_loss: 0.2199\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2236 - lambda_1231_loss: 0.2815 - lambda_1236_loss: 0.2236 - val_loss: 0.2182 - val_lambda_1231_loss: 0.2752 - val_lambda_1236_loss: 0.2182\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2225 - lambda_1231_loss: 0.2800 - lambda_1236_loss: 0.2225 - val_loss: 0.2110 - val_lambda_1231_loss: 0.2643 - val_lambda_1236_loss: 0.2110\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2204 - lambda_1231_loss: 0.2775 - lambda_1236_loss: 0.2204 - val_loss: 0.2152 - val_lambda_1231_loss: 0.2756 - val_lambda_1236_loss: 0.2152\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2170 - lambda_1231_loss: 0.2735 - lambda_1236_loss: 0.2170 - val_loss: 0.2104 - val_lambda_1231_loss: 0.2664 - val_lambda_1236_loss: 0.2104\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2163 - lambda_1231_loss: 0.2733 - lambda_1236_loss: 0.2163 - val_loss: 0.2118 - val_lambda_1231_loss: 0.2731 - val_lambda_1236_loss: 0.2118\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2133 - lambda_1231_loss: 0.2695 - lambda_1236_loss: 0.2133 - val_loss: 0.2181 - val_lambda_1231_loss: 0.2776 - val_lambda_1236_loss: 0.2181\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2118 - lambda_1231_loss: 0.2677 - lambda_1236_loss: 0.2118 - val_loss: 0.2035 - val_lambda_1231_loss: 0.2592 - val_lambda_1236_loss: 0.2035\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.2117 - lambda_1231_loss: 0.2679 - lambda_1236_loss: 0.2117 - val_loss: 0.2087 - val_lambda_1231_loss: 0.2685 - val_lambda_1236_loss: 0.2087\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2117 - lambda_1231_loss: 0.2676 - lambda_1236_loss: 0.2117 - val_loss: 0.2099 - val_lambda_1231_loss: 0.2646 - val_lambda_1236_loss: 0.2099\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2090 - lambda_1231_loss: 0.2651 - lambda_1236_loss: 0.2090 - val_loss: 0.2069 - val_lambda_1231_loss: 0.2614 - val_lambda_1236_loss: 0.2069\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2055 - lambda_1231_loss: 0.2609 - lambda_1236_loss: 0.2055 - val_loss: 0.2034 - val_lambda_1231_loss: 0.2588 - val_lambda_1236_loss: 0.2034\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2077 - lambda_1231_loss: 0.2631 - lambda_1236_loss: 0.2077 - val_loss: 0.2047 - val_lambda_1231_loss: 0.2640 - val_lambda_1236_loss: 0.2047\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2071 - lambda_1231_loss: 0.2625 - lambda_1236_loss: 0.2071 - val_loss: 0.2037 - val_lambda_1231_loss: 0.2593 - val_lambda_1236_loss: 0.2037\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.2051 - lambda_1231_loss: 0.2601 - lambda_1236_loss: 0.2051 - val_loss: 0.2045 - val_lambda_1231_loss: 0.2595 - val_lambda_1236_loss: 0.2045\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 106s 160ms/step - loss: 0.2050 - lambda_1231_loss: 0.2602 - lambda_1236_loss: 0.2050 - val_loss: 0.2057 - val_lambda_1231_loss: 0.2594 - val_lambda_1236_loss: 0.2057\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2039 - lambda_1231_loss: 0.2588 - lambda_1236_loss: 0.2039 - val_loss: 0.1955 - val_lambda_1231_loss: 0.2497 - val_lambda_1236_loss: 0.1955\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2037 - lambda_1231_loss: 0.2586 - lambda_1236_loss: 0.2037 - val_loss: 0.1965 - val_lambda_1231_loss: 0.2506 - val_lambda_1236_loss: 0.1965\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2021 - lambda_1231_loss: 0.2565 - lambda_1236_loss: 0.2021 - val_loss: 0.1931 - val_lambda_1231_loss: 0.2491 - val_lambda_1236_loss: 0.1931\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2024 - lambda_1231_loss: 0.2570 - lambda_1236_loss: 0.2024 - val_loss: 0.2015 - val_lambda_1231_loss: 0.2616 - val_lambda_1236_loss: 0.2015\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1991 - lambda_1231_loss: 0.2537 - lambda_1236_loss: 0.1991 - val_loss: 0.1960 - val_lambda_1231_loss: 0.2469 - val_lambda_1236_loss: 0.1960\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.2005 - lambda_1231_loss: 0.2555 - lambda_1236_loss: 0.2005 - val_loss: 0.1934 - val_lambda_1231_loss: 0.2467 - val_lambda_1236_loss: 0.1934\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1972 - lambda_1231_loss: 0.2515 - lambda_1236_loss: 0.1972 - val_loss: 0.1923 - val_lambda_1231_loss: 0.2479 - val_lambda_1236_loss: 0.1923\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1971 - lambda_1231_loss: 0.2514 - lambda_1236_loss: 0.1971 - val_loss: 0.1915 - val_lambda_1231_loss: 0.2441 - val_lambda_1236_loss: 0.1915\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1972 - lambda_1231_loss: 0.2511 - lambda_1236_loss: 0.1972 - val_loss: 0.1962 - val_lambda_1231_loss: 0.2486 - val_lambda_1236_loss: 0.1962\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1965 - lambda_1231_loss: 0.2505 - lambda_1236_loss: 0.1965 - val_loss: 0.1953 - val_lambda_1231_loss: 0.2529 - val_lambda_1236_loss: 0.1953\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1953 - lambda_1231_loss: 0.2492 - lambda_1236_loss: 0.1953 - val_loss: 0.1882 - val_lambda_1231_loss: 0.2407 - val_lambda_1236_loss: 0.1882\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1942 - lambda_1231_loss: 0.2480 - lambda_1236_loss: 0.1942 - val_loss: 0.1922 - val_lambda_1231_loss: 0.2459 - val_lambda_1236_loss: 0.1922\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1967 - lambda_1231_loss: 0.2509 - lambda_1236_loss: 0.1967 - val_loss: 0.1897 - val_lambda_1231_loss: 0.2432 - val_lambda_1236_loss: 0.1897\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1941 - lambda_1231_loss: 0.2478 - lambda_1236_loss: 0.1941 - val_loss: 0.1940 - val_lambda_1231_loss: 0.2466 - val_lambda_1236_loss: 0.1940\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1952 - lambda_1231_loss: 0.2490 - lambda_1236_loss: 0.1952 - val_loss: 0.1892 - val_lambda_1231_loss: 0.2423 - val_lambda_1236_loss: 0.1892\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1938 - lambda_1231_loss: 0.2473 - lambda_1236_loss: 0.1938 - val_loss: 0.1890 - val_lambda_1231_loss: 0.2457 - val_lambda_1236_loss: 0.1890\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1939 - lambda_1231_loss: 0.2478 - lambda_1236_loss: 0.1939 - val_loss: 0.1896 - val_lambda_1231_loss: 0.2464 - val_lambda_1236_loss: 0.1896\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1919 - lambda_1231_loss: 0.2454 - lambda_1236_loss: 0.1919 - val_loss: 0.1935 - val_lambda_1231_loss: 0.2484 - val_lambda_1236_loss: 0.1935\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1924 - lambda_1231_loss: 0.2458 - lambda_1236_loss: 0.1924 - val_loss: 0.1904 - val_lambda_1231_loss: 0.2399 - val_lambda_1236_loss: 0.1904\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1919 - lambda_1231_loss: 0.2450 - lambda_1236_loss: 0.1919 - val_loss: 0.2025 - val_lambda_1231_loss: 0.2597 - val_lambda_1236_loss: 0.2025\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1915 - lambda_1231_loss: 0.2448 - lambda_1236_loss: 0.1915 - val_loss: 0.1887 - val_lambda_1231_loss: 0.2442 - val_lambda_1236_loss: 0.1887\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1910 - lambda_1231_loss: 0.2444 - lambda_1236_loss: 0.1910 - val_loss: 0.1916 - val_lambda_1231_loss: 0.2442 - val_lambda_1236_loss: 0.1916\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1900 - lambda_1231_loss: 0.2428 - lambda_1236_loss: 0.1900 - val_loss: 0.1836 - val_lambda_1231_loss: 0.2354 - val_lambda_1236_loss: 0.1836\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1904 - lambda_1231_loss: 0.2434 - lambda_1236_loss: 0.1904 - val_loss: 0.1864 - val_lambda_1231_loss: 0.2385 - val_lambda_1236_loss: 0.1864\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 107s 161ms/step - loss: 0.1892 - lambda_1231_loss: 0.2422 - lambda_1236_loss: 0.1892 - val_loss: 0.1835 - val_lambda_1231_loss: 0.2392 - val_lambda_1236_loss: 0.1835\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 107s 160ms/step - loss: 0.1909 - lambda_1231_loss: 0.2442 - lambda_1236_loss: 0.1909 - val_loss: 0.1848 - val_lambda_1231_loss: 0.2372 - val_lambda_1236_loss: 0.1848\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_95 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_865 (Conv2D)             (None, 256, 256, 48) 912         input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_866 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_865[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_867 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_868 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_869 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_870 (Conv2D)             (None, 256, 256, 2)  98          conv2d_869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_289 (Add)                   (None, 256, 256, 2)  0           conv2d_870[0][0]                 \n",
      "                                                                 input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_96 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_145 (Multiply)         (None, 256, 256, 2)  0           add_289[0][0]                    \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_290 (Add)                   (None, 256, 256, 2)  0           multiply_145[0][0]               \n",
      "                                                                 input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1241 (Lambda)            (None, 256, 256, 2)  0           add_290[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_871 (Conv2D)             (None, 256, 256, 48) 912         lambda_1241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_872 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_873 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_874 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_875 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_876 (Conv2D)             (None, 256, 256, 2)  98          conv2d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_291 (Add)                   (None, 256, 256, 2)  0           conv2d_876[0][0]                 \n",
      "                                                                 lambda_1241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1246 (Lambda)            (None, 256, 256, 2)  0           add_291[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_146 (Multiply)         (None, 256, 256, 2)  0           lambda_1246[0][0]                \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_292 (Add)                   (None, 256, 256, 2)  0           multiply_146[0][0]               \n",
      "                                                                 input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1251 (Lambda)            (None, 256, 256, 2)  0           add_292[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_877 (Conv2D)             (None, 256, 256, 48) 912         lambda_1251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_878 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_877[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_879 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_878[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_880 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_879[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_881 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_882 (Conv2D)             (None, 256, 256, 2)  98          conv2d_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_293 (Add)                   (None, 256, 256, 2)  0           conv2d_882[0][0]                 \n",
      "                                                                 lambda_1251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1256 (Lambda)            (None, 256, 256, 2)  0           add_293[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_147 (Multiply)         (None, 256, 256, 2)  0           lambda_1256[0][0]                \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_294 (Add)                   (None, 256, 256, 2)  0           multiply_147[0][0]               \n",
      "                                                                 input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1261 (Lambda)            (None, 256, 256, 2)  0           add_294[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_883 (Conv2D)             (None, 256, 256, 48) 912         lambda_1261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_884 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_883[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_885 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_884[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_886 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_887 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_886[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_888 (Conv2D)             (None, 256, 256, 2)  98          conv2d_887[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_295 (Add)                   (None, 256, 256, 2)  0           conv2d_888[0][0]                 \n",
      "                                                                 lambda_1261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1266 (Lambda)            (None, 256, 256, 2)  0           add_295[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_148 (Multiply)         (None, 256, 256, 2)  0           lambda_1266[0][0]                \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_296 (Add)                   (None, 256, 256, 2)  0           multiply_148[0][0]               \n",
      "                                                                 input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1271 (Lambda)            (None, 256, 256, 2)  0           add_296[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1276 (Lambda)            (None, 256, 256, 1)  0           lambda_1271[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 125s 187ms/step - loss: 0.1572 - lambda_1271_loss: 0.1796 - lambda_1276_loss: 0.1572 - val_loss: 0.1175 - val_lambda_1271_loss: 0.1365 - val_lambda_1276_loss: 0.1175\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1075 - lambda_1271_loss: 0.1292 - lambda_1276_loss: 0.1075 - val_loss: 0.1028 - val_lambda_1271_loss: 0.1252 - val_lambda_1276_loss: 0.1028\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0887 - lambda_1271_loss: 0.1031 - lambda_1276_loss: 0.0887 - val_loss: 0.0921 - val_lambda_1271_loss: 0.1079 - val_lambda_1276_loss: 0.0921\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0824 - lambda_1271_loss: 0.0964 - lambda_1276_loss: 0.0824 - val_loss: 0.0876 - val_lambda_1271_loss: 0.0997 - val_lambda_1276_loss: 0.0876\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0782 - lambda_1271_loss: 0.0907 - lambda_1276_loss: 0.0782 - val_loss: 0.0889 - val_lambda_1271_loss: 0.1061 - val_lambda_1276_loss: 0.0889\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0758 - lambda_1271_loss: 0.0879 - lambda_1276_loss: 0.0758 - val_loss: 0.0785 - val_lambda_1271_loss: 0.0886 - val_lambda_1276_loss: 0.0785\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0734 - lambda_1271_loss: 0.0848 - lambda_1276_loss: 0.0734 - val_loss: 0.0792 - val_lambda_1271_loss: 0.0925 - val_lambda_1276_loss: 0.0792\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0720 - lambda_1271_loss: 0.0844 - lambda_1276_loss: 0.0720 - val_loss: 0.0746 - val_lambda_1271_loss: 0.0894 - val_lambda_1276_loss: 0.0746\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0696 - lambda_1271_loss: 0.0802 - lambda_1276_loss: 0.0696 - val_loss: 0.0789 - val_lambda_1271_loss: 0.0867 - val_lambda_1276_loss: 0.0789\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0687 - lambda_1271_loss: 0.0796 - lambda_1276_loss: 0.0687 - val_loss: 0.0845 - val_lambda_1271_loss: 0.0942 - val_lambda_1276_loss: 0.0845\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0666 - lambda_1271_loss: 0.0760 - lambda_1276_loss: 0.0666 - val_loss: 0.0795 - val_lambda_1271_loss: 0.0871 - val_lambda_1276_loss: 0.0795\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 112s 168ms/step - loss: 0.0655 - lambda_1271_loss: 0.0754 - lambda_1276_loss: 0.0655 - val_loss: 0.0758 - val_lambda_1271_loss: 0.0843 - val_lambda_1276_loss: 0.0758\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0659 - lambda_1271_loss: 0.0766 - lambda_1276_loss: 0.0659 - val_loss: 0.0735 - val_lambda_1271_loss: 0.0809 - val_lambda_1276_loss: 0.0735\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0643 - lambda_1271_loss: 0.0734 - lambda_1276_loss: 0.0643 - val_loss: 0.0748 - val_lambda_1271_loss: 0.0831 - val_lambda_1276_loss: 0.0748\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0641 - lambda_1271_loss: 0.0740 - lambda_1276_loss: 0.0641 - val_loss: 0.0746 - val_lambda_1271_loss: 0.0822 - val_lambda_1276_loss: 0.0746\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0630 - lambda_1271_loss: 0.0719 - lambda_1276_loss: 0.0630 - val_loss: 0.0713 - val_lambda_1271_loss: 0.0808 - val_lambda_1276_loss: 0.0713\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0619 - lambda_1271_loss: 0.0708 - lambda_1276_loss: 0.0619 - val_loss: 0.0682 - val_lambda_1271_loss: 0.0763 - val_lambda_1276_loss: 0.0682\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0613 - lambda_1271_loss: 0.0697 - lambda_1276_loss: 0.0613 - val_loss: 0.0728 - val_lambda_1271_loss: 0.0803 - val_lambda_1276_loss: 0.0728\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0612 - lambda_1271_loss: 0.0701 - lambda_1276_loss: 0.0612 - val_loss: 0.0731 - val_lambda_1271_loss: 0.0844 - val_lambda_1276_loss: 0.0731\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0614 - lambda_1271_loss: 0.0707 - lambda_1276_loss: 0.0614 - val_loss: 0.0698 - val_lambda_1271_loss: 0.0803 - val_lambda_1276_loss: 0.0698\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0629 - lambda_1271_loss: 0.0731 - lambda_1276_loss: 0.0629 - val_loss: 0.0738 - val_lambda_1271_loss: 0.0835 - val_lambda_1276_loss: 0.0738\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0606 - lambda_1271_loss: 0.0690 - lambda_1276_loss: 0.0606 - val_loss: 0.0662 - val_lambda_1271_loss: 0.0749 - val_lambda_1276_loss: 0.0662\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0593 - lambda_1271_loss: 0.0675 - lambda_1276_loss: 0.0593 - val_loss: 0.0662 - val_lambda_1271_loss: 0.0753 - val_lambda_1276_loss: 0.0662\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0588 - lambda_1271_loss: 0.0673 - lambda_1276_loss: 0.0588 - val_loss: 0.0723 - val_lambda_1271_loss: 0.0816 - val_lambda_1276_loss: 0.0723\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0588 - lambda_1271_loss: 0.0669 - lambda_1276_loss: 0.0588 - val_loss: 0.0781 - val_lambda_1271_loss: 0.0901 - val_lambda_1276_loss: 0.0781\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0603 - lambda_1271_loss: 0.0695 - lambda_1276_loss: 0.0603 - val_loss: 0.0671 - val_lambda_1271_loss: 0.0817 - val_lambda_1276_loss: 0.0671\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0580 - lambda_1271_loss: 0.0658 - lambda_1276_loss: 0.0580 - val_loss: 0.0653 - val_lambda_1271_loss: 0.0724 - val_lambda_1276_loss: 0.0653\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0574 - lambda_1271_loss: 0.0649 - lambda_1276_loss: 0.0574 - val_loss: 0.0661 - val_lambda_1271_loss: 0.0768 - val_lambda_1276_loss: 0.0661\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0573 - lambda_1271_loss: 0.0655 - lambda_1276_loss: 0.0573 - val_loss: 0.0669 - val_lambda_1271_loss: 0.0751 - val_lambda_1276_loss: 0.0669\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0567 - lambda_1271_loss: 0.0643 - lambda_1276_loss: 0.0567 - val_loss: 0.0668 - val_lambda_1271_loss: 0.0732 - val_lambda_1276_loss: 0.0668\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0560 - lambda_1271_loss: 0.0637 - lambda_1276_loss: 0.0560 - val_loss: 0.0699 - val_lambda_1271_loss: 0.0770 - val_lambda_1276_loss: 0.0699\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0560 - lambda_1271_loss: 0.0633 - lambda_1276_loss: 0.0560 - val_loss: 0.0665 - val_lambda_1271_loss: 0.0753 - val_lambda_1276_loss: 0.0665\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0567 - lambda_1271_loss: 0.0650 - lambda_1276_loss: 0.0567 - val_loss: 0.0704 - val_lambda_1271_loss: 0.0802 - val_lambda_1276_loss: 0.0704\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0556 - lambda_1271_loss: 0.0630 - lambda_1276_loss: 0.0556 - val_loss: 0.0691 - val_lambda_1271_loss: 0.0776 - val_lambda_1276_loss: 0.0691\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0565 - lambda_1271_loss: 0.0643 - lambda_1276_loss: 0.0565 - val_loss: 0.0635 - val_lambda_1271_loss: 0.0694 - val_lambda_1276_loss: 0.0635\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0560 - lambda_1271_loss: 0.0635 - lambda_1276_loss: 0.0560 - val_loss: 0.0674 - val_lambda_1271_loss: 0.0756 - val_lambda_1276_loss: 0.0674\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0553 - lambda_1271_loss: 0.0630 - lambda_1276_loss: 0.0553 - val_loss: 0.0672 - val_lambda_1271_loss: 0.0749 - val_lambda_1276_loss: 0.0672\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0553 - lambda_1271_loss: 0.0629 - lambda_1276_loss: 0.0553 - val_loss: 0.0704 - val_lambda_1271_loss: 0.0815 - val_lambda_1276_loss: 0.0704\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0553 - lambda_1271_loss: 0.0625 - lambda_1276_loss: 0.0553 - val_loss: 0.0663 - val_lambda_1271_loss: 0.0743 - val_lambda_1276_loss: 0.0663\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0546 - lambda_1271_loss: 0.0619 - lambda_1276_loss: 0.0546 - val_loss: 0.0633 - val_lambda_1271_loss: 0.0695 - val_lambda_1276_loss: 0.0633\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0545 - lambda_1271_loss: 0.0615 - lambda_1276_loss: 0.0545 - val_loss: 0.0655 - val_lambda_1271_loss: 0.0734 - val_lambda_1276_loss: 0.0655\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0546 - lambda_1271_loss: 0.0624 - lambda_1276_loss: 0.0546 - val_loss: 0.0650 - val_lambda_1271_loss: 0.0729 - val_lambda_1276_loss: 0.0650\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0543 - lambda_1271_loss: 0.0615 - lambda_1276_loss: 0.0543 - val_loss: 0.0681 - val_lambda_1271_loss: 0.0760 - val_lambda_1276_loss: 0.0681\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0542 - lambda_1271_loss: 0.0617 - lambda_1276_loss: 0.0542 - val_loss: 0.0634 - val_lambda_1271_loss: 0.0712 - val_lambda_1276_loss: 0.0634\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0535 - lambda_1271_loss: 0.0605 - lambda_1276_loss: 0.0535 - val_loss: 0.0626 - val_lambda_1271_loss: 0.0689 - val_lambda_1276_loss: 0.0626\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0533 - lambda_1271_loss: 0.0602 - lambda_1276_loss: 0.0533 - val_loss: 0.0669 - val_lambda_1271_loss: 0.0724 - val_lambda_1276_loss: 0.0669\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0541 - lambda_1271_loss: 0.0614 - lambda_1276_loss: 0.0541 - val_loss: 0.0652 - val_lambda_1271_loss: 0.0741 - val_lambda_1276_loss: 0.0652\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0533 - lambda_1271_loss: 0.0604 - lambda_1276_loss: 0.0533 - val_loss: 0.0626 - val_lambda_1271_loss: 0.0718 - val_lambda_1276_loss: 0.0626\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0538 - lambda_1271_loss: 0.0611 - lambda_1276_loss: 0.0538 - val_loss: 0.0674 - val_lambda_1271_loss: 0.0769 - val_lambda_1276_loss: 0.0674\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0528 - lambda_1271_loss: 0.0598 - lambda_1276_loss: 0.0528 - val_loss: 0.0621 - val_lambda_1271_loss: 0.0682 - val_lambda_1276_loss: 0.0621\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_97 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_889 (Conv2D)             (None, 256, 256, 48) 912         input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_890 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_889[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_891 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_890[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_892 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_893 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_892[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_894 (Conv2D)             (None, 256, 256, 2)  98          conv2d_893[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_297 (Add)                   (None, 256, 256, 2)  0           conv2d_894[0][0]                 \n",
      "                                                                 input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_98 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_149 (Multiply)         (None, 256, 256, 2)  0           add_297[0][0]                    \n",
      "                                                                 input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_298 (Add)                   (None, 256, 256, 2)  0           multiply_149[0][0]               \n",
      "                                                                 input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_895 (Conv2D)             (None, 256, 256, 48) 912         add_298[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_896 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_895[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_897 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_896[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_898 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_897[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_899 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_898[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_900 (Conv2D)             (None, 256, 256, 2)  98          conv2d_899[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_299 (Add)                   (None, 256, 256, 2)  0           conv2d_900[0][0]                 \n",
      "                                                                 add_298[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_150 (Multiply)         (None, 256, 256, 2)  0           add_299[0][0]                    \n",
      "                                                                 input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_300 (Add)                   (None, 256, 256, 2)  0           multiply_150[0][0]               \n",
      "                                                                 input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1281 (Lambda)            (None, 256, 256, 2)  0           add_300[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_901 (Conv2D)             (None, 256, 256, 48) 912         lambda_1281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_902 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_901[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_903 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_902[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_904 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_903[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_905 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_904[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_906 (Conv2D)             (None, 256, 256, 2)  98          conv2d_905[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_301 (Add)                   (None, 256, 256, 2)  0           conv2d_906[0][0]                 \n",
      "                                                                 lambda_1281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1286 (Lambda)            (None, 256, 256, 2)  0           add_301[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_151 (Multiply)         (None, 256, 256, 2)  0           lambda_1286[0][0]                \n",
      "                                                                 input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_302 (Add)                   (None, 256, 256, 2)  0           multiply_151[0][0]               \n",
      "                                                                 input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1291 (Lambda)            (None, 256, 256, 2)  0           add_302[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_907 (Conv2D)             (None, 256, 256, 48) 912         lambda_1291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_908 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_907[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_909 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_908[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_910 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_909[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_911 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_910[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_912 (Conv2D)             (None, 256, 256, 2)  98          conv2d_911[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_303 (Add)                   (None, 256, 256, 2)  0           conv2d_912[0][0]                 \n",
      "                                                                 lambda_1291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1296 (Lambda)            (None, 256, 256, 2)  0           add_303[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_152 (Multiply)         (None, 256, 256, 2)  0           lambda_1296[0][0]                \n",
      "                                                                 input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_304 (Add)                   (None, 256, 256, 2)  0           multiply_152[0][0]               \n",
      "                                                                 input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1301 (Lambda)            (None, 256, 256, 2)  0           add_304[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1306 (Lambda)            (None, 256, 256, 1)  0           lambda_1301[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkii_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 126s 188ms/step - loss: 0.1831 - lambda_1301_loss: 0.2138 - lambda_1306_loss: 0.1831 - val_loss: 0.1309 - val_lambda_1301_loss: 0.1552 - val_lambda_1306_loss: 0.1309\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1194 - lambda_1301_loss: 0.1415 - lambda_1306_loss: 0.1194 - val_loss: 0.1131 - val_lambda_1301_loss: 0.1377 - val_lambda_1306_loss: 0.1131\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.1079 - lambda_1301_loss: 0.1268 - lambda_1306_loss: 0.1079 - val_loss: 0.1058 - val_lambda_1301_loss: 0.1291 - val_lambda_1306_loss: 0.1058\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.1026 - lambda_1301_loss: 0.1203 - lambda_1306_loss: 0.1026 - val_loss: 0.1025 - val_lambda_1301_loss: 0.1221 - val_lambda_1306_loss: 0.1025\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0994 - lambda_1301_loss: 0.1170 - lambda_1306_loss: 0.0994 - val_loss: 0.0967 - val_lambda_1301_loss: 0.1087 - val_lambda_1306_loss: 0.0967\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0948 - lambda_1301_loss: 0.1108 - lambda_1306_loss: 0.0948 - val_loss: 0.1015 - val_lambda_1301_loss: 0.1134 - val_lambda_1306_loss: 0.1015\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0935 - lambda_1301_loss: 0.1103 - lambda_1306_loss: 0.0935 - val_loss: 0.0952 - val_lambda_1301_loss: 0.1137 - val_lambda_1306_loss: 0.0952\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0920 - lambda_1301_loss: 0.1092 - lambda_1306_loss: 0.0920 - val_loss: 0.0991 - val_lambda_1301_loss: 0.1240 - val_lambda_1306_loss: 0.0991\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0896 - lambda_1301_loss: 0.1058 - lambda_1306_loss: 0.0896 - val_loss: 0.0904 - val_lambda_1301_loss: 0.1058 - val_lambda_1306_loss: 0.0904\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0896 - lambda_1301_loss: 0.1058 - lambda_1306_loss: 0.0896 - val_loss: 0.0939 - val_lambda_1301_loss: 0.1183 - val_lambda_1306_loss: 0.0939\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0877 - lambda_1301_loss: 0.1037 - lambda_1306_loss: 0.0877 - val_loss: 0.0956 - val_lambda_1301_loss: 0.1147 - val_lambda_1306_loss: 0.0956\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0855 - lambda_1301_loss: 0.1017 - lambda_1306_loss: 0.0855 - val_loss: 0.0994 - val_lambda_1301_loss: 0.1160 - val_lambda_1306_loss: 0.0994\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0848 - lambda_1301_loss: 0.1007 - lambda_1306_loss: 0.0848 - val_loss: 0.0911 - val_lambda_1301_loss: 0.1093 - val_lambda_1306_loss: 0.0911\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0836 - lambda_1301_loss: 0.0999 - lambda_1306_loss: 0.0836 - val_loss: 0.0884 - val_lambda_1301_loss: 0.1079 - val_lambda_1306_loss: 0.0884\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0825 - lambda_1301_loss: 0.0986 - lambda_1306_loss: 0.0825 - val_loss: 0.0841 - val_lambda_1301_loss: 0.1045 - val_lambda_1306_loss: 0.0841\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0811 - lambda_1301_loss: 0.0970 - lambda_1306_loss: 0.0811 - val_loss: 0.0877 - val_lambda_1301_loss: 0.1123 - val_lambda_1306_loss: 0.0877\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0789 - lambda_1301_loss: 0.0932 - lambda_1306_loss: 0.0789 - val_loss: 0.0814 - val_lambda_1301_loss: 0.0930 - val_lambda_1306_loss: 0.0814\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0789 - lambda_1301_loss: 0.0934 - lambda_1306_loss: 0.0789 - val_loss: 0.0795 - val_lambda_1301_loss: 0.0917 - val_lambda_1306_loss: 0.0795\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0772 - lambda_1301_loss: 0.0907 - lambda_1306_loss: 0.0772 - val_loss: 0.0881 - val_lambda_1301_loss: 0.1030 - val_lambda_1306_loss: 0.0881\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0771 - lambda_1301_loss: 0.0910 - lambda_1306_loss: 0.0771 - val_loss: 0.0819 - val_lambda_1301_loss: 0.0982 - val_lambda_1306_loss: 0.0819\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0764 - lambda_1301_loss: 0.0897 - lambda_1306_loss: 0.0764 - val_loss: 0.0811 - val_lambda_1301_loss: 0.0911 - val_lambda_1306_loss: 0.0811\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0749 - lambda_1301_loss: 0.0870 - lambda_1306_loss: 0.0749 - val_loss: 0.0805 - val_lambda_1301_loss: 0.0975 - val_lambda_1306_loss: 0.0805\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0752 - lambda_1301_loss: 0.0877 - lambda_1306_loss: 0.0752 - val_loss: 0.0828 - val_lambda_1301_loss: 0.0952 - val_lambda_1306_loss: 0.0828\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0754 - lambda_1301_loss: 0.0880 - lambda_1306_loss: 0.0754 - val_loss: 0.0814 - val_lambda_1301_loss: 0.0933 - val_lambda_1306_loss: 0.0814\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0742 - lambda_1301_loss: 0.0865 - lambda_1306_loss: 0.0742 - val_loss: 0.0929 - val_lambda_1301_loss: 0.1139 - val_lambda_1306_loss: 0.0929\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0736 - lambda_1301_loss: 0.0860 - lambda_1306_loss: 0.0736 - val_loss: 0.0782 - val_lambda_1301_loss: 0.0899 - val_lambda_1306_loss: 0.0782\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0730 - lambda_1301_loss: 0.0850 - lambda_1306_loss: 0.0730 - val_loss: 0.0764 - val_lambda_1301_loss: 0.0868 - val_lambda_1306_loss: 0.0764\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0737 - lambda_1301_loss: 0.0857 - lambda_1306_loss: 0.0737 - val_loss: 0.0773 - val_lambda_1301_loss: 0.0898 - val_lambda_1306_loss: 0.0773\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0731 - lambda_1301_loss: 0.0855 - lambda_1306_loss: 0.0731 - val_loss: 0.0805 - val_lambda_1301_loss: 0.0928 - val_lambda_1306_loss: 0.0805\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0718 - lambda_1301_loss: 0.0829 - lambda_1306_loss: 0.0718 - val_loss: 0.0787 - val_lambda_1301_loss: 0.0922 - val_lambda_1306_loss: 0.0787\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0715 - lambda_1301_loss: 0.0834 - lambda_1306_loss: 0.0715 - val_loss: 0.0782 - val_lambda_1301_loss: 0.0962 - val_lambda_1306_loss: 0.0782\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0714 - lambda_1301_loss: 0.0824 - lambda_1306_loss: 0.0714 - val_loss: 0.0764 - val_lambda_1301_loss: 0.0864 - val_lambda_1306_loss: 0.0764\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 110s 166ms/step - loss: 0.0707 - lambda_1301_loss: 0.0819 - lambda_1306_loss: 0.0707 - val_loss: 0.0735 - val_lambda_1301_loss: 0.0830 - val_lambda_1306_loss: 0.0735\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0707 - lambda_1301_loss: 0.0822 - lambda_1306_loss: 0.0707 - val_loss: 0.0754 - val_lambda_1301_loss: 0.0860 - val_lambda_1306_loss: 0.0754\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0707 - lambda_1301_loss: 0.0820 - lambda_1306_loss: 0.0707 - val_loss: 0.0801 - val_lambda_1301_loss: 0.0950 - val_lambda_1306_loss: 0.0801\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0693 - lambda_1301_loss: 0.0801 - lambda_1306_loss: 0.0693 - val_loss: 0.0759 - val_lambda_1301_loss: 0.0864 - val_lambda_1306_loss: 0.0759\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0704 - lambda_1301_loss: 0.0815 - lambda_1306_loss: 0.0704 - val_loss: 0.0778 - val_lambda_1301_loss: 0.0878 - val_lambda_1306_loss: 0.0778\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0698 - lambda_1301_loss: 0.0805 - lambda_1306_loss: 0.0698 - val_loss: 0.0765 - val_lambda_1301_loss: 0.0899 - val_lambda_1306_loss: 0.0765\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0698 - lambda_1301_loss: 0.0810 - lambda_1306_loss: 0.0698 - val_loss: 0.0772 - val_lambda_1301_loss: 0.0900 - val_lambda_1306_loss: 0.0772\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0689 - lambda_1301_loss: 0.0791 - lambda_1306_loss: 0.0689 - val_loss: 0.0736 - val_lambda_1301_loss: 0.0853 - val_lambda_1306_loss: 0.0736\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0693 - lambda_1301_loss: 0.0800 - lambda_1306_loss: 0.0693 - val_loss: 0.0751 - val_lambda_1301_loss: 0.0854 - val_lambda_1306_loss: 0.0751\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0708 - lambda_1301_loss: 0.0822 - lambda_1306_loss: 0.0708 - val_loss: 0.0736 - val_lambda_1301_loss: 0.0839 - val_lambda_1306_loss: 0.0736\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0685 - lambda_1301_loss: 0.0783 - lambda_1306_loss: 0.0685 - val_loss: 0.0827 - val_lambda_1301_loss: 0.1002 - val_lambda_1306_loss: 0.0827\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0682 - lambda_1301_loss: 0.0784 - lambda_1306_loss: 0.0682 - val_loss: 0.0748 - val_lambda_1301_loss: 0.0853 - val_lambda_1306_loss: 0.0748\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0679 - lambda_1301_loss: 0.0780 - lambda_1306_loss: 0.0679 - val_loss: 0.0727 - val_lambda_1301_loss: 0.0817 - val_lambda_1306_loss: 0.0727\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0675 - lambda_1301_loss: 0.0779 - lambda_1306_loss: 0.0675 - val_loss: 0.0732 - val_lambda_1301_loss: 0.0824 - val_lambda_1306_loss: 0.0732\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0676 - lambda_1301_loss: 0.0775 - lambda_1306_loss: 0.0676 - val_loss: 0.0775 - val_lambda_1301_loss: 0.0902 - val_lambda_1306_loss: 0.0775\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0669 - lambda_1301_loss: 0.0770 - lambda_1306_loss: 0.0669 - val_loss: 0.0809 - val_lambda_1301_loss: 0.1001 - val_lambda_1306_loss: 0.0809\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0681 - lambda_1301_loss: 0.0784 - lambda_1306_loss: 0.0681 - val_loss: 0.0811 - val_lambda_1301_loss: 0.0981 - val_lambda_1306_loss: 0.0811\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0677 - lambda_1301_loss: 0.0784 - lambda_1306_loss: 0.0677 - val_loss: 0.0735 - val_lambda_1301_loss: 0.0826 - val_lambda_1306_loss: 0.0735\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_99 (InputLayer)           (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_913 (Conv2D)             (None, 256, 256, 48) 912         input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_914 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_913[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_915 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_914[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_916 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_915[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_917 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_918 (Conv2D)             (None, 256, 256, 2)  98          conv2d_917[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_305 (Add)                   (None, 256, 256, 2)  0           conv2d_918[0][0]                 \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_100 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_153 (Multiply)         (None, 256, 256, 2)  0           add_305[0][0]                    \n",
      "                                                                 input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_306 (Add)                   (None, 256, 256, 2)  0           multiply_153[0][0]               \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_919 (Conv2D)             (None, 256, 256, 48) 912         add_306[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_920 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_919[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_921 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_920[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_922 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_923 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_922[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_924 (Conv2D)             (None, 256, 256, 2)  98          conv2d_923[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_307 (Add)                   (None, 256, 256, 2)  0           conv2d_924[0][0]                 \n",
      "                                                                 add_306[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_154 (Multiply)         (None, 256, 256, 2)  0           add_307[0][0]                    \n",
      "                                                                 input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_308 (Add)                   (None, 256, 256, 2)  0           multiply_154[0][0]               \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1311 (Lambda)            (None, 256, 256, 2)  0           add_308[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_925 (Conv2D)             (None, 256, 256, 48) 912         lambda_1311[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_926 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_925[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_927 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_928 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_927[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_929 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_928[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_930 (Conv2D)             (None, 256, 256, 2)  98          conv2d_929[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_309 (Add)                   (None, 256, 256, 2)  0           conv2d_930[0][0]                 \n",
      "                                                                 lambda_1311[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1316 (Lambda)            (None, 256, 256, 2)  0           add_309[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_155 (Multiply)         (None, 256, 256, 2)  0           lambda_1316[0][0]                \n",
      "                                                                 input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_310 (Add)                   (None, 256, 256, 2)  0           multiply_155[0][0]               \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_931 (Conv2D)             (None, 256, 256, 48) 912         add_310[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_932 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_931[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_933 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_932[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_934 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_933[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_935 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_934[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_936 (Conv2D)             (None, 256, 256, 2)  98          conv2d_935[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_311 (Add)                   (None, 256, 256, 2)  0           conv2d_936[0][0]                 \n",
      "                                                                 add_310[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_156 (Multiply)         (None, 256, 256, 2)  0           add_311[0][0]                    \n",
      "                                                                 input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_312 (Add)                   (None, 256, 256, 2)  0           multiply_156[0][0]               \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1321 (Lambda)            (None, 256, 256, 2)  0           add_312[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1326 (Lambda)            (None, 256, 256, 1)  0           lambda_1321[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 125s 188ms/step - loss: 0.2117 - lambda_1321_loss: 0.2505 - lambda_1326_loss: 0.2117 - val_loss: 0.1900 - val_lambda_1321_loss: 0.2334 - val_lambda_1326_loss: 0.1900\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1591 - lambda_1321_loss: 0.1928 - lambda_1326_loss: 0.1591 - val_loss: 0.1452 - val_lambda_1321_loss: 0.1720 - val_lambda_1326_loss: 0.1452\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1424 - lambda_1321_loss: 0.1746 - lambda_1326_loss: 0.1424 - val_loss: 0.1361 - val_lambda_1321_loss: 0.1657 - val_lambda_1326_loss: 0.1361\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1327 - lambda_1321_loss: 0.1624 - lambda_1326_loss: 0.1327 - val_loss: 0.1224 - val_lambda_1321_loss: 0.1531 - val_lambda_1326_loss: 0.1224\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1280 - lambda_1321_loss: 0.1576 - lambda_1326_loss: 0.1280 - val_loss: 0.1259 - val_lambda_1321_loss: 0.1555 - val_lambda_1326_loss: 0.1259\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1241 - lambda_1321_loss: 0.1530 - lambda_1326_loss: 0.1241 - val_loss: 0.1231 - val_lambda_1321_loss: 0.1486 - val_lambda_1326_loss: 0.1231\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1225 - lambda_1321_loss: 0.1509 - lambda_1326_loss: 0.1225 - val_loss: 0.1179 - val_lambda_1321_loss: 0.1451 - val_lambda_1326_loss: 0.1179\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1186 - lambda_1321_loss: 0.1461 - lambda_1326_loss: 0.1186 - val_loss: 0.1202 - val_lambda_1321_loss: 0.1469 - val_lambda_1326_loss: 0.1202\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1171 - lambda_1321_loss: 0.1442 - lambda_1326_loss: 0.1171 - val_loss: 0.1292 - val_lambda_1321_loss: 0.1526 - val_lambda_1326_loss: 0.1292\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1143 - lambda_1321_loss: 0.1405 - lambda_1326_loss: 0.1143 - val_loss: 0.1188 - val_lambda_1321_loss: 0.1460 - val_lambda_1326_loss: 0.1188\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1139 - lambda_1321_loss: 0.1402 - lambda_1326_loss: 0.1139 - val_loss: 0.1180 - val_lambda_1321_loss: 0.1419 - val_lambda_1326_loss: 0.1180\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1115 - lambda_1321_loss: 0.1365 - lambda_1326_loss: 0.1115 - val_loss: 0.1066 - val_lambda_1321_loss: 0.1314 - val_lambda_1326_loss: 0.1066\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1108 - lambda_1321_loss: 0.1364 - lambda_1326_loss: 0.1108 - val_loss: 0.1120 - val_lambda_1321_loss: 0.1390 - val_lambda_1326_loss: 0.1120\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1087 - lambda_1321_loss: 0.1337 - lambda_1326_loss: 0.1087 - val_loss: 0.1097 - val_lambda_1321_loss: 0.1336 - val_lambda_1326_loss: 0.1097\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1083 - lambda_1321_loss: 0.1331 - lambda_1326_loss: 0.1083 - val_loss: 0.1099 - val_lambda_1321_loss: 0.1386 - val_lambda_1326_loss: 0.1099\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1066 - lambda_1321_loss: 0.1310 - lambda_1326_loss: 0.1066 - val_loss: 0.1088 - val_lambda_1321_loss: 0.1336 - val_lambda_1326_loss: 0.1088\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1058 - lambda_1321_loss: 0.1300 - lambda_1326_loss: 0.1058 - val_loss: 0.1056 - val_lambda_1321_loss: 0.1308 - val_lambda_1326_loss: 0.1056\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1062 - lambda_1321_loss: 0.1303 - lambda_1326_loss: 0.1062 - val_loss: 0.1057 - val_lambda_1321_loss: 0.1288 - val_lambda_1326_loss: 0.1057\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1041 - lambda_1321_loss: 0.1276 - lambda_1326_loss: 0.1041 - val_loss: 0.1041 - val_lambda_1321_loss: 0.1262 - val_lambda_1326_loss: 0.1041\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1035 - lambda_1321_loss: 0.1268 - lambda_1326_loss: 0.1035 - val_loss: 0.1104 - val_lambda_1321_loss: 0.1344 - val_lambda_1326_loss: 0.1104\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1028 - lambda_1321_loss: 0.1259 - lambda_1326_loss: 0.1028 - val_loss: 0.1025 - val_lambda_1321_loss: 0.1246 - val_lambda_1326_loss: 0.1025\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1029 - lambda_1321_loss: 0.1262 - lambda_1326_loss: 0.1029 - val_loss: 0.1031 - val_lambda_1321_loss: 0.1273 - val_lambda_1326_loss: 0.1031\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1015 - lambda_1321_loss: 0.1245 - lambda_1326_loss: 0.1015 - val_loss: 0.1035 - val_lambda_1321_loss: 0.1286 - val_lambda_1326_loss: 0.1035\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1017 - lambda_1321_loss: 0.1244 - lambda_1326_loss: 0.1017 - val_loss: 0.1072 - val_lambda_1321_loss: 0.1353 - val_lambda_1326_loss: 0.1072\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1008 - lambda_1321_loss: 0.1234 - lambda_1326_loss: 0.1008 - val_loss: 0.1006 - val_lambda_1321_loss: 0.1244 - val_lambda_1326_loss: 0.1006\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0999 - lambda_1321_loss: 0.1221 - lambda_1326_loss: 0.0999 - val_loss: 0.1060 - val_lambda_1321_loss: 0.1309 - val_lambda_1326_loss: 0.1060\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0996 - lambda_1321_loss: 0.1218 - lambda_1326_loss: 0.0996 - val_loss: 0.1028 - val_lambda_1321_loss: 0.1214 - val_lambda_1326_loss: 0.1028\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0995 - lambda_1321_loss: 0.1216 - lambda_1326_loss: 0.0995 - val_loss: 0.1085 - val_lambda_1321_loss: 0.1311 - val_lambda_1326_loss: 0.1085\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0987 - lambda_1321_loss: 0.1208 - lambda_1326_loss: 0.0987 - val_loss: 0.1017 - val_lambda_1321_loss: 0.1265 - val_lambda_1326_loss: 0.1017\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0987 - lambda_1321_loss: 0.1209 - lambda_1326_loss: 0.0987 - val_loss: 0.0992 - val_lambda_1321_loss: 0.1206 - val_lambda_1326_loss: 0.0992\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0977 - lambda_1321_loss: 0.1193 - lambda_1326_loss: 0.0977 - val_loss: 0.1033 - val_lambda_1321_loss: 0.1263 - val_lambda_1326_loss: 0.1033\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0978 - lambda_1321_loss: 0.1195 - lambda_1326_loss: 0.0978 - val_loss: 0.1007 - val_lambda_1321_loss: 0.1206 - val_lambda_1326_loss: 0.1007\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0974 - lambda_1321_loss: 0.1190 - lambda_1326_loss: 0.0974 - val_loss: 0.1034 - val_lambda_1321_loss: 0.1226 - val_lambda_1326_loss: 0.1034\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0975 - lambda_1321_loss: 0.1191 - lambda_1326_loss: 0.0975 - val_loss: 0.1057 - val_lambda_1321_loss: 0.1271 - val_lambda_1326_loss: 0.1057\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0968 - lambda_1321_loss: 0.1182 - lambda_1326_loss: 0.0968 - val_loss: 0.1009 - val_lambda_1321_loss: 0.1223 - val_lambda_1326_loss: 0.1009\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0966 - lambda_1321_loss: 0.1176 - lambda_1326_loss: 0.0966 - val_loss: 0.1025 - val_lambda_1321_loss: 0.1253 - val_lambda_1326_loss: 0.1025\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0956 - lambda_1321_loss: 0.1166 - lambda_1326_loss: 0.0956 - val_loss: 0.0966 - val_lambda_1321_loss: 0.1183 - val_lambda_1326_loss: 0.0966\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0958 - lambda_1321_loss: 0.1170 - lambda_1326_loss: 0.0958 - val_loss: 0.1033 - val_lambda_1321_loss: 0.1275 - val_lambda_1326_loss: 0.1033\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0955 - lambda_1321_loss: 0.1165 - lambda_1326_loss: 0.0955 - val_loss: 0.1001 - val_lambda_1321_loss: 0.1227 - val_lambda_1326_loss: 0.1001\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0954 - lambda_1321_loss: 0.1166 - lambda_1326_loss: 0.0954 - val_loss: 0.0999 - val_lambda_1321_loss: 0.1217 - val_lambda_1326_loss: 0.0999\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0950 - lambda_1321_loss: 0.1159 - lambda_1326_loss: 0.0950 - val_loss: 0.1026 - val_lambda_1321_loss: 0.1243 - val_lambda_1326_loss: 0.1026\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0949 - lambda_1321_loss: 0.1155 - lambda_1326_loss: 0.0949 - val_loss: 0.0969 - val_lambda_1321_loss: 0.1185 - val_lambda_1326_loss: 0.0969\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0929 - lambda_1321_loss: 0.1130 - lambda_1326_loss: 0.0929 - val_loss: 0.1004 - val_lambda_1321_loss: 0.1185 - val_lambda_1326_loss: 0.1004\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0945 - lambda_1321_loss: 0.1151 - lambda_1326_loss: 0.0945 - val_loss: 0.0987 - val_lambda_1321_loss: 0.1188 - val_lambda_1326_loss: 0.0987\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0941 - lambda_1321_loss: 0.1149 - lambda_1326_loss: 0.0941 - val_loss: 0.1030 - val_lambda_1321_loss: 0.1235 - val_lambda_1326_loss: 0.1030\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0936 - lambda_1321_loss: 0.1140 - lambda_1326_loss: 0.0936 - val_loss: 0.0967 - val_lambda_1321_loss: 0.1198 - val_lambda_1326_loss: 0.0967\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0938 - lambda_1321_loss: 0.1142 - lambda_1326_loss: 0.0938 - val_loss: 0.0969 - val_lambda_1321_loss: 0.1198 - val_lambda_1326_loss: 0.0969\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0931 - lambda_1321_loss: 0.1133 - lambda_1326_loss: 0.0931 - val_loss: 0.0972 - val_lambda_1321_loss: 0.1166 - val_lambda_1326_loss: 0.0972\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0929 - lambda_1321_loss: 0.1132 - lambda_1326_loss: 0.0929 - val_loss: 0.1017 - val_lambda_1321_loss: 0.1242 - val_lambda_1326_loss: 0.1017\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0926 - lambda_1321_loss: 0.1127 - lambda_1326_loss: 0.0926 - val_loss: 0.0946 - val_lambda_1321_loss: 0.1144 - val_lambda_1326_loss: 0.0946\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_101 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_937 (Conv2D)             (None, 256, 256, 48) 912         input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_938 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_937[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_939 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_938[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_940 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_939[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_941 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_940[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_942 (Conv2D)             (None, 256, 256, 2)  98          conv2d_941[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_313 (Add)                   (None, 256, 256, 2)  0           conv2d_942[0][0]                 \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_102 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_157 (Multiply)         (None, 256, 256, 2)  0           add_313[0][0]                    \n",
      "                                                                 input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_314 (Add)                   (None, 256, 256, 2)  0           multiply_157[0][0]               \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_943 (Conv2D)             (None, 256, 256, 48) 912         add_314[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_944 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_943[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_945 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_944[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_946 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_945[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_947 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_946[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_948 (Conv2D)             (None, 256, 256, 2)  98          conv2d_947[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_315 (Add)                   (None, 256, 256, 2)  0           conv2d_948[0][0]                 \n",
      "                                                                 add_314[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_158 (Multiply)         (None, 256, 256, 2)  0           add_315[0][0]                    \n",
      "                                                                 input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_316 (Add)                   (None, 256, 256, 2)  0           multiply_158[0][0]               \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_949 (Conv2D)             (None, 256, 256, 48) 912         add_316[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_950 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_949[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_951 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_950[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_952 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_953 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_952[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_954 (Conv2D)             (None, 256, 256, 2)  98          conv2d_953[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_317 (Add)                   (None, 256, 256, 2)  0           conv2d_954[0][0]                 \n",
      "                                                                 add_316[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_159 (Multiply)         (None, 256, 256, 2)  0           add_317[0][0]                    \n",
      "                                                                 input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_318 (Add)                   (None, 256, 256, 2)  0           multiply_159[0][0]               \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1331 (Lambda)            (None, 256, 256, 2)  0           add_318[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_955 (Conv2D)             (None, 256, 256, 48) 912         lambda_1331[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_956 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_955[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_957 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_956[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_958 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_957[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_959 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_958[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_960 (Conv2D)             (None, 256, 256, 2)  98          conv2d_959[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_319 (Add)                   (None, 256, 256, 2)  0           conv2d_960[0][0]                 \n",
      "                                                                 lambda_1331[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1336 (Lambda)            (None, 256, 256, 2)  0           add_319[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_160 (Multiply)         (None, 256, 256, 2)  0           lambda_1336[0][0]                \n",
      "                                                                 input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_320 (Add)                   (None, 256, 256, 2)  0           multiply_160[0][0]               \n",
      "                                                                 input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1341 (Lambda)            (None, 256, 256, 2)  0           add_320[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1346 (Lambda)            (None, 256, 256, 1)  0           lambda_1341[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kkki_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 125s 188ms/step - loss: 0.2151 - lambda_1341_loss: 0.2479 - lambda_1346_loss: 0.2151 - val_loss: 0.1681 - val_lambda_1341_loss: 0.2036 - val_lambda_1346_loss: 0.1681\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1601 - lambda_1341_loss: 0.1889 - lambda_1346_loss: 0.1601 - val_loss: 0.1487 - val_lambda_1341_loss: 0.1739 - val_lambda_1346_loss: 0.1487\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1456 - lambda_1341_loss: 0.1730 - lambda_1346_loss: 0.1456 - val_loss: 0.1379 - val_lambda_1341_loss: 0.1669 - val_lambda_1346_loss: 0.1379\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1398 - lambda_1341_loss: 0.1668 - lambda_1346_loss: 0.1398 - val_loss: 0.1306 - val_lambda_1341_loss: 0.1555 - val_lambda_1346_loss: 0.1306\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1333 - lambda_1341_loss: 0.1590 - lambda_1346_loss: 0.1333 - val_loss: 0.1270 - val_lambda_1341_loss: 0.1566 - val_lambda_1346_loss: 0.1270\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1317 - lambda_1341_loss: 0.1574 - lambda_1346_loss: 0.1317 - val_loss: 0.1320 - val_lambda_1341_loss: 0.1506 - val_lambda_1346_loss: 0.1320\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1284 - lambda_1341_loss: 0.1540 - lambda_1346_loss: 0.1284 - val_loss: 0.1285 - val_lambda_1341_loss: 0.1488 - val_lambda_1346_loss: 0.1285\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1283 - lambda_1341_loss: 0.1537 - lambda_1346_loss: 0.1283 - val_loss: 0.1223 - val_lambda_1341_loss: 0.1517 - val_lambda_1346_loss: 0.1223\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1230 - lambda_1341_loss: 0.1482 - lambda_1346_loss: 0.1230 - val_loss: 0.1191 - val_lambda_1341_loss: 0.1487 - val_lambda_1346_loss: 0.1191\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1207 - lambda_1341_loss: 0.1449 - lambda_1346_loss: 0.1207 - val_loss: 0.1250 - val_lambda_1341_loss: 0.1642 - val_lambda_1346_loss: 0.1250\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.1187 - lambda_1341_loss: 0.1432 - lambda_1346_loss: 0.1187 - val_loss: 0.1166 - val_lambda_1341_loss: 0.1429 - val_lambda_1346_loss: 0.1166\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1179 - lambda_1341_loss: 0.1414 - lambda_1346_loss: 0.1179 - val_loss: 0.1176 - val_lambda_1341_loss: 0.1438 - val_lambda_1346_loss: 0.1176\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1163 - lambda_1341_loss: 0.1396 - lambda_1346_loss: 0.1163 - val_loss: 0.1147 - val_lambda_1341_loss: 0.1453 - val_lambda_1346_loss: 0.1147\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1162 - lambda_1341_loss: 0.1398 - lambda_1346_loss: 0.1162 - val_loss: 0.1157 - val_lambda_1341_loss: 0.1454 - val_lambda_1346_loss: 0.1157\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1143 - lambda_1341_loss: 0.1370 - lambda_1346_loss: 0.1143 - val_loss: 0.1191 - val_lambda_1341_loss: 0.1485 - val_lambda_1346_loss: 0.1191\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1145 - lambda_1341_loss: 0.1373 - lambda_1346_loss: 0.1145 - val_loss: 0.1156 - val_lambda_1341_loss: 0.1464 - val_lambda_1346_loss: 0.1156\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1133 - lambda_1341_loss: 0.1357 - lambda_1346_loss: 0.1133 - val_loss: 0.1141 - val_lambda_1341_loss: 0.1393 - val_lambda_1346_loss: 0.1141\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1116 - lambda_1341_loss: 0.1340 - lambda_1346_loss: 0.1116 - val_loss: 0.1181 - val_lambda_1341_loss: 0.1428 - val_lambda_1346_loss: 0.1181\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1109 - lambda_1341_loss: 0.1328 - lambda_1346_loss: 0.1109 - val_loss: 0.1118 - val_lambda_1341_loss: 0.1365 - val_lambda_1346_loss: 0.1118\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1101 - lambda_1341_loss: 0.1314 - lambda_1346_loss: 0.1101 - val_loss: 0.1134 - val_lambda_1341_loss: 0.1364 - val_lambda_1346_loss: 0.1134\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1097 - lambda_1341_loss: 0.1311 - lambda_1346_loss: 0.1097 - val_loss: 0.1121 - val_lambda_1341_loss: 0.1296 - val_lambda_1346_loss: 0.1121\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1095 - lambda_1341_loss: 0.1310 - lambda_1346_loss: 0.1095 - val_loss: 0.1083 - val_lambda_1341_loss: 0.1298 - val_lambda_1346_loss: 0.1083\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1083 - lambda_1341_loss: 0.1291 - lambda_1346_loss: 0.1083 - val_loss: 0.1100 - val_lambda_1341_loss: 0.1354 - val_lambda_1346_loss: 0.1100\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1083 - lambda_1341_loss: 0.1293 - lambda_1346_loss: 0.1083 - val_loss: 0.1107 - val_lambda_1341_loss: 0.1355 - val_lambda_1346_loss: 0.1107\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1087 - lambda_1341_loss: 0.1299 - lambda_1346_loss: 0.1087 - val_loss: 0.1129 - val_lambda_1341_loss: 0.1396 - val_lambda_1346_loss: 0.1129\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1071 - lambda_1341_loss: 0.1283 - lambda_1346_loss: 0.1071 - val_loss: 0.1087 - val_lambda_1341_loss: 0.1274 - val_lambda_1346_loss: 0.1087\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1078 - lambda_1341_loss: 0.1288 - lambda_1346_loss: 0.1078 - val_loss: 0.1050 - val_lambda_1341_loss: 0.1245 - val_lambda_1346_loss: 0.1050\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1071 - lambda_1341_loss: 0.1278 - lambda_1346_loss: 0.1071 - val_loss: 0.1150 - val_lambda_1341_loss: 0.1339 - val_lambda_1346_loss: 0.1150\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.1053 - lambda_1341_loss: 0.1256 - lambda_1346_loss: 0.1053 - val_loss: 0.1077 - val_lambda_1341_loss: 0.1314 - val_lambda_1346_loss: 0.1077\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1043 - lambda_1341_loss: 0.1245 - lambda_1346_loss: 0.1043 - val_loss: 0.1075 - val_lambda_1341_loss: 0.1313 - val_lambda_1346_loss: 0.1075\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.1056 - lambda_1341_loss: 0.1259 - lambda_1346_loss: 0.1056 - val_loss: 0.1076 - val_lambda_1341_loss: 0.1267 - val_lambda_1346_loss: 0.1076\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1049 - lambda_1341_loss: 0.1249 - lambda_1346_loss: 0.1049 - val_loss: 0.1076 - val_lambda_1341_loss: 0.1268 - val_lambda_1346_loss: 0.1076\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1037 - lambda_1341_loss: 0.1235 - lambda_1346_loss: 0.1037 - val_loss: 0.1063 - val_lambda_1341_loss: 0.1288 - val_lambda_1346_loss: 0.1063\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1041 - lambda_1341_loss: 0.1245 - lambda_1346_loss: 0.1041 - val_loss: 0.1023 - val_lambda_1341_loss: 0.1239 - val_lambda_1346_loss: 0.1023\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1028 - lambda_1341_loss: 0.1222 - lambda_1346_loss: 0.1028 - val_loss: 0.1052 - val_lambda_1341_loss: 0.1302 - val_lambda_1346_loss: 0.1052\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.1027 - lambda_1341_loss: 0.1223 - lambda_1346_loss: 0.1027 - val_loss: 0.1054 - val_lambda_1341_loss: 0.1251 - val_lambda_1346_loss: 0.1054\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1019 - lambda_1341_loss: 0.1216 - lambda_1346_loss: 0.1019 - val_loss: 0.1035 - val_lambda_1341_loss: 0.1241 - val_lambda_1346_loss: 0.1035\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1028 - lambda_1341_loss: 0.1223 - lambda_1346_loss: 0.1028 - val_loss: 0.1066 - val_lambda_1341_loss: 0.1325 - val_lambda_1346_loss: 0.1066\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1030 - lambda_1341_loss: 0.1225 - lambda_1346_loss: 0.1030 - val_loss: 0.1076 - val_lambda_1341_loss: 0.1303 - val_lambda_1346_loss: 0.1076\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1014 - lambda_1341_loss: 0.1208 - lambda_1346_loss: 0.1014 - val_loss: 0.1011 - val_lambda_1341_loss: 0.1227 - val_lambda_1346_loss: 0.1011\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1002 - lambda_1341_loss: 0.1189 - lambda_1346_loss: 0.1002 - val_loss: 0.1019 - val_lambda_1341_loss: 0.1240 - val_lambda_1346_loss: 0.1019\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1015 - lambda_1341_loss: 0.1210 - lambda_1346_loss: 0.1015 - val_loss: 0.1022 - val_lambda_1341_loss: 0.1229 - val_lambda_1346_loss: 0.1022\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1009 - lambda_1341_loss: 0.1203 - lambda_1346_loss: 0.1009 - val_loss: 0.1033 - val_lambda_1341_loss: 0.1274 - val_lambda_1346_loss: 0.1033\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1002 - lambda_1341_loss: 0.1190 - lambda_1346_loss: 0.1002 - val_loss: 0.1019 - val_lambda_1341_loss: 0.1261 - val_lambda_1346_loss: 0.1019\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1016 - lambda_1341_loss: 0.1206 - lambda_1346_loss: 0.1016 - val_loss: 0.1026 - val_lambda_1341_loss: 0.1211 - val_lambda_1346_loss: 0.1026\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.1002 - lambda_1341_loss: 0.1188 - lambda_1346_loss: 0.1002 - val_loss: 0.1001 - val_lambda_1341_loss: 0.1172 - val_lambda_1346_loss: 0.1001\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0997 - lambda_1341_loss: 0.1184 - lambda_1346_loss: 0.0997 - val_loss: 0.1008 - val_lambda_1341_loss: 0.1205 - val_lambda_1346_loss: 0.1008\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 109s 163ms/step - loss: 0.0990 - lambda_1341_loss: 0.1178 - lambda_1346_loss: 0.0990 - val_loss: 0.1014 - val_lambda_1341_loss: 0.1224 - val_lambda_1346_loss: 0.1014\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 108s 163ms/step - loss: 0.0983 - lambda_1341_loss: 0.1165 - lambda_1346_loss: 0.0983 - val_loss: 0.1016 - val_lambda_1341_loss: 0.1215 - val_lambda_1346_loss: 0.1016\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.0986 - lambda_1341_loss: 0.1170 - lambda_1346_loss: 0.0986 - val_loss: 0.1005 - val_lambda_1341_loss: 0.1198 - val_lambda_1346_loss: 0.1005\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_103 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_961 (Conv2D)             (None, 256, 256, 48) 912         input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_962 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_963 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_962[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_964 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_963[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_965 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_964[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_966 (Conv2D)             (None, 256, 256, 2)  98          conv2d_965[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_321 (Add)                   (None, 256, 256, 2)  0           conv2d_966[0][0]                 \n",
      "                                                                 input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_104 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_161 (Multiply)         (None, 256, 256, 2)  0           add_321[0][0]                    \n",
      "                                                                 input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_322 (Add)                   (None, 256, 256, 2)  0           multiply_161[0][0]               \n",
      "                                                                 input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1351 (Lambda)            (None, 256, 256, 2)  0           add_322[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_967 (Conv2D)             (None, 256, 256, 48) 912         lambda_1351[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_968 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_967[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_969 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_968[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_970 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_969[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_971 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_970[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_972 (Conv2D)             (None, 256, 256, 2)  98          conv2d_971[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_323 (Add)                   (None, 256, 256, 2)  0           conv2d_972[0][0]                 \n",
      "                                                                 lambda_1351[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1356 (Lambda)            (None, 256, 256, 2)  0           add_323[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_162 (Multiply)         (None, 256, 256, 2)  0           lambda_1356[0][0]                \n",
      "                                                                 input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_324 (Add)                   (None, 256, 256, 2)  0           multiply_162[0][0]               \n",
      "                                                                 input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1361 (Lambda)            (None, 256, 256, 2)  0           add_324[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_973 (Conv2D)             (None, 256, 256, 48) 912         lambda_1361[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_974 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_973[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_975 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_974[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_976 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_975[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_977 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_976[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_978 (Conv2D)             (None, 256, 256, 2)  98          conv2d_977[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_325 (Add)                   (None, 256, 256, 2)  0           conv2d_978[0][0]                 \n",
      "                                                                 lambda_1361[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1366 (Lambda)            (None, 256, 256, 2)  0           add_325[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_163 (Multiply)         (None, 256, 256, 2)  0           lambda_1366[0][0]                \n",
      "                                                                 input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_326 (Add)                   (None, 256, 256, 2)  0           multiply_163[0][0]               \n",
      "                                                                 input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_979 (Conv2D)             (None, 256, 256, 48) 912         add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_980 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_979[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_981 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_980[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_982 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_983 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_982[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_984 (Conv2D)             (None, 256, 256, 2)  98          conv2d_983[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_327 (Add)                   (None, 256, 256, 2)  0           conv2d_984[0][0]                 \n",
      "                                                                 add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_164 (Multiply)         (None, 256, 256, 2)  0           add_327[0][0]                    \n",
      "                                                                 input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 256, 256, 2)  0           multiply_164[0][0]               \n",
      "                                                                 input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1371 (Lambda)            (None, 256, 256, 2)  0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1376 (Lambda)            (None, 256, 256, 1)  0           lambda_1371[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 127s 190ms/step - loss: 0.1729 - lambda_1371_loss: 0.2003 - lambda_1376_loss: 0.1729 - val_loss: 0.1334 - val_lambda_1371_loss: 0.1567 - val_lambda_1376_loss: 0.1334\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1196 - lambda_1371_loss: 0.1404 - lambda_1376_loss: 0.1196 - val_loss: 0.1205 - val_lambda_1371_loss: 0.1377 - val_lambda_1376_loss: 0.1205\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.1074 - lambda_1371_loss: 0.1263 - lambda_1376_loss: 0.1074 - val_loss: 0.1046 - val_lambda_1371_loss: 0.1237 - val_lambda_1376_loss: 0.1046\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.1009 - lambda_1371_loss: 0.1186 - lambda_1376_loss: 0.1009 - val_loss: 0.0987 - val_lambda_1371_loss: 0.1140 - val_lambda_1376_loss: 0.0987\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0963 - lambda_1371_loss: 0.1136 - lambda_1376_loss: 0.0963 - val_loss: 0.0985 - val_lambda_1371_loss: 0.1145 - val_lambda_1376_loss: 0.0985\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0939 - lambda_1371_loss: 0.1111 - lambda_1376_loss: 0.0939 - val_loss: 0.0942 - val_lambda_1371_loss: 0.1091 - val_lambda_1376_loss: 0.0942\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0911 - lambda_1371_loss: 0.1079 - lambda_1376_loss: 0.0911 - val_loss: 0.0954 - val_lambda_1371_loss: 0.1192 - val_lambda_1376_loss: 0.0954\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0897 - lambda_1371_loss: 0.1060 - lambda_1376_loss: 0.0897 - val_loss: 0.0969 - val_lambda_1371_loss: 0.1137 - val_lambda_1376_loss: 0.0969\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0885 - lambda_1371_loss: 0.1044 - lambda_1376_loss: 0.0885 - val_loss: 0.0980 - val_lambda_1371_loss: 0.1141 - val_lambda_1376_loss: 0.0980\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0860 - lambda_1371_loss: 0.1017 - lambda_1376_loss: 0.0860 - val_loss: 0.0937 - val_lambda_1371_loss: 0.1109 - val_lambda_1376_loss: 0.0937\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 110s 166ms/step - loss: 0.0852 - lambda_1371_loss: 0.1003 - lambda_1376_loss: 0.0852 - val_loss: 0.0928 - val_lambda_1371_loss: 0.1098 - val_lambda_1376_loss: 0.0928\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0836 - lambda_1371_loss: 0.0988 - lambda_1376_loss: 0.0836 - val_loss: 0.0902 - val_lambda_1371_loss: 0.1084 - val_lambda_1376_loss: 0.0902\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0819 - lambda_1371_loss: 0.0970 - lambda_1376_loss: 0.0819 - val_loss: 0.0935 - val_lambda_1371_loss: 0.1101 - val_lambda_1376_loss: 0.0935\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0815 - lambda_1371_loss: 0.0961 - lambda_1376_loss: 0.0815 - val_loss: 0.0925 - val_lambda_1371_loss: 0.1055 - val_lambda_1376_loss: 0.0925\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0804 - lambda_1371_loss: 0.0947 - lambda_1376_loss: 0.0804 - val_loss: 0.0909 - val_lambda_1371_loss: 0.1039 - val_lambda_1376_loss: 0.0909\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0799 - lambda_1371_loss: 0.0945 - lambda_1376_loss: 0.0799 - val_loss: 0.0903 - val_lambda_1371_loss: 0.1099 - val_lambda_1376_loss: 0.0903\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0791 - lambda_1371_loss: 0.0933 - lambda_1376_loss: 0.0791 - val_loss: 0.0850 - val_lambda_1371_loss: 0.1007 - val_lambda_1376_loss: 0.0850\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0779 - lambda_1371_loss: 0.0924 - lambda_1376_loss: 0.0779 - val_loss: 0.0900 - val_lambda_1371_loss: 0.1099 - val_lambda_1376_loss: 0.0900\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0770 - lambda_1371_loss: 0.0912 - lambda_1376_loss: 0.0770 - val_loss: 0.0921 - val_lambda_1371_loss: 0.1062 - val_lambda_1376_loss: 0.0921\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0773 - lambda_1371_loss: 0.0908 - lambda_1376_loss: 0.0773 - val_loss: 0.0802 - val_lambda_1371_loss: 0.0933 - val_lambda_1376_loss: 0.0802\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0769 - lambda_1371_loss: 0.0909 - lambda_1376_loss: 0.0769 - val_loss: 0.0859 - val_lambda_1371_loss: 0.1103 - val_lambda_1376_loss: 0.0859\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0756 - lambda_1371_loss: 0.0891 - lambda_1376_loss: 0.0756 - val_loss: 0.0870 - val_lambda_1371_loss: 0.1043 - val_lambda_1376_loss: 0.0870\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0754 - lambda_1371_loss: 0.0892 - lambda_1376_loss: 0.0754 - val_loss: 0.0850 - val_lambda_1371_loss: 0.1010 - val_lambda_1376_loss: 0.0850\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0752 - lambda_1371_loss: 0.0885 - lambda_1376_loss: 0.0752 - val_loss: 0.0874 - val_lambda_1371_loss: 0.1026 - val_lambda_1376_loss: 0.0874\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0758 - lambda_1371_loss: 0.0900 - lambda_1376_loss: 0.0758 - val_loss: 0.0832 - val_lambda_1371_loss: 0.0993 - val_lambda_1376_loss: 0.0832\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0744 - lambda_1371_loss: 0.0880 - lambda_1376_loss: 0.0744 - val_loss: 0.0862 - val_lambda_1371_loss: 0.0981 - val_lambda_1376_loss: 0.0862\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0743 - lambda_1371_loss: 0.0879 - lambda_1376_loss: 0.0743 - val_loss: 0.0912 - val_lambda_1371_loss: 0.1093 - val_lambda_1376_loss: 0.0912\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0739 - lambda_1371_loss: 0.0884 - lambda_1376_loss: 0.0739 - val_loss: 0.0789 - val_lambda_1371_loss: 0.0898 - val_lambda_1376_loss: 0.0789\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0726 - lambda_1371_loss: 0.0859 - lambda_1376_loss: 0.0726 - val_loss: 0.0796 - val_lambda_1371_loss: 0.0932 - val_lambda_1376_loss: 0.0796\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0723 - lambda_1371_loss: 0.0861 - lambda_1376_loss: 0.0723 - val_loss: 0.0872 - val_lambda_1371_loss: 0.1020 - val_lambda_1376_loss: 0.0872\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0716 - lambda_1371_loss: 0.0851 - lambda_1376_loss: 0.0716 - val_loss: 0.0808 - val_lambda_1371_loss: 0.0966 - val_lambda_1376_loss: 0.0808\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0712 - lambda_1371_loss: 0.0841 - lambda_1376_loss: 0.0712 - val_loss: 0.0824 - val_lambda_1371_loss: 0.1170 - val_lambda_1376_loss: 0.0824\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0712 - lambda_1371_loss: 0.0843 - lambda_1376_loss: 0.0712 - val_loss: 0.0818 - val_lambda_1371_loss: 0.0982 - val_lambda_1376_loss: 0.0818\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0696 - lambda_1371_loss: 0.0824 - lambda_1376_loss: 0.0696 - val_loss: 0.0799 - val_lambda_1371_loss: 0.1004 - val_lambda_1376_loss: 0.0799\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0694 - lambda_1371_loss: 0.0820 - lambda_1376_loss: 0.0694 - val_loss: 0.0783 - val_lambda_1371_loss: 0.0895 - val_lambda_1376_loss: 0.0783\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0690 - lambda_1371_loss: 0.0817 - lambda_1376_loss: 0.0690 - val_loss: 0.0758 - val_lambda_1371_loss: 0.0893 - val_lambda_1376_loss: 0.0758\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0695 - lambda_1371_loss: 0.0822 - lambda_1376_loss: 0.0695 - val_loss: 0.0760 - val_lambda_1371_loss: 0.0873 - val_lambda_1376_loss: 0.0760\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0687 - lambda_1371_loss: 0.0812 - lambda_1376_loss: 0.0687 - val_loss: 0.0820 - val_lambda_1371_loss: 0.0943 - val_lambda_1376_loss: 0.0820\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0681 - lambda_1371_loss: 0.0802 - lambda_1376_loss: 0.0681 - val_loss: 0.0735 - val_lambda_1371_loss: 0.0860 - val_lambda_1376_loss: 0.0735\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0685 - lambda_1371_loss: 0.0806 - lambda_1376_loss: 0.0685 - val_loss: 0.0767 - val_lambda_1371_loss: 0.0932 - val_lambda_1376_loss: 0.0767\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0681 - lambda_1371_loss: 0.0802 - lambda_1376_loss: 0.0681 - val_loss: 0.0764 - val_lambda_1371_loss: 0.0883 - val_lambda_1376_loss: 0.0764\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0679 - lambda_1371_loss: 0.0796 - lambda_1376_loss: 0.0679 - val_loss: 0.0755 - val_lambda_1371_loss: 0.0891 - val_lambda_1376_loss: 0.0755\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0680 - lambda_1371_loss: 0.0796 - lambda_1376_loss: 0.0680 - val_loss: 0.0775 - val_lambda_1371_loss: 0.0886 - val_lambda_1376_loss: 0.0775\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0678 - lambda_1371_loss: 0.0795 - lambda_1376_loss: 0.0678 - val_loss: 0.0758 - val_lambda_1371_loss: 0.0974 - val_lambda_1376_loss: 0.0758\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0670 - lambda_1371_loss: 0.0790 - lambda_1376_loss: 0.0670 - val_loss: 0.0749 - val_lambda_1371_loss: 0.0861 - val_lambda_1376_loss: 0.0749\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0674 - lambda_1371_loss: 0.0789 - lambda_1376_loss: 0.0674 - val_loss: 0.0744 - val_lambda_1371_loss: 0.0882 - val_lambda_1376_loss: 0.0744\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0679 - lambda_1371_loss: 0.0800 - lambda_1376_loss: 0.0679 - val_loss: 0.0827 - val_lambda_1371_loss: 0.0950 - val_lambda_1376_loss: 0.0827\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0657 - lambda_1371_loss: 0.0764 - lambda_1376_loss: 0.0657 - val_loss: 0.0784 - val_lambda_1371_loss: 0.0904 - val_lambda_1376_loss: 0.0784\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0666 - lambda_1371_loss: 0.0780 - lambda_1376_loss: 0.0666 - val_loss: 0.0738 - val_lambda_1371_loss: 0.0851 - val_lambda_1376_loss: 0.0738\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0667 - lambda_1371_loss: 0.0780 - lambda_1376_loss: 0.0667 - val_loss: 0.0826 - val_lambda_1371_loss: 0.0976 - val_lambda_1376_loss: 0.0826\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_105 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_985 (Conv2D)             (None, 256, 256, 48) 912         input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_986 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_985[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_987 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_986[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_988 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_987[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_989 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_988[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_990 (Conv2D)             (None, 256, 256, 2)  98          conv2d_989[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 256, 256, 2)  0           conv2d_990[0][0]                 \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_106 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_165 (Multiply)         (None, 256, 256, 2)  0           add_329[0][0]                    \n",
      "                                                                 input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 256, 256, 2)  0           multiply_165[0][0]               \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1381 (Lambda)            (None, 256, 256, 2)  0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_991 (Conv2D)             (None, 256, 256, 48) 912         lambda_1381[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_992 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_991[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_993 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_992[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_994 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_993[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_995 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_994[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_996 (Conv2D)             (None, 256, 256, 2)  98          conv2d_995[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_331 (Add)                   (None, 256, 256, 2)  0           conv2d_996[0][0]                 \n",
      "                                                                 lambda_1381[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1386 (Lambda)            (None, 256, 256, 2)  0           add_331[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_166 (Multiply)         (None, 256, 256, 2)  0           lambda_1386[0][0]                \n",
      "                                                                 input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_332 (Add)                   (None, 256, 256, 2)  0           multiply_166[0][0]               \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_997 (Conv2D)             (None, 256, 256, 48) 912         add_332[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_998 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_997[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_999 (Conv2D)             (None, 256, 256, 48) 20784       conv2d_998[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1000 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_999[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1001 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1000[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1002 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1001[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_333 (Add)                   (None, 256, 256, 2)  0           conv2d_1002[0][0]                \n",
      "                                                                 add_332[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_167 (Multiply)         (None, 256, 256, 2)  0           add_333[0][0]                    \n",
      "                                                                 input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_334 (Add)                   (None, 256, 256, 2)  0           multiply_167[0][0]               \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1391 (Lambda)            (None, 256, 256, 2)  0           add_334[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1003 (Conv2D)            (None, 256, 256, 48) 912         lambda_1391[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1004 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1003[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1005 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1004[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1006 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1005[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1007 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1006[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1008 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1007[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_335 (Add)                   (None, 256, 256, 2)  0           conv2d_1008[0][0]                \n",
      "                                                                 lambda_1391[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1396 (Lambda)            (None, 256, 256, 2)  0           add_335[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_168 (Multiply)         (None, 256, 256, 2)  0           lambda_1396[0][0]                \n",
      "                                                                 input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_336 (Add)                   (None, 256, 256, 2)  0           multiply_168[0][0]               \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1401 (Lambda)            (None, 256, 256, 2)  0           add_336[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1406 (Lambda)            (None, 256, 256, 1)  0           lambda_1401[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiki_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 128s 192ms/step - loss: 0.1664 - lambda_1401_loss: 0.1928 - lambda_1406_loss: 0.1664 - val_loss: 0.1244 - val_lambda_1401_loss: 0.1558 - val_lambda_1406_loss: 0.1244\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.1175 - lambda_1401_loss: 0.1393 - lambda_1406_loss: 0.1175 - val_loss: 0.1080 - val_lambda_1401_loss: 0.1320 - val_lambda_1406_loss: 0.1080\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.1070 - lambda_1401_loss: 0.1256 - lambda_1406_loss: 0.1070 - val_loss: 0.1084 - val_lambda_1401_loss: 0.1277 - val_lambda_1406_loss: 0.1084\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.1000 - lambda_1401_loss: 0.1176 - lambda_1406_loss: 0.1000 - val_loss: 0.1017 - val_lambda_1401_loss: 0.1159 - val_lambda_1406_loss: 0.1017\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0949 - lambda_1401_loss: 0.1115 - lambda_1406_loss: 0.0949 - val_loss: 0.0949 - val_lambda_1401_loss: 0.1097 - val_lambda_1406_loss: 0.0949\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0942 - lambda_1401_loss: 0.1116 - lambda_1406_loss: 0.0942 - val_loss: 0.0925 - val_lambda_1401_loss: 0.1123 - val_lambda_1406_loss: 0.0925\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0908 - lambda_1401_loss: 0.1070 - lambda_1406_loss: 0.0908 - val_loss: 0.0930 - val_lambda_1401_loss: 0.1151 - val_lambda_1406_loss: 0.0930\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0891 - lambda_1401_loss: 0.1052 - lambda_1406_loss: 0.0891 - val_loss: 0.0939 - val_lambda_1401_loss: 0.1097 - val_lambda_1406_loss: 0.0939\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0865 - lambda_1401_loss: 0.1020 - lambda_1406_loss: 0.0865 - val_loss: 0.0904 - val_lambda_1401_loss: 0.1120 - val_lambda_1406_loss: 0.0904\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0854 - lambda_1401_loss: 0.1005 - lambda_1406_loss: 0.0854 - val_loss: 0.0920 - val_lambda_1401_loss: 0.1064 - val_lambda_1406_loss: 0.0920\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0841 - lambda_1401_loss: 0.0997 - lambda_1406_loss: 0.0841 - val_loss: 0.0873 - val_lambda_1401_loss: 0.1049 - val_lambda_1406_loss: 0.0873\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0830 - lambda_1401_loss: 0.0978 - lambda_1406_loss: 0.0830 - val_loss: 0.0865 - val_lambda_1401_loss: 0.1079 - val_lambda_1406_loss: 0.0865\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0823 - lambda_1401_loss: 0.0972 - lambda_1406_loss: 0.0823 - val_loss: 0.0852 - val_lambda_1401_loss: 0.1004 - val_lambda_1406_loss: 0.0852\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0804 - lambda_1401_loss: 0.0950 - lambda_1406_loss: 0.0804 - val_loss: 0.0873 - val_lambda_1401_loss: 0.1063 - val_lambda_1406_loss: 0.0873\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0798 - lambda_1401_loss: 0.0944 - lambda_1406_loss: 0.0798 - val_loss: 0.0985 - val_lambda_1401_loss: 0.1157 - val_lambda_1406_loss: 0.0985\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0790 - lambda_1401_loss: 0.0934 - lambda_1406_loss: 0.0790 - val_loss: 0.0884 - val_lambda_1401_loss: 0.1063 - val_lambda_1406_loss: 0.0884\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0781 - lambda_1401_loss: 0.0923 - lambda_1406_loss: 0.0781 - val_loss: 0.0934 - val_lambda_1401_loss: 0.1116 - val_lambda_1406_loss: 0.0934\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0786 - lambda_1401_loss: 0.0928 - lambda_1406_loss: 0.0786 - val_loss: 0.0860 - val_lambda_1401_loss: 0.1056 - val_lambda_1406_loss: 0.0860\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0768 - lambda_1401_loss: 0.0907 - lambda_1406_loss: 0.0768 - val_loss: 0.0850 - val_lambda_1401_loss: 0.1050 - val_lambda_1406_loss: 0.0850\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0760 - lambda_1401_loss: 0.0899 - lambda_1406_loss: 0.0760 - val_loss: 0.0831 - val_lambda_1401_loss: 0.0986 - val_lambda_1406_loss: 0.0831\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0758 - lambda_1401_loss: 0.0893 - lambda_1406_loss: 0.0758 - val_loss: 0.0862 - val_lambda_1401_loss: 0.1033 - val_lambda_1406_loss: 0.0862\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0743 - lambda_1401_loss: 0.0874 - lambda_1406_loss: 0.0743 - val_loss: 0.0790 - val_lambda_1401_loss: 0.0929 - val_lambda_1406_loss: 0.0790\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0746 - lambda_1401_loss: 0.0883 - lambda_1406_loss: 0.0746 - val_loss: 0.0802 - val_lambda_1401_loss: 0.0927 - val_lambda_1406_loss: 0.0802\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0739 - lambda_1401_loss: 0.0872 - lambda_1406_loss: 0.0739 - val_loss: 0.0906 - val_lambda_1401_loss: 0.1050 - val_lambda_1406_loss: 0.0906\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0740 - lambda_1401_loss: 0.0872 - lambda_1406_loss: 0.0740 - val_loss: 0.0865 - val_lambda_1401_loss: 0.1032 - val_lambda_1406_loss: 0.0865\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0731 - lambda_1401_loss: 0.0863 - lambda_1406_loss: 0.0731 - val_loss: 0.0823 - val_lambda_1401_loss: 0.0933 - val_lambda_1406_loss: 0.0823\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0725 - lambda_1401_loss: 0.0854 - lambda_1406_loss: 0.0725 - val_loss: 0.0804 - val_lambda_1401_loss: 0.0942 - val_lambda_1406_loss: 0.0804\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0726 - lambda_1401_loss: 0.0859 - lambda_1406_loss: 0.0726 - val_loss: 0.0887 - val_lambda_1401_loss: 0.1055 - val_lambda_1406_loss: 0.0887\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0721 - lambda_1401_loss: 0.0849 - lambda_1406_loss: 0.0721 - val_loss: 0.0800 - val_lambda_1401_loss: 0.0945 - val_lambda_1406_loss: 0.0800\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0713 - lambda_1401_loss: 0.0844 - lambda_1406_loss: 0.0713 - val_loss: 0.0771 - val_lambda_1401_loss: 0.0899 - val_lambda_1406_loss: 0.0771\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0715 - lambda_1401_loss: 0.0847 - lambda_1406_loss: 0.0715 - val_loss: 0.0829 - val_lambda_1401_loss: 0.0990 - val_lambda_1406_loss: 0.0829\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0712 - lambda_1401_loss: 0.0840 - lambda_1406_loss: 0.0712 - val_loss: 0.0814 - val_lambda_1401_loss: 0.0950 - val_lambda_1406_loss: 0.0814\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0700 - lambda_1401_loss: 0.0828 - lambda_1406_loss: 0.0700 - val_loss: 0.0777 - val_lambda_1401_loss: 0.0895 - val_lambda_1406_loss: 0.0777\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0698 - lambda_1401_loss: 0.0825 - lambda_1406_loss: 0.0698 - val_loss: 0.0881 - val_lambda_1401_loss: 0.1028 - val_lambda_1406_loss: 0.0881\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0704 - lambda_1401_loss: 0.0834 - lambda_1406_loss: 0.0704 - val_loss: 0.0825 - val_lambda_1401_loss: 0.0971 - val_lambda_1406_loss: 0.0825\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0696 - lambda_1401_loss: 0.0820 - lambda_1406_loss: 0.0696 - val_loss: 0.0758 - val_lambda_1401_loss: 0.0900 - val_lambda_1406_loss: 0.0758\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0697 - lambda_1401_loss: 0.0822 - lambda_1406_loss: 0.0697 - val_loss: 0.0767 - val_lambda_1401_loss: 0.0910 - val_lambda_1406_loss: 0.0767\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0697 - lambda_1401_loss: 0.0821 - lambda_1406_loss: 0.0697 - val_loss: 0.0773 - val_lambda_1401_loss: 0.0903 - val_lambda_1406_loss: 0.0773\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0683 - lambda_1401_loss: 0.0804 - lambda_1406_loss: 0.0683 - val_loss: 0.0757 - val_lambda_1401_loss: 0.0887 - val_lambda_1406_loss: 0.0757\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0687 - lambda_1401_loss: 0.0808 - lambda_1406_loss: 0.0687 - val_loss: 0.0757 - val_lambda_1401_loss: 0.0893 - val_lambda_1406_loss: 0.0757\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0681 - lambda_1401_loss: 0.0804 - lambda_1406_loss: 0.0681 - val_loss: 0.0755 - val_lambda_1401_loss: 0.0875 - val_lambda_1406_loss: 0.0755\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0680 - lambda_1401_loss: 0.0803 - lambda_1406_loss: 0.0680 - val_loss: 0.0743 - val_lambda_1401_loss: 0.0860 - val_lambda_1406_loss: 0.0743\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0681 - lambda_1401_loss: 0.0801 - lambda_1406_loss: 0.0681 - val_loss: 0.0825 - val_lambda_1401_loss: 0.0964 - val_lambda_1406_loss: 0.0825\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0677 - lambda_1401_loss: 0.0797 - lambda_1406_loss: 0.0677 - val_loss: 0.0759 - val_lambda_1401_loss: 0.0887 - val_lambda_1406_loss: 0.0759\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0676 - lambda_1401_loss: 0.0796 - lambda_1406_loss: 0.0676 - val_loss: 0.0772 - val_lambda_1401_loss: 0.0904 - val_lambda_1406_loss: 0.0772\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0675 - lambda_1401_loss: 0.0795 - lambda_1406_loss: 0.0675 - val_loss: 0.0768 - val_lambda_1401_loss: 0.0905 - val_lambda_1406_loss: 0.0768\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 109s 164ms/step - loss: 0.0673 - lambda_1401_loss: 0.0793 - lambda_1406_loss: 0.0673 - val_loss: 0.0743 - val_lambda_1401_loss: 0.0859 - val_lambda_1406_loss: 0.0743\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0672 - lambda_1401_loss: 0.0791 - lambda_1406_loss: 0.0672 - val_loss: 0.0758 - val_lambda_1401_loss: 0.0911 - val_lambda_1406_loss: 0.0758\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0662 - lambda_1401_loss: 0.0780 - lambda_1406_loss: 0.0662 - val_loss: 0.0746 - val_lambda_1401_loss: 0.0855 - val_lambda_1406_loss: 0.0746\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0668 - lambda_1401_loss: 0.0786 - lambda_1406_loss: 0.0668 - val_loss: 0.0780 - val_lambda_1401_loss: 0.0903 - val_lambda_1406_loss: 0.0780\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_107 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1009 (Conv2D)            (None, 256, 256, 48) 912         input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1010 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1009[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1011 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1010[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1012 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1011[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1013 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1012[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1014 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1013[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_337 (Add)                   (None, 256, 256, 2)  0           conv2d_1014[0][0]                \n",
      "                                                                 input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_108 (InputLayer)          (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_169 (Multiply)         (None, 256, 256, 2)  0           add_337[0][0]                    \n",
      "                                                                 input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_338 (Add)                   (None, 256, 256, 2)  0           multiply_169[0][0]               \n",
      "                                                                 input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1411 (Lambda)            (None, 256, 256, 2)  0           add_338[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1015 (Conv2D)            (None, 256, 256, 48) 912         lambda_1411[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1016 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1015[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1017 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1016[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1018 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1017[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1019 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1018[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1020 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1019[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_339 (Add)                   (None, 256, 256, 2)  0           conv2d_1020[0][0]                \n",
      "                                                                 lambda_1411[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1416 (Lambda)            (None, 256, 256, 2)  0           add_339[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_170 (Multiply)         (None, 256, 256, 2)  0           lambda_1416[0][0]                \n",
      "                                                                 input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_340 (Add)                   (None, 256, 256, 2)  0           multiply_170[0][0]               \n",
      "                                                                 input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1421 (Lambda)            (None, 256, 256, 2)  0           add_340[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1021 (Conv2D)            (None, 256, 256, 48) 912         lambda_1421[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1022 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1021[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1023 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1022[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1024 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1023[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1025 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1024[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1026 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1025[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_341 (Add)                   (None, 256, 256, 2)  0           conv2d_1026[0][0]                \n",
      "                                                                 lambda_1421[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1426 (Lambda)            (None, 256, 256, 2)  0           add_341[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_171 (Multiply)         (None, 256, 256, 2)  0           lambda_1426[0][0]                \n",
      "                                                                 input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_342 (Add)                   (None, 256, 256, 2)  0           multiply_171[0][0]               \n",
      "                                                                 input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1027 (Conv2D)            (None, 256, 256, 48) 912         add_342[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1028 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1027[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1029 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1028[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1030 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1029[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1031 (Conv2D)            (None, 256, 256, 48) 20784       conv2d_1030[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1032 (Conv2D)            (None, 256, 256, 2)  98          conv2d_1031[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_343 (Add)                   (None, 256, 256, 2)  0           conv2d_1032[0][0]                \n",
      "                                                                 add_342[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_172 (Multiply)         (None, 256, 256, 2)  0           add_343[0][0]                    \n",
      "                                                                 input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_344 (Add)                   (None, 256, 256, 2)  0           multiply_172[0][0]               \n",
      "                                                                 input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1431 (Lambda)            (None, 256, 256, 2)  0           add_344[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1436 (Lambda)            (None, 256, 256, 1)  0           lambda_1431[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 336,584\n",
      "Trainable params: 336,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "../Models/flat_unrolled_cascade_kiik_gaussian_25.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "667/667 [==============================] - 129s 193ms/step - loss: 0.1696 - lambda_1431_loss: 0.1968 - lambda_1436_loss: 0.1696 - val_loss: 0.1278 - val_lambda_1431_loss: 0.1510 - val_lambda_1436_loss: 0.1278\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.1171 - lambda_1431_loss: 0.1378 - lambda_1436_loss: 0.1171 - val_loss: 0.1132 - val_lambda_1431_loss: 0.1294 - val_lambda_1436_loss: 0.1132\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 110s 166ms/step - loss: 0.1066 - lambda_1431_loss: 0.1257 - lambda_1436_loss: 0.1066 - val_loss: 0.1032 - val_lambda_1431_loss: 0.1215 - val_lambda_1436_loss: 0.1032\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.1000 - lambda_1431_loss: 0.1173 - lambda_1436_loss: 0.1000 - val_loss: 0.1084 - val_lambda_1431_loss: 0.1260 - val_lambda_1436_loss: 0.1084\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0975 - lambda_1431_loss: 0.1154 - lambda_1436_loss: 0.0975 - val_loss: 0.1005 - val_lambda_1431_loss: 0.1177 - val_lambda_1436_loss: 0.1005\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0928 - lambda_1431_loss: 0.1089 - lambda_1436_loss: 0.0928 - val_loss: 0.0962 - val_lambda_1431_loss: 0.1141 - val_lambda_1436_loss: 0.0962\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0922 - lambda_1431_loss: 0.1085 - lambda_1436_loss: 0.0922 - val_loss: 0.0932 - val_lambda_1431_loss: 0.1075 - val_lambda_1436_loss: 0.0932\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 110s 164ms/step - loss: 0.0888 - lambda_1431_loss: 0.1048 - lambda_1436_loss: 0.0888 - val_loss: 0.1026 - val_lambda_1431_loss: 0.1158 - val_lambda_1436_loss: 0.1026\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0875 - lambda_1431_loss: 0.1034 - lambda_1436_loss: 0.0875 - val_loss: 0.1005 - val_lambda_1431_loss: 0.1151 - val_lambda_1436_loss: 0.1005\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0856 - lambda_1431_loss: 0.1008 - lambda_1436_loss: 0.0856 - val_loss: 0.0971 - val_lambda_1431_loss: 0.1117 - val_lambda_1436_loss: 0.0971\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0851 - lambda_1431_loss: 0.1008 - lambda_1436_loss: 0.0851 - val_loss: 0.0883 - val_lambda_1431_loss: 0.1022 - val_lambda_1436_loss: 0.0883\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0833 - lambda_1431_loss: 0.0981 - lambda_1436_loss: 0.0833 - val_loss: 0.0935 - val_lambda_1431_loss: 0.1090 - val_lambda_1436_loss: 0.0935\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0820 - lambda_1431_loss: 0.0967 - lambda_1436_loss: 0.0820 - val_loss: 0.0858 - val_lambda_1431_loss: 0.1002 - val_lambda_1436_loss: 0.0858\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0811 - lambda_1431_loss: 0.0955 - lambda_1436_loss: 0.0811 - val_loss: 0.0959 - val_lambda_1431_loss: 0.1151 - val_lambda_1436_loss: 0.0959\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0808 - lambda_1431_loss: 0.0955 - lambda_1436_loss: 0.0808 - val_loss: 0.0875 - val_lambda_1431_loss: 0.1000 - val_lambda_1436_loss: 0.0875\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0801 - lambda_1431_loss: 0.0949 - lambda_1436_loss: 0.0801 - val_loss: 0.0929 - val_lambda_1431_loss: 0.1087 - val_lambda_1436_loss: 0.0929\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0793 - lambda_1431_loss: 0.0933 - lambda_1436_loss: 0.0793 - val_loss: 0.0859 - val_lambda_1431_loss: 0.1006 - val_lambda_1436_loss: 0.0859\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0788 - lambda_1431_loss: 0.0929 - lambda_1436_loss: 0.0788 - val_loss: 0.0835 - val_lambda_1431_loss: 0.0980 - val_lambda_1436_loss: 0.0835\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0780 - lambda_1431_loss: 0.0919 - lambda_1436_loss: 0.0780 - val_loss: 0.0889 - val_lambda_1431_loss: 0.1032 - val_lambda_1436_loss: 0.0889\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0769 - lambda_1431_loss: 0.0906 - lambda_1436_loss: 0.0769 - val_loss: 0.0895 - val_lambda_1431_loss: 0.1063 - val_lambda_1436_loss: 0.0895\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0766 - lambda_1431_loss: 0.0902 - lambda_1436_loss: 0.0766 - val_loss: 0.0868 - val_lambda_1431_loss: 0.1019 - val_lambda_1436_loss: 0.0868\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0764 - lambda_1431_loss: 0.0900 - lambda_1436_loss: 0.0764 - val_loss: 0.0840 - val_lambda_1431_loss: 0.1003 - val_lambda_1436_loss: 0.0840\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0758 - lambda_1431_loss: 0.0898 - lambda_1436_loss: 0.0758 - val_loss: 0.0909 - val_lambda_1431_loss: 0.1102 - val_lambda_1436_loss: 0.0909\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0753 - lambda_1431_loss: 0.0887 - lambda_1436_loss: 0.0753 - val_loss: 0.0853 - val_lambda_1431_loss: 0.1002 - val_lambda_1436_loss: 0.0853\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0753 - lambda_1431_loss: 0.0893 - lambda_1436_loss: 0.0753 - val_loss: 0.0824 - val_lambda_1431_loss: 0.1005 - val_lambda_1436_loss: 0.0824\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0740 - lambda_1431_loss: 0.0880 - lambda_1436_loss: 0.0740 - val_loss: 0.0817 - val_lambda_1431_loss: 0.0964 - val_lambda_1436_loss: 0.0817\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.0739 - lambda_1431_loss: 0.0881 - lambda_1436_loss: 0.0739 - val_loss: 0.0996 - val_lambda_1431_loss: 0.1185 - val_lambda_1436_loss: 0.0996\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.0722 - lambda_1431_loss: 0.0857 - lambda_1436_loss: 0.0722 - val_loss: 0.0788 - val_lambda_1431_loss: 0.0922 - val_lambda_1436_loss: 0.0788\n",
      "Epoch 29/50\n",
      "517/667 [======================>.......] - ETA: 21s - loss: 0.0726 - lambda_1431_loss: 0.0868 - lambda_1436_loss: 0.0726"
     ]
    }
   ],
   "source": [
    "under_pattern = ['gaussian_factor=','poisson_center_radius=18_']\n",
    "under_rates = ['20','25','16_7','33','50']\n",
    "models_list = ['iiii','iii','k','i',\\\n",
    "               'kk','ii','ik','ki',\\\n",
    "               'kkk','kii','kik','kki','iik','iki','iik',\\\n",
    "               'ikii','kkkk','kiii','kkii','kkik','kkki','kiik','kiki','kiik',\\\n",
    "               'ikkk','ikik','ikki','iiik','iiki','iiik']\n",
    "\n",
    "for up in under_pattern:\n",
    "    up_prefix = \"../Data/Sampling-patterns/256x256/\" + up\n",
    "    for under in under_rates:\n",
    "        # undersampling patterns - uncentred k-space\n",
    "        var_sampling_mask = np.fft.fftshift(~np.load(up_prefix + under + \"perc.npy\") ,axes = (1,2))\n",
    "        var_sampling_mask = np.concatenate((var_sampling_mask[:,:,:,np.newaxis],var_sampling_mask[:,:,:,np.newaxis]),\\\n",
    "                                          axis = -1)\n",
    "        #var_sampling_mask[:] = var_sampling_mask[0,np.newaxis,:,:,:]\n",
    "        #var_sampling_mask = np.fft.fftshift(var_sampling_mask,axes = (1,2))\n",
    "        print(\"Undersampling:\", 1.0*var_sampling_mask.sum()/var_sampling_mask.size)\n",
    "        print(\"Mask type:\",  var_sampling_mask.dtype)\n",
    "        plt.figure()\n",
    "        plt.imshow(var_sampling_mask[0,:,:,0],cmap = \"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        indexes = np.random.choice(np.arange(var_sampling_mask.shape[0],dtype =int),kspace_val.shape[0],replace = True)\n",
    "        val_var_sampling_mask = (var_sampling_mask[indexes])\n",
    "        kspace_val_copy = kspace_val.copy()\n",
    "        kspace_val_copy[val_var_sampling_mask] = 0\n",
    "        val_var_sampling_mask = val_var_sampling_mask.astype(np.float32)\n",
    "    \n",
    "        seed = 905\n",
    "        image_datagen1 = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.05,\n",
    "            zoom_range=0.05,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "        image_datagen2 = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.05,\n",
    "            zoom_range=0.05,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "        \n",
    "        image_generator1 = image_datagen1.flow(rec_train[:,:,:,0,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "        image_generator2 = image_datagen2.flow(rec_train[:,:,:,1,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "\n",
    "        # combine generators into one which yields image and masks\n",
    "        combined = combine_generator(image_generator1,image_generator2, var_sampling_mask)\n",
    "\n",
    "        \n",
    "        # sample data augmentation\n",
    "        for ii in combined:\n",
    "            print(ii[1][1].shape)\n",
    "            plt.figure()\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(ii[1][1][4,:,:,0],cmap = 'gray')\n",
    "            plt.axis(\"off\")\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(np.log(1+np.abs(ii[0][0][4,:,:,0] + 1j*ii[0][0][4,:,:,1])),cmap = 'gray')\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(ii[0][1][4,:,:,0],cmap = 'gray')\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            break\n",
    "        for jj in models_list:\n",
    "            model = fsnet.deep_cascade_flat_unrolled(jj, H, W)\n",
    "            opt = Adam(lr = 1e-3,decay = 1e-5)\n",
    "            model.compile(loss = [fsnet.nrmse_min_max,fsnet.nrmse_min_max],loss_weights=[0.0,1.0],optimizer=opt)\n",
    "            up_name = up.split(\"_\")[0]\n",
    "            model_name = \"../Models/flat_unrolled_cascade_\" + jj + \"_\" + up_name + \"_\" + under + \".hdf5\"\n",
    "\n",
    "            #if os.path.isfile(model_name):\n",
    "            #    model.load_weights(model_name)\n",
    "            print(model.summary())\n",
    "            print(model_name)\n",
    "            # Checkpoint callback to save model  along the epochs\n",
    "            checkpoint = ModelCheckpoint(model_name, mode = 'min', \\\n",
    "                                     monitor='val_loss',verbose=0,\\\n",
    "                                     save_best_only=True, save_weights_only = True)\n",
    "\n",
    "\n",
    "            hist = model.fit_generator(combined,\n",
    "                         epochs=epochs,\n",
    "                         steps_per_epoch=rec_train.shape[0]//batch_size,\n",
    "                         verbose=1,\n",
    "                         validation_data= ([kspace_val_copy,val_var_sampling_mask],[rec_val,rec_val_abs]),\n",
    "                         callbacks=[checkpoint,earlyStopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
